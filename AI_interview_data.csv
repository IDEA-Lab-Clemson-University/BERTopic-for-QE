ID,Interview.ID,Role,Speaker,Utterance,Line,Stanza,ML.AI.Applications,Limitations.of.ML.AI,Privacy,Human.involvemnt.interaction,Bias..Prejudice..and.Harm,Minimizing.Bias.and.Harm,Assessing.Underlying.Motivations,Trust.Building,Algorithms.and.computational.thinking,Training.and.Testing.Machines.Using.Data
1,AH,Researcher,Researcher 1,"Okay, here we go. All right. So I'm recording this interview and we are interviewing with Madison. Did I say that correctly?",1,1,0,0,0,0,0,0,0,0,0,0
2,AH,Grad Student,Madison,Yes.,2,1,0,0,0,0,0,0,0,0,0,0
3,AH,Researcher,Researcher 1,"Okay, great. And what is the date today? Today is Thursday, January 27th, 2022. Just so we have it for the record. Okay. So let's get started. So Allyson, can you tell us a little bit first, just about you, your professional background and your work history?",3,1,0,0,0,0,0,0,0,0,0,0
4,AH,Grad Student,Madison,Sure. So I am an active duty army officer. I work in the cyber operations field for the army and I've been in the cyber operations field for the army since 2016. So some of my past jobs have really focused on incident response and defensive cyber is my main background work area and right now I am pursuing my doctoral studies in human centered computing focused on particularly adaptive autonomy in human AI teams.,4,1,0,0,0,1,0,0,0,0,0,0
5,AH,Researcher,Researcher 1,"Okay. Can you tell us more about, you said the projects that you worked on before? I don't even know what they are. You said defense, what was it?",5,1,0,0,0,0,0,0,0,0,0,0
6,AH,Grad Student,Madison,So mostly defensive cyber operations. So a lot of incident response kind of stuff.,6,1,0,0,0,0,0,0,0,0,0,0
7,AH,Researcher,Researcher 1,Okay. Can you give a little example of that?,7,1,0,0,0,0,0,0,0,0,0,0
8,AH,Grad Student,Madison,"So one job I had, when I was on a team, we would go out to different sites of critical infrastructure and basically assess their security posture and detect if they had any breaches or things like that and that all I've also done instant response missions, where a corporation may detect that they've had a breach of their security defenses and we come in and figure out where it came from, how to fix it and get rid of all the traces that are still on their systems or the networks.",8,1,0,0,1,1,0,1,0,0,1,0
9,AH,Researcher,Researcher 1,Okay. Got it. Got it. So then how did you become interested in joining the research lab that you're in now and exploring more AI applications?,9,1,1,0,0,0,0,0,0,0,0,0
10,AH,Grad Student,Madison,"So something, we noticed that a lot of the tools, so to speak that we use in computer security are very automated and are going towards the trend of what you would consider AI autonomous agents and I started to become interested in Dr. Thomas work on human AI teaming because those systems are almost getting to the point in computer security where they would have a full team role. And just trying, I wanted to start looking into the factors that would make those teams more successful as those tools become more and more autonomous.",10,1,1,0,1,0,0,0,0,1,0,0
11,AH,Researcher,Researcher 1,"Okay, great. So is human AI teaming a mix of AI agents and humans working together to complete a task?",11,1,1,0,0,0,0,0,0,0,0,0
12,AH,Grad Student,Madison,Yes.,12,1,0,0,0,0,0,0,0,0,0,0
13,AH,Researcher,Researcher 1,Okay. So can you tell me a little bit more maybe about your understanding of that and maybe why you're interested in it or why you think it is important work?,13,1,0,0,0,0,0,0,0,0,0,0
14,AH,Grad Student,Madison,"Sure. So the big differentiator for what would be a teammate versus a tool is that it's sort of an interdependent relationship. I'm not just using a system. I need stuff from it. It needs stuff for me. And there's a symbiotic relationship there. And I saw that as becoming more and more important, and I'm really interested in it because a lot of the tools that we're using on like computer security and a lot of other professional organizations are getting so sophisticated that they have capabilities that we're not able to do, that we really need to be able to leverage better. So from my perspective and a security standpoint, that's a lot of data analysis. AI can tackle data sets that we can't even fathom at a much faster rate. And we need to be able to give it a certain amount of autonomy to do that. But then there's also the human side of, I still need human reasoning to be involved in making a decision, especially when the risks or the consequences are high. So there's a lot of just interesting research areas for figuring out what the right balance is of that and how we work together with those tools.",14,1,1,0,1,1,0,0,0,1,1,0
15,AH,Researcher,Researcher 1,"That's so interesting, like this hybrid task force and like what the responsibilities should be of the AI and what the responsibilities should be the human. I think that's fascinating. Okay. So more about you personally. So what sort of activities related to AI would you do in a typical week in your position now?",15,1,1,0,0,1,0,0,0,0,0,0
16,AH,Grad Student,Madison,"I mean, right now it's a lot of just research and what their capabilities are and then trying to model what they might be able to do. So I'm designing a new experiment right now and we're going to fake the AI. We're not going to make the real system, but we have to be able to make it seem real to the person doing the experiments. There's a lot of research there about what the AI should be capable of and what the person would see and interact with the AI.",16,1,1,0,0,1,0,0,0,0,0,0
17,AH,Researcher,Researcher 1,"So tell me more about faking the AI. So you're not actually building the AI system, so what does it mean to fake the AI?",17,1,0,0,0,1,0,0,0,0,0,0
18,AH,Grad Student,Madison,"So what I'm doing right now, we have a chat client and it's supposed to be like the way that the AI would communicate with their teammate is through textual chat. So it'll just be, me or my trained team members actually typing out with the AI, I would tell them, but the participant doesn't know that. So they have to feel like it's an actual automated agent that they're conversing back and forth with as they're doing their task.",18,1,1,0,0,1,0,0,0,1,0,0
19,AH,Researcher,Researcher 1,I see. And what sort of rules do you base it on? How do you know what to type to sound like an AI agent?,19,1,0,0,0,1,0,0,0,0,0,0
20,AH,Grad Student,Madison,"I mean, that's part of the research, I mean, it's very structured. We're going to have a very strict script because an AI would've a very set amount of things that it would say. So that's part of the training for anyone that we do our experiments with, they have to be trained to literally stick toe to toe to the script because it's not like an AI agent's going to go off script, so.",20,1,1,1,0,0,0,0,0,0,0,0
21,AH,Researcher,Researcher 1,"Very cool. So what sort of, so you're in the research and a little bit of design part of your work, what sort of problems do you deal with when designing these experiments or what sort of problems I guess have you read about then in the research?",21,1,0,0,0,0,1,0,0,0,0,0
22,AH,Grad Student,Madison,"The first part would be just what people perceive, even as AI, something that's come up in a lot of my beginning research, is that what that means is completely different so on. I'll say the term AI, and some people think that they work with it everyday because they have all these automated systems and then some people think it's not going to be AI until it looks like something out of iRobot. So you have a very, there's not a very good definition of when something officially becomes AI and not everyone has that state mental model of what it should be. So that's a big difficulty to overcome when you talk, when you're working at human interaction with those kind of systems.",22,1,1,1,0,1,0,0,0,0,0,0
23,AH,Researcher,Researcher 1,"So if me or somebody else were to ask you, hey, stop you on the street, how would you define AI?",23,1,0,0,0,0,0,0,0,0,0,0
24,AH,Grad Student,Madison,"So for me, the ability to learn is really what separates it from an automated system. Because you can script something and just have it go and it's automated, but that doesn't make it intelligent.",24,1,1,0,0,1,0,0,0,0,0,1
25,AH,Researcher,Researcher 1,Sure.,25,1,0,0,0,0,0,0,0,0,0,0
26,AH,Grad Student,Madison,I think that the ability to learn or change its own code from what it's preset to be is where we start becoming an intelligent system.,26,1,0,0,0,0,0,0,0,0,0,1
27,AH,Researcher,Researcher 1,So then what about machine learning? How would you define machine learning and how in its relation to AI?,27,1,0,0,0,0,0,0,0,0,0,0
28,AH,Grad Student,Madison,"Machine learning is definitely one of the main factors that enables something to do that learning and be adaptable, which is really where I'm starting to look at research wise because in order to adapt and make changes to what it's just set to do, it has to be able to perceive and make inferences about its environment and its interactions. And that's where machine learning and deep learning really come in.",28,1,1,0,0,0,0,0,0,0,0,1
29,AH,Researcher,Researcher 1,"So related to that, either related to the work that you're doing with these sort of, with these mixed AI human teams or even beyond that, what are some current issues or trends that you see in AI or in machine learning?",29,1,0,0,0,0,0,0,0,0,0,0
30,AH,Grad Student,Madison,"I think we're still having a really hard time trying to replicate the human reason, part of what an AI is supposed to learn, because it can perceive certain environmental cues and pick up on new things it hasn't encountered and may inferences off of past [inaudible 00:09:38] but we can't, we are not really at a point where an AI could have any intuitive aspect of its decision making and human reasoning. And I think that inability is what causes a lot of the tension that we see with where the human should be involved in an autonomous agent, like doing something or making a decision because we know it can't replicate that aspect of human reason and learning.",30,1,1,1,0,1,0,0,0,0,0,0
31,AH,Researcher,Researcher 1,Yeah. What do you mean by intuitiveness? What does it mean when humans have intuitive nature that a machine doesn't?,31,1,0,1,0,0,0,0,0,0,0,0
32,AH,Grad Student,Madison,"So I think that based off our past experiences, people are able to develop opinions and feelings about whether something is likely or not that might not be so factually based.",32,1,0,0,0,0,0,0,0,0,0,0
33,AH,Researcher,Researcher 1,"I see, like a gut feeling.",33,1,0,0,0,0,0,0,0,0,0,0
34,AH,Grad Student,Madison,"Yeah. And even just the tendency, like one thing I was discussing in a research project I'm working on right now is that a lot of people didn't trust an AI to work in a risky decision be because they thought it'd be too logical. Like it's going to make a decision based off what the exact probability of something happening is versus what a human in this scenario is probably going to start thinking of the worst case as possible and they may be tangentially probable, but it might be so bad that they're not going to make a decision. And that's part of a human emotional factor that's not going to be replicated by a machine.",34,1,1,1,0,1,1,0,1,1,1,0
35,AH,Researcher,Researcher 1,"Not yet anyway. Okay, great. I'm learning so much by the way. I just [inaudible 00:11:18] you, this is great. Thank you for doing this. So kind of related to that, how do you think these advances in AI and machine learning help us and who do you think in particular it might help?",35,1,0,0,0,0,0,0,1,0,0,0
36,AH,Grad Student,Madison,"And the best thing about being able to utilize AI, especially from where my background is, it's just the ability to look and process so much more and faster than humans are capable of. And I think that'll help from the computer security standpoint immensely because our networks and just our vast space with internet of things and build your own devices is expanding so big that we need those systems in order to analyze the network and protect us from breaches, things like that. And then in other areas it's really important in human AI because we have all these abilities now on our social media or games to make avatars or realistic environments and all these other sort of things that we can really interact with. So a lot of people in my lab work are more in a gaming kind of area and human AI collaboration and that and you can make gaming and learning environments so realistic with AI agents being part of the system. I actually think it could be really beneficial if learning continues on the trend, it's going to be more and more virtual where maybe be there is an AI representation of other classmates or your teacher or things that might kind of bridge the gap between being physically in a building versus isolated in my own house. There might be a middle ground there.",36,1,1,0,1,1,0,1,0,0,1,0
37,AH,Researcher,Researcher 1,Yeah. That's great. Like simulating that environment a little bit closer to what we had in person potentially.,37,1,1,0,0,0,0,0,0,0,0,0
38,AH,Grad Student,Madison,"Yeah. I mean, so like my young son, if we're doing something like virtual learning, he's got to be on virtual learning for that day or that week. It's very difficult for him to pay attention to just a screen for longer than like 10 to 15 minutes. But maybe if it was like a very immersive environment where you had some AI students that were almost collaborating with you, it might be something he could engage in and get a lot more from that environment.",38,1,1,0,0,1,0,0,0,0,0,0
39,AH,Researcher,Researcher 1,"Yeah. Yeah. Maybe in the near future. Okay. So on the opposite end of the spectrum, how do some of the advances in AI or machine learning that you know about, how do they harm us and who in particular do you think they harm?",39,1,0,0,0,0,1,0,1,0,0,0
40,AH,Grad Student,Madison,"I mean, the aspect is so, AI is only as good as the data we give it, things like that. And I think there's a lot of discussion and research right now about a lot of AI being really biased to majorities because that's the data that they have access to. And so there might not be the ability to accurately assess or communicate with minority populations. And it could, I think there's some discussion about it kind of reinforcing biases and stereotypes because it's just operating off of the set of data that it's given.",40,1,0,1,0,1,1,0,0,0,1,1
41,AH,Researcher,Researcher 1,Do you know of any examples?,41,1,0,0,0,0,0,0,0,0,0,0
42,AH,Grad Student,Madison,"We were talking about it a lot in recognition software and things like that, where the data sets that it's usually using to recognize and communicate with people is generally very Western white male and wrongly classifies people and communicates with them as if they were that group, which makes it very difficult for people to not only work but connect to it and get the benefits as so much to some other populations.",42,1,1,1,0,1,1,0,0,1,0,1
43,AH,Researcher,Researcher 1,So in a sense then certain populations who aren't white males are excluded from that.,43,1,0,0,0,0,1,0,0,0,0,0
44,AH,Grad Student,Madison,"Yeah and they just don't feel comfortable working with it and then it becomes like cyclic, right. Because you need the data in order to fix the data, but if those portions of the populations feel boxed out, then you don't get that.",44,1,0,1,0,1,1,1,0,1,0,1
45,AH,Researcher,Researcher 1,"Yeah. So it's like you start with that data set that's not very representative. And then you test it on a not very representative sample because those who aren't representative or represented in the data in the machine don't want to use it. So then you don't end up teaching it to be more inclusive, I guess. Is that right?",45,1,0,1,0,1,1,0,0,0,1,1
46,AH,Grad Student,Madison,"Yeah. It's like everyone's got an Alexa or something like that in their house. And it is vocal recognition software, but if it can't understand you, it can't understand you. So it already has some of that bias in it or it can't understand certain dialects and accents and things like that.",46,1,1,1,0,1,1,0,0,0,0,0
47,AH,Researcher,Researcher 1,"Yeah. Yeah, absolutely. It's getting a little better though. I have a young son too and Alexa is starting to understand him.",47,1,1,0,0,1,0,0,0,0,0,0
48,AH,Grad Student,Madison,"Oh yeah. My son figured out, I guess about a month ago, how to actually tell Alexa how to do things. And now it's hilarious because I have the app on my phone where I can see all the devices and I can see what Alexa, hears him saying.",48,1,1,0,0,1,0,0,0,0,0,0
49,AH,Researcher,Researcher 1,What can I ask? What she thinks he's saying?,49,1,0,0,0,0,0,0,0,0,0,0
50,AH,Grad Student,Madison,"It's usually just missed words. Like he's obsessed with a few different movies and songs as little kids are and it's down to the point where all he has to do is say the word, Alexa Zombies and it knows to play the Disney channel original movie Zombies soundtrack.",50,1,1,1,0,1,0,0,0,0,0,0
51,AH,Researcher,Researcher 1,"Yeah, yeah, yeah, yeah. Definitely. I can relate to that on a personal level. Okay. So then the people who are designing these tools and distributing these AI and ML applications, who would you say, how would you describe that population of people?",51,1,0,0,0,1,0,0,1,0,0,0
52,AH,Grad Student,Madison,"I mean, I know from my experiences that it is very male dominated women make up less than 12% of the AI really working population. I think it is. I think that Western white male for where I'm working from is probably dominant. But I mean, I don't think that, that's globally applicable, I would definitely say male dominated.",52,1,0,1,0,1,1,0,0,0,0,0
53,AH,Researcher,Researcher 1,Yeah. And then do you think that connects them to the types of applications or tools that are being developed?,53,1,0,0,0,1,0,0,0,0,0,0
54,AH,Grad Student,Madison,"Yeah. I mean, I think especially when we talk about the human interaction phases, there's a lot of psychology that goes into whether someone wants to work with a device or not. So there can be some disconnect between the developers and the users a lot of time and that's usually when we see a product not doing well is when the designers think that something is exactly what the users want, but they're disconnected with who their user population actually is. And it might be a very good product, but if you miss that user interface part of it, then no one's going to use it.",54,1,0,1,0,1,0,0,0,1,0,0
55,AH,Researcher,Researcher 1,Yeah. Okay. So any other sort of ethical or social issues that you see using AI or ML that you know about or want to share?,55,1,0,0,0,0,1,0,0,0,0,0
56,AH,Grad Student,Madison,"I mean, I know privacy is always a big issue, especially when you're talking about collecting major data, in order for something to apply or use machine learning. It's got to be collecting a lot of data about environment and people it's working with. So you have people who are comfortable sharing different levels of information and different levels of being information collected about them. And then also if you have an agent like that constantly collecting data, wherever it's working or interacting, there's the concept of like, okay, at what point do you require people to be like, oh, where this is going on and happening and require some sort of consent versus like it's just, it's so ubiquitous that everybody just knows it's going on. There's probably a tipping point somewhere there, but I think that are long ways off from that. So I think the privacy concerns are going to be pretty, pretty important.",56,1,1,0,1,1,0,0,0,1,0,1
57,AH,Researcher,Researcher 1,Definitely. Yeah. Okay. So just shifting a little bit. This is more directly related to some of the work that we do in my lab. What are your thoughts about youth learning about artificial intelligence or machine learning even as young as elementary or middle school?,57,1,0,0,0,1,0,0,0,0,1,0
58,AH,Grad Student,Madison,"I think it's super important because it teaches you a lot about just logic thinking. So, I mean, if you start looking at how AI is designed or learned, it's very, there's a lot of logical flows and a little bit more about coding and it's almost its own language. And actually the younger, we can start that the better. Kids pick up. It's like what we discovered about foreign languages way too late was that we were starting teaching people way too late. I think it's the same when we start talking about coding and machine learning, the earlier we can start the more natural those language processes come to kids.",58,1,1,0,0,1,0,0,0,0,1,0
59,AH,Researcher,Researcher 1,"Yeah. As, so as someone who works so closely with AI, can you imagine an elementary school student or a middle schooler or even younger than that, what sort of, how could you break that down? Like AI or machine learning to get them kind of exposed to that?",59,1,0,0,0,0,0,0,0,0,1,0
60,AH,Grad Student,Madison,"I think it can start with simple games like when we start teaching kids to code, there's MIT developed scratch and very visual, game way of doing it. And I think you'd definitely start in a similar way by teaching them, just make a game to teach what you want it to do through logical representations. And they can build something that looks and dresses how they want and you name it and they make a connection to it.",60,1,1,0,0,1,0,0,0,0,1,0
61,AH,Researcher,Researcher 1,Any sort of core concepts you think you would include or could be included or could be kind of broken down for kids specifically?,61,1,0,0,0,0,0,0,0,0,0,0
62,AH,Grad Student,Madison,"Yeah. I think you start very simply with the state logic that defines most AI systems because that not only school teach them about how the AI system functions, but also just a lot about very basic decision and logic trees, which is important for kids to understand. So I think really starting from that, if this, then this or this kind of breakdown.",62,1,0,0,0,1,0,0,0,0,1,0
63,AH,Researcher,Researcher 1,Like some branches or like trees that kind of statement.,63,1,0,0,0,0,0,0,0,0,0,0
64,AH,Grad Student,Madison,"Starting with logic trees and then some state machine logic, things like that.",64,1,0,0,0,0,0,0,0,0,1,0
65,AH,Researcher,Researcher 1,"Okay, great. And then, so related to what we were talking about, what about ethical or social issues that we discussed or even beyond that maybe we haven't discussed, how would you, what are your thoughts about youth learning about that in conjunction with AI and ML?",65,1,0,0,0,0,1,0,0,0,1,0
66,AH,Grad Student,Madison,"Yeah, I think that part of that's going to be more important for our kids and we ever thought just because I think the average now for a kid to get a cell phone is 10, which is mind boggling to me, but that's the statistic and that's just going to keep getting younger as it's becomes more and more. And then they're using tablets and everything in schools and all that. So understanding that things that collect data, create privacy concerns, they have to consider the people around them to include AI, I think will be definitely a necessary part of elementary education.",66,1,0,0,1,1,0,1,0,0,0,0
67,AH,Researcher,Researcher 1,"Yeah, absolutely. Kids are getting Chromebooks in second grade now. The schools are distributing. We just talked about our children, interacting with Alexa that's a intelligent system, so.",67,1,1,0,0,0,0,0,0,0,0,0
68,AH,Grad Student,Madison,I would go in and make sure all abilities to purchase anything were turned off of every device in my house and...,68,1,0,0,0,0,0,0,0,0,0,0
69,AH,Researcher,Researcher 1,Yes.,69,1,0,0,0,0,0,0,0,0,0,0
70,AH,Grad Student,Madison,Things like that.,70,1,0,0,0,0,0,0,0,0,0,0
71,AH,Researcher,Researcher 1,"Yeah, I learned that a little bit the hard way, but just one mistake and then we fixed it. Okay, great. So imagining it sounds like you think it is important to teach kids about both those things like AI concepts, but also maybe some of the ethics around privacy and other issues and maybe getting more important as the years go on. Do you know of or can you think of any specific tools or activities or ways to engage youth in both of those things?",71,1,0,0,0,0,0,0,0,0,1,0
72,AH,Grad Student,Madison,"For kids, especially younger, the more tactile they can get on anything the better and the more able they are to really pay attention. So just if we can make physical representations of those trees and the logic and things that move to the better. So one of my sons teach preschool teacher, they have were teaching them shapes and they have like shaped man who gets on the floor and they put them all the pieces together to make shapes and patterns and things. You can do the same thing with logic trees and decision making and then even understanding things like privacy, where you know how far something spreads or what you're taking. So just the more tactile you can really make something for kids at that age the better.",72,1,0,0,1,0,0,0,0,0,1,0
73,AH,Researcher,Researcher 1,"Yeah, that's great. And then last one kind of related to that. Can you think of ways then to help them connect these topics to their everyday lives and make it meaningful for them?",73,1,0,0,0,0,0,0,0,0,0,0
74,AH,Grad Student,Madison,"I think it's going to be a lot easier than we think just because they're so ingrained in the technology itself. My daughter is just about to turn one and she can already swipe on a tablet because she's watches her brother swipe on a tablet. And I think just those simple movement to think, they're going to be so more used to it than we are getting used to it. I don't think it'll be that much of a stretch just relating it to the devices they already use or have , I mean, even Alexa is a type of AI, because it does learn things about you, it learns to pick up your voice and your inflections and specific words and what you like. So, I mean just being able to talk about the everyday devices that they use is going to be easy for them.",74,1,1,0,0,0,0,0,0,0,0,0
75,AH,Researcher,Researcher 1,"Yeah, yeah. And then what about young kids? Do you think they're interested or can relate to those ethical issues or social issues that we discussed like non-representive data sets or....",75,1,0,0,0,0,1,0,0,0,0,0
76,AH,Grad Student,Madison,"Yeah, I mean, I just have to be broad as close to them as they can like little things like, hey, you can't turn on this device in your sister's room and listen, because there's a privacy implication there. Just don't make it about huge asylum impact. It's got to be close ecosystems to themselves.",76,1,1,0,1,0,1,1,0,0,1,0
77,AH,Researcher,Researcher 1,"Personal. Yeah, yeah. I think we have similar lives. I also have a one year old daughter and a four old son.",77,1,0,0,0,0,0,0,0,0,0,0
78,AH,Grad Student,Madison,"Oh yeah, close. I have a one year old and a three year old.",78,1,0,0,0,0,0,0,0,0,0,0
79,AH,Researcher,Researcher 1,"Yeah, yeah. Pretty close. Yeah, so when you're talking about her swiping, she does similar things, very happy with the technology. She barely talks. She's about maybe 10 words and one of them is Alexa. She walks around screaming, Alexa, Alexa. Okay, great. What about if you've had experiences, the last question really, experiences teaching or been in situations where you're the student, have your teachers or have you used any learning techniques that you feel were helpful to learn some of these ideas?",79,1,1,0,0,0,0,0,0,0,0,0
80,AH,Grad Student,Madison,"So the biggest thing that comes to mind in terms of just learning the logic patterns that are behind these is, I had a class, it was my only EE class. I absolutely hated it. And I would not have made it through if my husband didn't have to be an electrical engineer, where we had to program a Roomba so that it would go and park somewhere. And we had to develop this state machine logic that would do that and then program everything. But I think, yeah, hands on activities like that you're going to program a Roomba and watch it do it or a remote control car or something like that. Something what we can physically see the effects of what they've created is really helpful.",80,1,1,0,0,1,0,0,0,0,1,0
81,AH,Researcher,Researcher 1,"Yeah. I think that's absolutely right. We sort of, we run a couple of pilots with some kids and we learn that very quickly that they love robots. They want to take what they're doing on the screen and see it in real life and see that connection. And so I think that's absolutely right. Especially with young kids. That tactile piece that physical computing I think is really important.",81,1,1,0,0,1,0,0,0,0,1,0
82,AH,Grad Student,Madison,"Yeah and it gives them, I mean, little bit older geeks might get a good jump of satisfaction out of their code compiling, but for kids, they need to see something more. So, oh my code made it do this and it can go there now is a lot better ever win.",82,1,1,0,0,1,0,0,0,0,1,0
83,AH,Researcher,Researcher 1,"Yeah, exactly. And I can run over my sister or we can have a race it's like integrating that into their everyday fun.",83,1,0,0,0,0,0,0,0,0,0,0
84,AH,Grad Student,Madison,Yeah.,84,1,0,0,0,0,0,0,0,0,0,0
85,AH,Researcher,Researcher 1,"Okay. Great. Well, thank you so much. Is there anything else you want to add that we didn't touch on?",85,1,0,0,0,0,0,0,0,0,0,0
86,AH,Grad Student,Madison,"I can't think of anything, but if you have any additional questions, feel free to wrap it up.",86,1,0,0,0,0,0,0,0,0,0,0
87,AH,Researcher,Researcher 1,"Okay. You so much, this was super helpful. I really enjoyed talking with you. And again, this is really helpful for our research. So thank you for taking the time out to talk with us.",87,1,0,0,0,0,0,0,0,0,0,0
88,AH,Grad Student,Madison,No problem. Have a great day.,88,1,0,0,0,0,0,0,0,0,0,0
89,AH,Researcher,Researcher 1,Okay. Thanks. Bye Allyson.,89,1,0,0,0,0,0,0,0,0,0,0
90,AH,Grad Student,Madison,Bye.,90,1,0,0,0,0,0,0,0,0,0,0
1,JM,Researcher,Researcher 1,"Okay. Hello, Joe. This is Joe Michaelis. This is Friday, January 28th, 2022. So I'm just going to get right into it. Joe, can you tell me about your professional background and a little bit about your work history?",1,2,0,0,0,0,0,0,0,0,0,0
2,JM,Faculty,Michael,"Sure. Yeah. Currently an assistant professor in computer science and learning sciences at University of Illinois, Chicago. The work I do is in social robots for educational purposes that are designed as learning companions, where they work with or around kids to help them learn in lots of different scenarios. My training with it is... My PhD's in learning sciences from University of Wisconsin, but I have a PhD minor in computer science where I did a lot of human robot interaction work. So I'm trained on the HR, the design of the robots and the interactions, and on learning and learning theory. And so the combination of those two is to design learning interactions for kids to really enhance their learning experiences.",2,2,1,0,0,1,0,0,0,0,1,0
3,JM,Researcher,Researcher 1,And what sort of technology or programming do you use for these robots or have you been using? Do you use artificial intelligence or machine learning?,3,2,0,0,0,1,0,0,0,0,1,0
4,JM,Faculty,Michael,"A bit. Yeah. So the primary ones that I'd say we use is... I mean, my mine is often fringe machine learning AI, and often dumb versions of what could be construed as AI, because my work a lot of times is really interested in the interactions and not so much the technological solutions to automating those things. So we do a lot of work that uses text-to-speech, which I would definitely put in the AI natural language processing camp. And in that, one of the real challenges is in balancing the automated portion of it. It's nearly impossible to get the speech exactly right. And so we debate a lot about how much time and energy to put into adding in markup language, things that can edit the [profidy 00:02:19] and that sort of stuff of the output versus just taking what we get. And so what that means in our workflow is that if we preset everything, if we know everything exactly that the robot's going to say, then we can prerecord all the audio, and then we can review it and make sure we massage and finesse it. But if we want the robot to be more spontaneous where it's generating the audio in the field, we don't have that opportunity to correct or even review what's going on with these things. So you'd mentioned the ethical and social aspects of those things. That's one of my big concerns is when we use these off-the-shelf technologies without any human in the loop, that bad things on a low level just might make it seem confusing or just inauthentic. But it could also be pretty problematic the way that it comes across or even if we're auto-generating what's to be said, if there's even a syntax error in those things, then it comes through.I had one during my early grad work where we were trying to insert the student's name into the speech that the robot said, and this was all automatically processed. I didn't prerecord anything. And we screwed up the syntax on it. And so it ended up actually reading the markup code that we had in there. It'd be like, ""Hello, ate our open bracket, closed bracket,"" And had all these weird things that it said. And I was really happy that I caught that before we put it in the field because that's the sort of thing that it's nightmare fuel. Because again, I work with some youngish kids. They're 9 and 10. And so the last thing I want to do is scar them with this berserk-seeming robot. So yeah. So I think the text-to-speech is probably the primary one that I use on a daily basis.We're developing techniques then... Again, one of the things we want to do is try to automate some of what the robot says because the human part of it is so labor-intensive. So we're working on some techniques to use the real modern advances in tech summary are really helpful and pretty good now where I'm working on the homework utilities so the teachers can make homework assignments for kids that a robot would read to them. I think that's the one that you were going to be on the board for. So the idea there though, and when we're talking to teachers, they're like, ""This sounds great. I really love the idea, but I really need a lot of automation in here,"" that if they're going to go through and hand-write out everything the robot's going to say they just can't. So we're looking at doing some auto-tech summaries where they can bring in a PDF or a website of something that they want the kids to read at home for their class and then just say, ""Summarize this portion for the kids. And I want the robot to say that summary."" So that's the next level for us. And so again, we still have the text-to-speech problems in there where we're not going to have much control over the profidy and the way that it's delivered, but we'll also not have too much control over the actual contents of what's generated there. So we're working on methods to try to do pre-review things. So in the pipeline where the teacher maybe selects, summarize this portion and submits it before it actually gets out to a student, that we'd be able to have some sort of human review over that just to make sure it makes sense. And there's other automated reviewing techniques that are out there. I haven't looked at them in detail, but they're out there too.So that's, I think the one that is currently working on. And then the last one that comes to mind is I've always used OpenCV for facial recognition. And then we use that for face tracking. So all of my robots have been able to track the speaker by taking that essentially, just putting an X, Y position on the center of a face and then aligning motors to be where the robots face appears to be looking at the person. Probably the biggest one we haven't gotten into, the Misty robot that I have uses SLAM mapping. So it can do navigation in a home pretty simply. And that's an option. We just haven't chosen to do any mobile robot stuff in people's homes. It seems like one of the last things I want to work on.",4,2,1,1,0,1,1,1,0,1,1,1
5,JM,Researcher,Researcher 1,What is SLAM mapping?,5,2,0,0,0,0,0,0,0,0,0,0
6,JM,Faculty,Michael,"Oh yeah. Sorry. Simultaneous Location and Mapping. So it will essentially... and the more advanced Roombas, they do this too, right, where they'll just roam around and map out the space, and then the robot will be able to situate itself within that space so it can be intelligent about how it navigates around. But so far we haven't had any locomotion for robots in homes, again because of ethical and privacy concerns where if something goes wrong, I really don't want my robot to roll into the bathroom or just make people feel uncomfortable in their home. I think all the good things I'm trying to do will be totally undermined by a robot creeping people out. And it's also I think ethically the right thing to do to not have an opportunity to freak people out that way. So the robots I work with have that capability, and it's part of what makes them expensive, but I don't take advantage of it at all, other than the one robot I use for demonstrations in the lab. It's mapped out and does location sensing. And so it can follow me around and I have a few places around the lab that it knows to go. So just to impress people, I'd be like, ""Hey, Timmy, go to the table."" And it'll wander over to the table and people are like, ""Wow, that's [inaudible 00:08:28]."" Not really, but okay.",6,2,1,0,1,1,1,1,0,1,1,0
7,JM,Researcher,Researcher 1,"Well, okay. So you've already touched on some potentially ethical issues with the location sensors, going into more private areas, potentially if for some reason the algorithm does that. And then you also talked about it with the speech-to-text, just some errors there that can impact your work. With all the different technologies you just referred to, are there other social or ethical problems that you come across with your technologies, like the facial recognition or just the child interacting with the speech-to-text or anything?",7,2,1,1,1,0,1,0,0,0,1,0
8,JM,Faculty,Michael,"Yeah. In my work, not really. Not in an AI/ML way, one of the things we do is we'll set up auto video recording when kids are reading with a robot in the home. And so that was when we spent a lot of time thinking about and working with families and what's going to make them comfortable. And most of them were pretty fine with it. They just wanted it to be really, really clear when recording was happening. So it's actually impacts the choice of robots that I use. So the Misty robot I have has a little LED on its advisor that we can make really bright. And so it's there because when it's video recording, and it actually has a nice scene, but it's also really good indicator so that we train families to know that if you see that light, it's video recording. And we also train the families to know exactly how to shut that off in a one-touch thing. There's a spot on the robot that if you touch it there, the video recording will shut down.We also give them free license if they don't want to do that and just want to snap the whole thing off, that's okay too. So it's not in an AI/ML way, but in a privacy ethics issue, that's probably the number one thing I think we run into with my work.",8,2,1,0,1,1,1,1,0,1,0,0
9,JM,Researcher,Researcher 1,"Yeah. I mean, that's definitely related because a lot of AI and ML technologies surveil us, right, or take that data and then do something with it. So in that this case, it's about the data collection and how comfortable we are.",9,2,1,0,0,0,0,0,0,1,0,1
10,JM,Faculty,Michael,"Yeah. It's part of the decision we've done for facial recognition, part privacy, but also part practicality. We only do frame sampling... I think it's every... Might even be every minute now. We used to do it about 20 seconds, but even that was a little bit tough on the processing, and it ended up capturing a lot of information from the family home. So we set it somewhere between 30 and 60 seconds now where instead of trying to real-time video or a lot of people do three frames, a second kind of stuff, we take a really slow approach to it. In parts, we collect less data. It means that the facial recognition stuff is a little bit slower to respond. But in our user testing, it hasn't been too much of a big deal. So again, in that trade-off of how precise we can get the face tracking stuff versus how much information we're collecting from a home, we balance those two things out. And again, we're really clear with families about how that works and what's going on with it and how they can disable it if they need to.
",10,2,1,1,1,1,0,1,0,1,1,1
11,JM,Researcher,Researcher 1,"Yeah. And you haven't had any problems recognizing faces. It recognizes kids, all different kinds of kids?",11,2,1,0,0,0,1,0,0,0,0,0
12,JM,Faculty,Michael,"Oh yeah. That hasn't been a problem at all. Yeah. And it responds similarly. So the bugs are the same too. That was when I did my dissertation work. We did a lab study of it. And since I had so many kids, that was one thing that I was really aware of. I didn't want facial recognition to not work for somebody with darker skin kind of thing. That's a pretty common problem. And yeah, so I looked at it. I had some backup plans about what I might do to try to improve, but I really hadn't had any problems with it. And it's not the most sophisticated of face recognition. It's OpenCV. It's one of the simplest. It's one of the most widely-used, but it's pretty simple, but seem to perform just fine for the most part. I mean, we've had a lot of different students, a lot of different skin tones or facial shapes and all that sort of stuff. Never had anybody have any problems with it. Like I said, the bugs in it is it'll drop your face entirely, but that seems to be relatively... And we have a built-in backup of when the robot doesn't seem to think that a face is there, but a face was just there, that we build in a, let's assume that the face is still there [inaudible 00:13:20].",12,2,0,0,0,0,1,1,0,0,0,0
13,JM,Researcher,Researcher 1,"Act as if it's still there, robot.",13,2,0,0,0,0,0,0,0,0,0,0
14,JM,Faculty,Michael,"Right. And then also we have to deal with what if there's multiple faces in the scene? How do we do that? So the first layer of that is to whichever is the larger in the screen is most likely closest, and most likely closest is probably the one that's the main interactor. [crosstalk 00:13:38] that kind of stuff on there. But yeah, I haven't seen any issues with biases or differences based on that. And from the field stuff, that's where I worry more about it, where the lighting is less standard, that kind of stuff.",14,2,0,0,0,1,1,0,0,0,0,0
15,JM,Researcher,Researcher 1,Is it something you thought about or [crosstalk 00:13:56],15,2,0,0,0,0,0,0,0,0,0,0
16,JM,Faculty,Michael,Oh yeah. Absolutely.,16,2,0,0,0,0,0,0,0,0,0,0
17,JM,Researcher,Researcher 1,... you did a little... Yeah.,17,2,0,0,0,0,0,0,0,0,0,0
18,JM,Faculty,Michael,"Right. So my early field-based stuff, it was really small scale. And it was in the back of my head. You know what I mean? I mean, one of the things that helps is that I've worked with students who have... I mean, we have groups of students. So when they're testing these things out and working with me on these, we're able to do it. Actually, the one that we had the biggest trouble is with the speech recognition stuff. We did a little bit of voice recognition. I guess I hadn't mentioned that. The accents from some of the students, that was where we actually had the biggest trouble. So even relatively mild variations were really hard for speech recognition to pick up. And then that compounds when you have children who are already really tough for speech recognition to figure out any accent with those children. That's why we barely tried any of that actually out in the field. We were trying to do keywords and stuff. But yeah. That's the one that's a lot more problematic is in speech recognition rather than face. And I'm also not doing things where... I know I have colleagues who do emotion recognition, and that terrifies me. I think that [inaudible 00:15:13] no mistake because I know I've seen... I've run these things, and just my resting face, I get classified as border angry quite a bit. I'm a little jolly and I have a little bit of a down slope, and I'm kind of eyebrowey too. And so yeah, I get misclassified all the time on those things. But I've seen that implemented in ways that really does make me nervous, that if we're going to make estimates about, ""That kid is angry,"" and then do something with this data that says, ""This is an angry kid,"" I don't think we're anywhere close to having that as reliable. So that's in part why I use dumb things where face recognition that also has to do with say, ""That's a face,"" that I feel more comfortable and confident in. And if it fails, it's not super consequential, right? The worst-case scenario, if it fails, is it doesn't see a face. And if the face was there before, like I said, we have methods of dealing with that. And worst-case scenario, the robot just looks like it's not paying attention, right? I figured there might be some sort of psychological... I mean, damage is probably too strong a word... impact where a kid maybe feels ignored by the robot if that happens. But if we were using emotional things, emotional estimations to make decisions about what the robot does next, that I think would be much more impactful. So I mean, it's part of why I end up as a roboticist and a Luddite at the same time, that I just really worry about the consequence of technologies, that they work, but the danger... Let's say it's 80% effective, right? That 20%, if there's a pretty strong potential for impact, I want to avoid it. So I think that's part of why it's been successful is I'm not asking it to do too much. Just finding a face as much simpler than classifying it. ",18,2,1,1,0,1,1,0,0,0,0,1
19,JM,Researcher,Researcher 1,"Right. Yeah. Absolutely. If a kid is angry but the robot thinks the kid is joking and laughs at the kid while the kid is angry, I can imagine that would have a strong impact on a young child.",19,2,0,1,0,0,1,0,0,0,0,0
20,JM,Faculty,Michael,"Yeah. There are some grad students in our department that their work, they want to do things like that. And so I'm in their ear all the time about really walking through the consequences of mistakes.",20,2,0,1,0,0,0,0,0,0,0,0
21,JM,Researcher,Researcher 1,"Yeah. So going back, I just have a follow-up question about the speech recognition. And you talked about the different accents and the technology not necessarily recognizing different accents. Can you say a little bit more about what the technology you use did recognize specifically, what type of accents, and what type of accents it had problems with?",21,2,0,0,0,0,1,0,0,0,0,0
22,JM,Faculty,Michael,"Oh yeah. Well, so for the most part, I have a relatively Wisconsin accent. And so the models that we used were... we tried to do was out of Carnegie Mellon. I forget the name of the program that did it, but it was one that could run on board. And that did relatively standard US dialect, was generally really successful. The student who was running that was from India, though, and her accent was completely inaccessible to the robot. And then she worked with another student who was Korean and also really struggled with her accent as well. So between the two of them, they were just really frustrated trying to get... And we were just trying to set up simple keyword kind of things like, ""Hey, Alexa,"" kind of stuff. We were just trying to do simple keywords with the robot, and it got nowhere. So that was the Carnegie Mellon one. And then we've been a little bit more successful. I haven't used it, but the folks I worked with at Wisconsin who followed up with some of this, they did add some keywords to our last field-based one over the summer. And I don't know if they tested it much as far as accents go. I know one of the researchers on the team is Turkish, and she didn't seem to have much trouble. But again, we really constrained the word list for that. And the cloud-based ones I think are a little bit better now than the ones we were... Sync, that's the CMU one that we were using. So I think they're a little bit better now. And so that's one that has been starting to get cooked into the robots I have. I just haven't sent them out in the field doing that yet, but just simple, yes, no kind of stuff seems to work, and that hasn't... We haven't seen any evidence that that level has been impacted by any accent or dialects. ",22,2,0,1,0,1,1,1,0,0,1,1
23,JM,Researcher,Researcher 1,"Okay. So I know that AI and machine learning is not core, central to the work that you're doing, but you do use it and use it a lot of different ways, different applications. So if someone were to ask you like, ""Joe, how would you define AI?"" how would you define it?",23,2,0,0,0,0,0,0,0,0,0,0
24,JM,Faculty,Michael,"Yeah. I mean, it's essentially... So it has to appear intelligent, I think, right? So I don't know if it has to actually be intelligent. And so that's where I'd classify some of the things that I do that are... If you really dig down into it, it would probably be classified in algorithms, right? It's an algorithm. So I did a book selection algorithm. But I think it's important to think about the user's perspective on these things. And so I have a pretty broad idea about AI in that if it appears intelligent, if it comes across as intelligent... I mean, maybe if it even wasn't the intent that it comes across as intelligent, but it appears that way, I think we have to treat it as AI because of the impact it would have on the person that it's interacting with, right? So my book selection algorithm is not complicated at all. It's essentially like a sorting algorithm and we add in a couple of inputs about what the kids' book preferences are like, their reading skill level, the amount of time they read, that kind of stuff. And then we tag books for all those features, and we just make a priority queue out of it. Really simple, early CS stuff. But to the kids, it came across as intelligent. And I think that's the key factor, that when we interviewed them afterwards, kids felt that the robot was paying attention to them and that the suggestions the robot made for books were personal, that they were about them. And so that to me is now where you're in artificial intelligence and you really have to then take that seriously, because if the person believes that they're working with an intelligent machine, then you have to treat that carefully.",24,2,1,0,0,0,0,0,0,0,1,0
25,JM,Researcher,Researcher 1,"Yeah. That's such a wonderful HCI definition. I love that, right? It depends on how the agent or the person is perceiving it. And then what about machine learning? Same question.",25,2,0,0,0,0,0,0,0,0,0,0
26,JM,Faculty,Michael,"Yeah. In that sense, that I think, I would fall in line with a little bit more traditional perspective, because machine learning doesn't necessarily always have to... It's not is a user-facing part of what's happening. So it's essentially how to take a bunch of inputs, teaching a machine how to interpret those inputs, and to organize, categorize, or plan actions based on those inputs. So it's different levels of black boxiness that go along with it. But yeah, it's essentially the training machines to have a space in between input and output that is nonlinear, I guess. So I mean, the traditional perspective is you have this set of data that's coded with these sets. And so you train that way. And then a new set of data that isn't coded, the machine should take what it learned from this first one, apply it there, and come up with the same codes. Those codes could then be actions to do. Those codes could be categories. Those codes could be things like emotions, right? So, ""Here's 10,000 pictures of people who look angry. Here's 10,000 more. Which of these are angry?"" kind of thing. So that, I think. And now that I'm thinking about it, that's almost sneaky or more problematic sometimes because you don't necessarily always have the user interacting with it while you're developing these things and testing them. And it can be to such a scale sometimes that the errors and the problems in there are easy to miss, right? That, ""Hey, we got 99% accuracy,"" but that means if there's 100,000 images in that set that you're classifying on, 1% is actually a lot. And if that 1% impacts me and you're just going to take this thing off the shelf that's 99% accurate, and you're going to take it off the shelf, and it's going to make a medical diagnosis, and I get the 1% problem, that's pretty impactful. So again, that's one of the things I talk a lot with graduate students who are like, ""Oh, I'll just grab the thing and we'll just figure it out. It'll tell us what to do."" No, that's not safe in a lot of the things that we're doing. So, yeah. So I guess, I don't know. I mean, that's a too-long explanation of what machine learning is. ",26,2,1,1,0,1,1,1,0,0,1,1
27,JM,Researcher,Researcher 1,"No, it's perfect because it went to the next question. So it's great. You covered a lot. Well, the question was how do some of these AI or machine learning applications and tools harm us? And so you talked about that in your work and you just talked about that in a more general sense. So to keep going on that thread, who do you think in particular, right, some of these tools might harm?",27,2,0,0,0,0,1,0,0,0,0,0
28,JM,Faculty,Michael,"Honestly, [crosstalk 00:25:46]-",28,2,0,0,0,0,0,0,0,0,0,0
29,JM,Researcher,Researcher 1,What population of people? Who is that percentage of people you're referring to?,29,2,0,0,0,0,0,0,0,0,0,0
30,JM,Faculty,Michael,"Well, I mean, so there's definitely documentations of bias that are in there for essentially, right, the people who are designing and making these things cook in their own biases into there. And so if 98% of the data that we trained on are a bunch of white males, then anybody not in that category is going to be on the margins of the data set. And that means they have not been properly trained into that data. And so we're going to be misclassified at a much higher rate. So I mean, I think there's good efforts that are out there now to actually really think about representation and training sets. I don't know how that gets reported. I haven't seen anyone who has openly reported their training statistics that way, that, ""Here's how we balance gender and all the other demographic things that would go into impacting these outcomes."" So in a healthcare setting, I mean, it's happened before machine learning, is doing these diagnostic things, the reports of people where there's no black people represented in medical textbooks, right? That's not about a machine learning thing. That's about a human learning thing, where if you've never actually practiced or considered examining a person's body who's different than cliche US Western standards, then you're going to make errors. And so I think we're making the same mistake that we ignored before machine learning. We're making the same mistake. And yeah, I think right now, the biggest thing for me would be transparency on these things. How are these systems trained? What do we know about those data sets? So yeah, they're much more likely to impact marginalized communities because those are going to be the data that's on the margins in the training sets. But I do think there's repercussions for everyone as well. And that's part of my worry too, that definitely some populations are going to be overrepresented in how they're negatively impacted. But I think there's negative impacts across the board. And so again, emotion recognition kind of things, I think those are problematic. Medical examination kind of things, I think are really problematic. So I'm skeptical across the board, but yeah. [crosstalk 00:28:37]-",30,2,1,0,0,1,1,1,0,1,1,1
31,JM,Researcher,Researcher 1,"Yeah. There's marginalized communities because of biased data sets, but then there's also just, even though the percentage of error is low, the impact is high is what I'm hearing you say.",31,2,0,0,0,0,1,0,0,0,0,1
32,JM,Faculty,Michael,"Exactly. Yep. And the propensity to NCS to move fast. Who was that speaker? I think there was a speaker in Wisconsin that they talked about... Oh, no. It was the job talk. They were talking about the credo in Silicon Valley to move fast and break things [inaudible 00:29:09] what if we actually move slow and fix things? And that stuck with me because that's my feeling. I don't want to rush things out. I really do want to go slow, get it right so that the things that I want to help actually help.",32,2,0,0,0,0,0,1,0,0,0,0
33,JM,Researcher,Researcher 1,"Yeah. I love that, Joe. And I can see that in your work, the way you've described it. That's great. Okay. So let's switch. So talking a little bit about why we're doing this interview, right? We're taking what people are saying and trying to apply it for learning experiences for young people. So what are your thoughts just generally about elementary school, middle school-age kids learning about either AI machine learning and the social and ethical impacts or both? [crosstalk 00:29:56] ideas around that, what they should learn, what's important for them to know? Can they [crosstalk 00:30:00] in those issues",33,2,0,0,0,0,0,0,0,0,1,0
34,JM,Faculty,Michael,"Yeah. I mean, very much the way I would handle a science classroom or... I've never taught history, but a history classroom, so that we really need to make sure that part of the training is not just how to use it, but when to use it, why to use it, where it came from, where it's going. All the other pieces around it are really crucial, so that it's not just seen as a tool that you take off the shelf and you go do it, right? This isn't just a ruler that you put down and you draw a line. It's so much more complicated than that. Without really thinking about it, it's easy to use it, though like I said, with graduate students, the conversation I have all the time like, ""Careful with that,"" right? And so these are dangerous tools. And so understanding that is part of the training. The first step, I think, is really understanding, particularly for machine learning, how these things are built, where they come from. And if I were designing something for elementary kids, it would be to demonstrate how impactful the representation in the training set impacts that output set. That's really where I would start. So that's the basis of all their knowledge about this, is how machine learning systems are created so that every time they do use it, they should hopefully be there thinking about how this was put together. So that would be the first step, the ontology part of it. How do these things come to be? And then the output part of it, what are the potential impacts that again, it reminds me of working in labs with science kids. ""Okay. So here's this thing. What could go wrong and how are you going to mitigate that? And if it does go wrong, what do we do, right?"" Those are the questions that have to happen before you start even using basic glassware in a science lab. And so I think that those are the conversations that need to happen, that these need to be treated as complex and potentially damaging tools. And so even at a young age, kids got it. Kids totally get it, right? They have no problem. My six-year-old gets it with some of this stuff. She knows the tools around the house that are potentially dangerous, and she understands why and how they're dangerous. So I know that we can impart that to human elementary kids around this stuff. Because again, I think machine learning, you can do simple versions of it that really illustrate how it's working. And that's it. You can't just say like, ""Okay,"" right? I think illustrating it, showing them that and letting them manipulate those inputs and see what happens to the output kind of stuff. I think that's going to make some really powerful ways to demonstrate that and get it to really stick.",34,2,1,1,0,1,1,1,0,0,1,1
35,JM,Researcher,Researcher 1,"Yeah. Absolutely. You answered everything. I'm looking at my follow-ups. I'm like, ""Oh, you got that. You got that."" Yeah. I mean, if you want to expand a little bit, if you were to take Jules for example, right, your daughter, and she's six, and what would you want her to know about machine learning or about at that age, anything or about how harmful it can be? Would you talk to her about privacy? Would you talk to her about misrepresentation or discrimination? Where would you go?",35,2,0,0,1,0,1,0,0,0,1,0
36,JM,Faculty,Michael,"Yeah. It makes think of what we already do a lot with advertisement, that we call it out. We point it out for what it is. I see us doing that a little bit too. She doesn't encounter it that much, but we like to shine the light on these sort of things so she sees the impact of them. So when there's a commercial that catches her attention, we always say, ""That's an ad."" And she's so accustomed, she'll turn to us and like, ""What are they trying to sell us?"" And that's the approach, I think, again, on that output part is to really, I think, if you're teaching kids about it in ways that they're going to use it, that's a little bit different. But there's also the consumer side of it that I haven't really thought much about to really interrogate this thing, right? I'm on Twitter. Why am I seeing this thing? Right? And understanding at least some of the details behind what goes in there, right? So if you're completely not thoughtful about it, it might seem like, ""Because this is just the right thing for me to see,"" or, ""This is what all my friends are seeing,"" or, ""This is just the most important news."" But if you're actually taught that it's there because there's this system built to put it there in front of you, and that system has a goal that is maybe antithetical to your actual goals, those are the types of things that I teach Jules about. And then the same thing, right? There's little goofy online things that they'll use facial recognition and they put ears and stuff on people. We've talked about that too, where it goes wrong, and we talk about how and why that goes wrong. So if the ears end up on your eyes, we talk about like, ""Well, there's a system in there that there is an error, and that's how it screwed this up. It's not magic. It's a system."" So I think again, on the consumer side of it, I'm not trying to teach her to use these things yet, but I want her to be really aware of how they are. And again, it comes back to the way we treated science classrooms, that there's this social good, societal good for science literacy, that you can understand when this CDC says something and makes a recommendation, you understand at least the basics about the process of coming to those conclusions. You should understand at least the basics about how what you are seeing or who and what you're interacting with that come from machine learning and AI kind of thing, you should understand the role that those things play and their propensity for error. Because that's the other thing that comes up in my work. People assume the robots know what they're doing. People assume [crosstalk 00:36:26] smarter than they are because we have been culturally trained to believe that about them. My robots are often pretty dumb [crosstalk 00:36:33] really don't believe that about them at all. So that's the other side is to really be aware that they are limited, that the Jetsons' all-purpose robots or chat bots even are nowhere near close. So to treat them as if they are going to make a mistake all the time, because they are. You might not even notice it.",36,2,1,1,0,1,1,1,1,0,1,1
37,JM,Researcher,Researcher 1,"Yeah. That's a really interesting perspective, to treat our technologies with not just skepticism, but almost humanism, like they're going to make mistakes, right, and to see if we can see what those are and think critically. So one of the goals of our program, the goal is not to turn every kid into a computer scientist, right? The goal is to develop some sort of baseline critical data literacy, right, so that not only do they understand these concepts, but they can be critical consumers, as you put it, right, in their everyday lives and as they get older. So no matter who is designing these technologies, if they're consumers, they can feel like they can at least identify this as wrong and maybe say something about it, even if they're not the ones designing the technologies.",37,2,0,1,0,1,0,1,0,0,0,0
38,JM,Faculty,Michael,"Yeah. One that just comes to mind that didn't come up is self-driving car technology. And that is dangerous in a much more salient way, right? And I think getting people to understand, when I see a car and I look over, I evaluate what the person behind that wheel is attending to, right? Before I cross the street, I like to make sure that I see that person look at me so that I know that they're sensing me, right? So if and when it comes to be that I look over and there's nobody at that wheel, there really needs to be an acclimation to understanding, ""Okay, the situation is that there's a machine driving that car. How does it make mistakes?"" I know how people make mistakes, right? I know what it is. If they didn't look at me and I start to walk out and they just roll even at a red light, that could catch me. So I pay attention to that. What are the types of errors that machines make in that scenario are important, that we know that sometimes, it might not recognize a stop sign at all. People are typically better at it. Maybe not typically, but we learn to understand the types of errors that can be common in these systems, or even uncommon, if they're going to be catastrophic, and are aware enough in a way that we can respond in reasonable actions to it. I mean, right now, if I saw a driverless car, I would go nowhere near the street because they're prone to weird accidents that I don't understand right now. So I can't figure them out well enough to do it. But eventually, if they become commonplace, we'll have to know how that works.",38,2,1,1,0,0,1,0,0,0,0,0
39,JM,Researcher,Researcher 1,"Yeah. And that interaction between human and the self-driving car, the human and the technology, is really interesting. If you can't look at them in the eye, how do you interact with them to ensure to minimize risk, right? That's a whole other dimension of designing these technologies and testing them. And also-",39,2,1,1,0,0,1,1,0,0,0,0
40,JM,Faculty,Michael,"[crosstalk 00:39:37] I find really fascinating communicating those things. And that's the problem. The cars that get stuck at four-way stop signs because everybody else is rolling a little bit and they interpret that as going, that's a relatively simple fix. But that communication bit, right, that I glance at somebody and they know the that means I'm going to stop and you can go, that doesn't exist for self-driving cars. And electric vehicles who don't even make engine noises, right? So they don't communicate that they're coming. Those things are-",40,2,1,1,0,0,0,0,0,0,0,0
41,JM,Researcher,Researcher 1,"Yeah. I was thinking the scenarios are endless. And so we can't program for every possible scenario. A human can use their instinct and their gut reaction to respond to an unknown scenario, right? But I'm not sure what's a machine going to do.",41,2,1,1,0,1,0,0,0,0,0,0
42,JM,Faculty,Michael,Right. So [crosstalk 00:40:24]-,42,2,0,0,0,0,0,0,0,0,0,0
43,JM,Researcher,Researcher 1,"It'll relate it to some other data point that it has, and it can make that wrong decision.",43,2,1,1,0,0,1,0,0,0,0,1
44,JM,Faculty,Michael,"Yeah. Drones are another interesting one too, in that drones that just fly, they freak people out because they do not telegraph where they're going to go. So there's HCI design stuff that has them bank even though they don't need to so you can tell where it's planning to go, or orient itself forward so people can tell. Even knowing which is the front of the thing is important for a human to know to feel comfortable. And so again, I think both sides, on the design side, but on the consumer side, that we need to have this space of understanding of how these things work, in some cases, just for basic safety.",44,2,1,1,0,1,1,1,0,1,0,0
45,JM,Researcher,Researcher 1,"Yeah. Absolutely. All right. Thank you so much. This is so great. I mean, it's great to see you, but it's also just thank you for giving us your perspective. It's really helpful for our data and for the design of this program.",45,2,0,0,0,0,0,0,0,0,0,0
46,JM,Faculty,Michael,Yeah. Happy to help. Happy that you have Zoom to do most of your transcripts so your poor grad students don't have to scribble out everything.,46,2,0,0,0,0,0,0,0,0,0,0
47,JM,Researcher,Researcher 1,"I know. It works pretty well. I mean, we use Otter AI too. That works well, but it's nice just to have it be... I don't have to transfer it, download it. So that's great. Yeah. Thank you, Zoom, if you're listening.",47,2,1,0,0,0,0,0,0,0,0,0
48,JM,Faculty,Michael,Will this guy shut up or?,48,2,0,0,0,0,0,0,0,0,0,0
49,JM,Researcher,Researcher 1,"Yeah. it's not AI. It's a little person typing in my computer. Okay. All right. Thanks, Joe. Say hi to the family.",49,2,0,0,0,0,0,0,0,0,0,0
50,JM,Faculty,Michael,"I will. Yeah. You too. And I'm going to follow up. I want to chat with you about some of the other stuff too, so [crosstalk 00:41:57].",50,2,0,0,0,0,0,0,0,0,0,0
51,JM,Researcher,Researcher 1,Yeah. Definitely. [inaudible 00:41:58].,51,2,0,0,0,0,0,0,0,0,0,0
52,JM,Faculty,Michael,All right. Bye.,52,2,0,0,0,0,0,0,0,0,0,0
53,JM,Researcher,Researcher 1,Bye.,53,2,0,0,0,0,0,0,0,0,0,0
1,MAK,Researcher,Researcher 2,"All right, so we are here. We are interviewing Mariah Knowles. It is Monday, January 31, 2022. Hi Mariah, thank you so much for interviewing and volunteering to interview with us today. I'm just going to ask you a little bit of questions about your experience with AI and machine learning. And then at the end, we'll kind of pivot a little bit to ask some questions that are more directly related to our study and our work in our lab. So could you tell me a little bit about your professional background and your work history? And if any of that involves AI, that'd be a plus.",1,3,0,0,0,0,0,0,0,0,0,0
2,MAK,Grad Student,Whitney,"Well, as we said before we started recording I'm a tired, stressed grad student. I do a lot. I have a bajillion hats. I'm from Kentucky, before here and before that I lived in Georgia. In Kentucky, I got a Master's in Computer Science and a Master's in English. I worked at Fruit of the Loom, whose headquarters was in Bowling Green, Kentucky, where I was. And I did database stuff for them for six months. And that team, it was kind of rite of passage to accidentally lose the company a million dollars because they make enough that that's laughable. And we're just like, ""Holy shit, I'm going to get fired."" And they're like, ""No, no, no, we've all done it. Let's go fix this."" So I quit that job because I wanted to teach, and a full-time teaching position opened at the community college where I was an adjunct. So I taught for three years while I did my English masters and I moved here. So I do summer camps with kids and stuff, something I started doing in Kentucky that I still do here with [Wickedy 00:01:53] here. It was called VAMPY in Kentucky. I don't know what it is about making fun five letter acronym names for these things. So I work with Wickedy here and [Bedra 00:02:03] pre-college, doing stuff with high school students. The youngest I've done is fourth graders all the way up to 60 year old guy changing careers for the 12th time in the community college, teaching them how to program. Or last summer I was just fucking bored from the pandemics. Well, I get to pick the topics. I'm going to have fun with this. We made art in class, but we wrote code to generate art for us. And these kids from Korea are fucking phenomenal, just putting that out there. They blew us all away with the stuff they did. Let's see...",2,3,1,0,0,1,0,0,0,0,1,0
3,MAK,Researcher,Researcher 2,So I have a question really quick about Wickedy. You said that you have students from Korea. So is that remote that you guys are doing that or you had students within this area here in University that you see in-person?,3,3,0,0,0,0,0,0,0,0,0,0
4,MAK,Grad Student,Whitney,"Well, I'm here in Madison.",4,3,0,0,0,0,0,0,0,0,0,0
5,MAK,Researcher,Researcher 2,"I apologize, I knew that.",5,3,0,0,0,0,0,0,0,0,0,0
6,MAK,Grad Student,Whitney,"All good, there's too many schools. Summer 2019, it was in-person. Summer 2020 it wasn't held for the obvious reason. But because it wasn't held in 2020, we'd started doing during the semester some three Saturdays in a row camps instead of three weeks continuous. So I didn't make as much money that year, because I didn't have the... it pays a thousand a week, which is good money when you're trying to pay fucking rent over the summer and your [inaudible 00:03:34] doesn't get paid over the summer. So I taught instead 2020, I did remote. We were trying out a few different ways of running it. Right. And we kind of did some experiments with it and it was a class on... shoot, what the fuck was it called? Analysis Skills for College Success: Research and Data Analysis, something like that. It was essentially a research methods course for high schoolers. So they know that the word research doesn't mean Googling shit. It means thinking through things in a certain way, but it had to work no matter what major the student might go into. So I got to teach this really, really mixed methods, fun little three week camp thing to students drawing on the fact that I have a crazy, weird, mixed background and I continue doing weird mixed stuff. But all the offerings of that, every time I've done it, students the first time had fun. They were really attentive and stuff. Last time I had one student who actually did anything. And so students have just been increasingly burnt out from that. But summer '20, this most recent summer, we did it online. So I came into my office on Zoom and just was on Zoom for nine to three, but breaks, trying to mirror as much as we could of the in-person experience from the two years prior. It was better because students were a bit more captive. They are honors kids with rich parents, honestly. And they were excited. They wanted to go to this camp. They know it was canceled the previous year. They're big nerds. I never went to those camps, but I'm glad to teach the kids who go to those camp. So we've adapted with the pandemic with that. But it's all just various kinds of teaching. That's my one-line bio that I teach kids and adults how to code which is the [crosstalk 00:05:38].
",6,3,0,0,0,0,0,0,0,0,1,0
7,MAK,Researcher,Researcher 2,That's awesome. I mean we need more people to understand coding in general. So I think it's great that you do that work. Has any of the work you've done with those type of groups ever bridged into AI before or machine learning?,7,3,0,0,0,0,0,0,0,0,1,0
8,MAK,Grad Student,Whitney,"So I take this kind of data science approach to Python, where I have the students collect data on whatever they want. I've had a student, one of my favorites honestly, was someone analyzed Reddit posts about bourbon. And it was such a great project because he got to talk to his dad about it because it was kids in Kentucky. And there this huge value around family and stuff. So I'm like, ""Yeah, pick something that you can talk to your friends and family about. I don't want you to come into this completely alone. It's good to have someone who knows nothing about coding, but knows about bourbon to fucking talk to."" So this guy gets to nerd out with his dad for this whole project, just talking about bourbon and why people were saying certain things in these posts and what they meant. So he was just doing fucking the same thing that you guys are going to be doing with this transcript, analyzing the codes and themes and explaining why they matter. I don't know a fucking thing about bourbon. I used to live in Bardstown, the bourbon capital of the world, but I don't drink. So he did that, but he used Python after he kind of came up with his codes, used Python to go through and scrape it to label the data and then count it, and then say why it matter. And it's these 50 lines of code that he's put a lot of thought into it and can reason about the data that comes out of it. So that's the closest that I've gotten to doing AI stuff with coding because I tend to intro-level stuff. Here at UW, I have taught a data ethic course. So that's not about coding [crosstalk 00:08:09]-",8,3,1,0,0,1,0,0,0,0,1,1
9,MAK,Researcher,Researcher 2,But that's important.,9,3,0,0,0,0,0,0,0,0,0,0
10,MAK,Grad Student,Whitney,"Yes, it's a data ethics course. We talk about AI a fuck ton. So besides camps, teaching people how to code, I'm a PA right now with YJ Kim here at the Wisconsin Center for Ed Research and I know David Shaffer. And through him I've heard about goal like everyone else in this community. So I hear about University all the time. But where was I going? So I have a PA ship here. I've TAed here, TA for code and power a lot with Dr. Royston and that's kind of your classic critical theory approach to AI and a lot of... but like meritocracy, Google image search results for black women showing images of gorillas, those kinds of cases. Yeah, it's kind of fucked up. So talk about how code and power get gets embedded. And it's very critical around institutions and getting students to think about that stuff and learn about implicit biases and things like that. We actually have them take the implicit bias test and then think about the limitations of that test and try and reason about what data says. But-",10,3,1,0,0,0,1,1,0,0,1,0
11,MAK,Researcher,Researcher 2,"[crosstalk 00:09:29]- sorry, keep going, you're on a roll.",11,3,0,0,0,0,0,0,0,0,0,0
12,MAK,Grad Student,Whitney,"All right, so the data ethics course though, is a newer course. I was a TA who helped to design that course. Right before we did that, I interviewed. I was on [inaudible 00:09:44]. I interviewed 10 teachers of AI ethics courses and just talked to them about how they teach. And then conveniently after I did that, we then designed it [crosstalk 00:09:54]",12,3,0,0,0,0,1,1,0,0,0,0
13,MAK,Researcher,Researcher 2,What type of activities did you guys do around data ethics and ethics involving AI or machine learning?,13,3,0,0,0,0,1,0,0,0,0,0
14,MAK,Grad Student,Whitney,A lot of writing. It's [crosstalk 00:10:03],14,3,0,0,0,0,0,0,0,0,0,0
15,MAK,Researcher,Researcher 2,A lot of writing. ,15,3,0,0,0,0,0,0,0,0,0,0
16,MAK,Grad Student,Whitney,"So the data ethics course is a combi credit. There's a combi version and a non-combi version. When I taught it over summer, it was eight weeks online, a hundred-ish students, some combi, some non-combi. I had two TAs and also I was the TA for it twice after. So we designed it. I was a TA, I was a TA, and then I taught it and I'm praying to teach it again this summer. But it's a lot of writing because it's a big combi component. And Alan Ruble was the instructor who made it, who's my advisor. And when teachers design courses, they use the pedagogy they were taught with is the most number one thing I learned from talking with all these AI ethics teachers and all these different backgrounds is they might have similar motivation, similar goals, similar big picture aims where all we give a shit about AI ethics. But then what they actually do in the classroom is just what they were taught with. And I'm just like, ""Okay, that's not very critical of you, but good."" But it's good to see all these things and these different views besides my own too because again, I teach the way that I've been teaching. I teach drawing on my English background, not my computer science background, even though I teach computer science style courses because in English, they have you take pedagogy classes. So I'm drawing on that. I have weekly journals that I make my students do because I found that useful in a class I took. It's like, ""I like that so I'm going to make my students do it."" But I've adapted to make sense for coding. So in that class, it's a lot of writing and reading because that's what the instructor who designed did a lot because he's a philosopher. And in philosophy you do a lot of reading and writing. I added in because I like them the studio discussions. The students read an article or watch... do some kind of prep for the discussion. They meet with their group on Microsoft Teams or similar tool. They record it. They post the recording to the discussion board and then they watch X number of recordings and respond to them. I did a pre-post set up for that for the course where they read the first and second house at the time of the Pasco PD case that is happening in Florida. Pasco police department made an algorithm to predict who would commit crime or would be likely offenders and then went out and targeted people based on it. It's currently going under investigation by the Department of Justice, which means you're going to have a lot of fact finding about this case. So that's a good case to know when you're teaching data ethics.",16,3,1,0,0,1,1,1,1,0,1,0
17,MAK,Researcher,Researcher 2,"I did not know about that case, so I appreciate you telling me that.",17,3,0,0,0,0,0,0,0,0,0,0
18,MAK,Grad Student,Whitney,"I had them look at that pre-post so I could see kind of how they changed. I never actually went and looked at it. But I have the data and the recordings from of those student discussions. I had a cop in the class, so I paid a lot of attention to that student's change to make sure there were no red flags there. Pre, they did a lot of deflecting to their own police department, like, ""Talk about how well they do things."" Well, you're not talking about this case. This is the case under question, and you're deflecting from it. And at the end, they stayed on topic. And I was like, well, that's a pretty fucking good change. I'll take that as a huge win. Good, you're sticking with the case that we're talking about and thinking through its issues. ",18,3,0,0,0,0,0,0,0,0,0,0
19,MAK,Researcher,Researcher 2,"That is important. Kind of flipping it, so taking what you know about data ethics and what you've done in your courses, what type of activities do you think would be acceptable for young children? Thinking about maybe older elementary school or young middle school, would you suggest or would you maybe do with these to kind get them to think about data, data science, ethics, ethics of AI and all of that?",19,3,0,0,0,0,1,1,0,0,0,0
20,MAK,Grad Student,Whitney,"I can only steal ideas for that because I usually don't work with kids that young. I try to avoid compulsory schooling age stuff because I'm just like there's so much more to consider and so many more standards you have to meet, which is why summer camps are good because you can do whatever you want within reason. But there is this book. I wish this had the fun cover version of it. It's Living in data by Jer Thorp. And he's an installation artist. It's fascinating fucking reading. You should really find a recording of it if he has any book talks. It's the same stuff in the book. But he says it and it has pictures.He's an installation artist. Him and his group of his grad students, one thing they did is they did this installation in New York, right on a city street. And it's this heart. You look at it, it's a heart. But it's all these pipes that are taller or shorter or whatever. It makes this heart shape. And people are like, ""Cool, we'll take selfies in front of it."" And they go look at it closer. And it's a bar chart. And it labels on there where the population in New York has come from, from around the world.So then he sees people taking selfies with the bar, finding where their family is from. And then they've caught two people having weddings in front of it. And he's like, ""This is the world's only bar chart that has also been a wedding venue."" And it's just fascinating. He has all these different ways of getting people to experience data differently as a way to get out of their head and think about things in a really cool way. So I asked what his views on data ethics were. He said, ""Well, I have a 300 page answer to it. It's called the book."" So I had to get the book and fuck, there was another one. There is this fun activity that I saw someone do and post results of where they had real young kids. I can't remember what age he said, but it had them draw what they thought Alexa looks like. Just take this disembodied voice that we as adults might take for granted and say, ""Well, kids, how do you think this looks?"" Something else that Jer Thorp did is working with kids, I just remembered this, is he had the students draw on big printouts of maps of their city, things that were important to them or things that they had noticed, like where are broken sidewalks? Where is the good place to get food? All these things that have meaning to the kids as they've experienced their own city. And they take this giant kid map and overlay it on old voting things. And you can see, well, here's the red lining that happened. Here's the history that you can see in the voting record aligning from forever ago with what you could see in your day to day life. And it was just this fascinating moment of overlaying and you go, ""Oh fuck."" You don't know that that's what you're drawing, but it's what you're drawing. And then they overlay it. It's like, well, there you go. This data has all a long history and you can see it kids. So that I thought was really cool. ",20,3,1,0,0,1,1,1,0,0,1,0
21,MAK,Researcher,Researcher 2,"That is showing them something that they've been experiencing for so long, but they've never really made the connection between the two, it sounds like what you're saying. That's really interesting. So I know you deal a lot with data science and maybe don't always branch into AI, but if somebody was going to come up a few for maybe you walking on the street, how would you define AI?",21,0,0,0,0,0,0,0,0,0,0,0
22,MAK,Grad Student,Whitney,"I use AI in a broad sense because people tend to use it in a broad sense. They don't know what the fuck it actually means. It also doesn't need to have... The reason why I define it the way I do, I'll start here and I'll go back to how I actually define it. There can be an AI moral case that has no AI actually in it, as long as the people in the case think that the system exists and that it has AI. And that's all that matters is they attribute morally relevant qualities to the system. And they attribute an AI label to the system, whether it exists or not. So they'd be like, ""Yeah, we're going to do this because it's faster."" Well, that's a morally relevant quality they're attributing to it, that they value speed and stuff. So they attribute that to it and that's what they reason about it. My advisor has this awesome paper called agency laundry, which is about the moment when... there's a train going by in the background. The moment when people go, ""No, it's not my fault. I didn't make the decision. The program made the decision."" He's like well no, you're laundering your agency into the system. And that's bad for X, X, X reason. And he walks through a few cases and those cases are all about algorithms it turns out. But the moral issue at heart is not about algorithms. It's the same moral issues we've had for a fucking long time. Nothing is new under the sun. One of the people I interviewed talked about how in her class, she has to talk to the students about how we have these questions about AI. It's new. We're not trying to regulate it. We're not trying to deal with it. We had the same fucking questions when the internet came up. We had the same questions when VHS tapes came up. And now those things kind of seem settled in retrospect. AI is just the thing that's new in question raising right now. It's really this longer huge tradition of technology raising questions is actually what I think is important. And so I use it in a broad sense. I just might just say it's an intelligent system and leave it at that. Whether it actually exists or not, whether it's actually humans on the other end or not, to me, it doesn't matter. It matters how people think about the system and whether they call it AI, fuck, sure, that's AI. ",22,3,1,0,0,1,0,0,0,0,1,0
23,MAK,Researcher,Researcher 2,"Yeah, it's the perception from the human standpoint is what you're kind of getting at. I think I like that to definition. That's great. So kind of same thing, but with machine learning. So if somebody came up to you, how would you define machine learning?",23,3,0,0,0,0,0,0,0,0,0,0
24,MAK,Grad Student,Whitney,"It's the same bucket. If it's a random person on the street, one, why the fuck are they talking to you about it, machine learning. Usually when we have that discussion, the technical discussion of AI versus machine learning, machine learning might be seen as a sub-case of AI a broad category and machine learning being a set of particular techniques for how we optimize AI. So having the machine learn from data, again, a big metaphor about comparing the human brain to computers, which is a bad thing to do for your own wellbeing. We aren't machines. Machines don't think like us. We call it... this is from Ellen Ullman's Close to the Machine, fantastic book. It's a memoir. I have it with me. And she talks about how we call it the machine. We call it a memory, but it's not right. So one, I don't like the name machine learning when people use it too much to compare to how babies. I'm like no, fuck, that's not it. But a way of optimizing around data, and so it's just really cool statistics. And it's really close to data science, where you're like you have data, but what meaning can you get out of this for a social reason? What's blind on this? I don't really care about the difference between, but then AI a more general label. If I have a bunch of if/then statements. Is that AI? Well, yeah, it used to be. We were trying to solve like chess originally or checkers. We had some pretty simple sequence of steps because that's how we thought the human brain worked or at least that area thought things worked. So I don't know. I use them broadly because I don't think the specifics matter. It's when we get to the ethics side of things.",24,3,0,0,0,0,0,0,0,0,1,1
25,MAK,Researcher,Researcher 2,"No that's great, thank you. So this might go more into some of your ethics background, but how do some advances in AI or machine learning help humans?",25,3,1,0,0,0,0,0,0,0,0,0
26,MAK,Grad Student,Whitney,"This we're getting to the... you know as a tired, stressed grad student, you can stare at something so much that you actually stop seeing it and your eyes blur over? That's where I'm at. I looked at these questions beforehand. I knew this one was going to be my wall. Fuck, I don't know. It's hard to say anymore. I've looked at things too much. I've over-theorized it.",26,3,0,0,0,0,0,0,0,0,0,0
27,MAK,Researcher,Researcher 2,"Do you have just maybe one example you could give, if that's maybe a little bit easier to pinpoint one specific thing than kind of thinking of the vast majority of them?",27,3,0,0,0,0,0,0,0,0,0,0
28,MAK,Grad Student,Whitney,One specific good that AI has done or might do.,28,3,0,0,0,0,0,0,0,0,0,0
29,MAK,Researcher,Researcher 2,"You could also think about on the reverse of it, how AI has harmed us or harmed humans.",29,3,0,0,0,0,1,0,0,0,0,0
30,MAK,Grad Student,Whitney,I'm going to stick with at the help first because that's the hard part. And I know my guys would be mad at me if I skipped the hard part.,30,3,0,0,0,0,0,0,0,0,0,0
31,MAK,Researcher,Researcher 2,Okay.,31,3,0,0,0,0,0,0,0,0,0,0
32,MAK,Grad Student,Whitney,"Okay, here's how I'm going to think about it. In the Pasco case, I'll use that example for both because it's good to ground myself in a fucking case so I don't go crazy. Looking at that case and thinking about how I speak to my students about AI ethics, which I speak to them the way I do because of my interviews of the 10 people I had. And they all had different views on things. It's like, well, how can I do this in a way that's kind of in agreement with all these different views, knowing that again, the course is going to be kind of pigeonholed the way that Allan did it. How can I introduce to things? And one of the things that people talk about a lot in the ethics, when you're giving people who aren't ethicists, they're just a fucking programmer. You want them to think through things, is the stake stakeholders model. We just ask what's at stake? But remember week one, I'm doing a pre-assignment where they don't have any understanding what I'm talking about. So I can't use the word stakes because they might take that in a too narrow sense. And so I say to them is, ""In this case, what are the things that we want to get right? Yes, there's this really shitty thing that happened in Florida. The article ends on a very sad note, but there are things that we're trying to get as humans in this. All the bad things that happened, we wanted those not to go that way, but we don't want to just burn out everything to happen because again, we're trying to get at things. So I have the students focus on this shared human endeavor of things we try to get right. And so in that case, the police department did a shitty thing, but they're trying to get right reducing crime. They're trying to right serving their community's interest. They're trying to get right distributing their resources well. Whether they actually got those things right in a way that still abides by fair terms is also preparation is a whole nother story, and we'll let the Department of Justice... we'll see what their investigation finds. But it has a lot of promise. And I try not to focus on promise because coming into viewing AI from the point of view of promise and predictions and it's... you mention advancements. My first instinct there is no, let's not talk about advancements first. There's a huge history of technology here. There's a huge history of institutions. Policing hasn't always been the best and still isn't always the best. And so if something's being embedded there, we better really look at that history. We can't look to advancement and promises of AI as a way to ignore how we got here. So I tried to avoid that framing. But we are trying to use it to get at good things. So I can't say what is actually done well, but I can say we're generally trying to get at good values with it. So let's get that right, kind of be my call to action. And that involves also looking at the history of how we get to places. Anna Hoffman, AI ethics researcher from Northwest, I can't remember where she's from, but she's awesome. You should look up her work. I have the idea of let's not talk about entry points from promises, or futures, or potential of AI because of a talk she had. She's like I'm in this pandemic and I'm tired and I'm sad. I'm a tired, stressed professor and I'm tired of looking at AI. So I'm going to come at this in a fun way, which is what does AI look like if we start from the position of infinite love for trans people? Let's just take a fundamentally different approach to how we might think about AI. And it was a really fucking fun talk. But one of the things is looking at the medias around promises of AI and what gets left out when we focus too much on promises. So I'm doubly rambling at this point, but the things we're trying to get right with AI, it's good to enumerate those. And we kind of reground ourselves in the value of what we're actually trying to do. And a lot of harms come out when we lose track of that and focus too much on it can just solve a lot of these things. When it's put into context that it ought not be in, harms can come up. When it's put into context too quickly, harms can come up. So I'm going to stop rambling and drink water.
",32,3,1,0,0,1,1,1,1,0,1,0
33,MAK,Researcher,Researcher 2,"Yeah, go for it. I know you've talked about harms and you've talked about the Pasco case in Florida. So I guess we could talk how has it harmed us and who are the populations that it is potentially harming, AI or machine learning?",33,3,0,0,0,0,1,0,0,0,0,0
34,MAK,Grad Student,Whitney,"I'm going to bring up... I had this already. Nope, that's my writing sample. I have just been writing all this down for applications to places. And I'm at the point where if I write something down, I'm going to forget it immediately, which is the opposite problem because now I'm not constantly thinking about it. So AI or AI ethics is a bundle of ethical issues. And so thinking about populations depends on your entry point to thinking what AI ethics is. And so I'm just reading my notes, honestly. We can't violate public trust, is kind of one thing. That comes up a lot in the discussions around autonomous vehicles, that we want to have autonomous vehicles for X, Y, Z reason. But in order for that to happen, the public kind of has to trust in the system. We have to agree. We have to know that it's not going to run over black people more than white people. If it gets down to that moment, we have to know that it isn't going to confuse us, not know that a cyclist is there or the actual case of where Uber hit a woman. I don't know if it was Uber or not, but there was an autonomous vehicle that hit a woman because she jaywalked. Well, jaywalking should result in a fine, if that, not in death from a car that didn't see you. The idea that the road is owned by cars is a relatively new one in human history. Roads were owned by the people walking on them. And so that one, public needs trust in it and that we don't want to violate that trust. So in a way we can harm everyone when we release things too early in that sense or have things that create harms. Also, the people who are literally hit by the car, I think get harmed the most. Let's see, there's a lot of talk around misinformation being amplified on social media. And there's also talk on certain things when you have newsfeeds, like Facebook, that put the things at the top that they think you want to see or that they want you to see. That's in their benefit for you to see. Or TikTok, as fun as it is to find your own extremely niche set of friends on TikTok, and ridiculously fast, what's getting left out? Who's getting pushed down? And so there's a lot of harms that come up when misinformation gets brought up to the top and there's a lot of harms that get caused when certain communities are just completely pushed down and systematically given lower scores in the algorithm. And so there's a lot of talk on TikTok around trans communities and people of color, people who don't look pretty getting rated lower by the algorithm, so they're not going to have as much of a viewership. And so when your money is tied to being a content creator, it sucks. There's also the whole thing that if you're queer and online, you are subject to harassment. You always have to have a few backup accounts because one of them is going to get blocked out because people are going to mass... people who don't like you are going to mass report everything you do until you get flagged by the algorithm as bad and systematically have your account removed, even though you didn't do anything wrong. That happens all the fucking times with trans content creators. There's like all these, ""Hey, my thing got deleted again."" And it's just happens. So there's a lot of algorithms that play a part in that. But also the algorithm isn't separate from the system of humans interacting with it. So fuck, I talked a long list, when it's applied in places like policing, compulsory education, medicine, et cetera. Those already have a lot of scrutiny on them, legal and public scrutiny on them. So it's very important that we get AI right in those cases because we're constantly looking at them for whatever reason. Reason might be that we have a lot of public scrutiny on policing and education because we want a fair and just society. And we see those institutions that are very important to the function of a fair and just society. So if we fuck up there at all, everyone pays attention. Work, AI changes the nature of work, and when the nature of work changes, some people are benefited and some people are completely displaced.",34,3,1,1,0,1,1,1,1,1,1,0
35,MAK,Researcher,Researcher 2,That's a really good one.,35,3,0,0,0,0,0,0,0,0,0,0
36,MAK,Grad Student,Whitney, it's not just bias is the takeaway.,36,3,0,0,0,0,1,0,0,0,0,0
37,MAK,Researcher,Researcher 2,That's a really good one.,37,3,0,0,0,0,0,0,0,0,0,0
38,MAK,Grad Student,Whitney,"AI also has the thing with we tend to forget about the labor that goes into it. It's the data, the people who are labeling the data, moderators whose job is to look at things flagged as potentially bad, that takes a huge toll in their mental health. There's all the Amazon Turk stories, the people who are tied to these really weird and very strict work schedules be able to get any work out of Amazon Turk to be able to feed their families. Then in the agency laundering paper, Allan also talks about Uber and it's algorithm uses for saying who's going to get what and how it distributes jobs. So that's the algorithm telling you what to do in terms of what work you can even get. And so when the nature of work changes, some people get benefited and some people get very displaced. And the government's aware of this. There was a bill proposed, I don't know where it's gone, but there's the AI jobs bill or something that says yes, people are going to get displaced by AI. So let's use the government money to try and help that where it can by offering training, et cetera. I have so many people who I teach in the community college who come in, who have changed jobs so many times. And it's just not from AI, just technology advancing. ",38,3,0,0,0,0,0,0,0,0,0,0
39,MAK,Researcher,Researcher 2,"Technology in general.
",39,3,1,0,0,1,1,1,0,0,1,0
40,MAK,Grad Student,Whitney,"I met a guy in person, he used to help make movies. He's like, ""yeah, my job used to take a team. And now it's just one dude at one program."" And so he's changing careers into learning how to code, and so there's that. Consumers might not be aware that they're interacting with AI when they're shopping online, except it might not be aware to the extent that they are and that can have harms to principles like consent, being aware enough of what's going on to be able to fully make a decision and not doing that you're interacting with AI or that visual. Invisible changes are happening on the screen behind the scenes. It might be bad depending on that context. And it's fucking hard to regulate AI.",40,3,1,0,0,1,1,1,0,0,1,0
41,MAK,Researcher,Researcher 2,"Yeah, nobody really wants to do it, do they? Those are great. Thank you so much for listing all of those. Some of those I had never really even thought of, although they make a lot of sense, just people being displaced from work from all the advancements of AI and how we're going to deal with that.",41,3,0,1,0,0,0,1,0,0,0,0
42,MAK,Grad Student,Whitney,It's not just bias is the takeaway.,42,3,0,0,0,0,0,0,0,0,0,0
43,MAK,Researcher,Researcher 2,"Yes, exactly. There's a lot of other things that go into it. So we're going to pivot a little bit more. I know you don't necessarily always work with youth, but what are your thoughts about youth learning about machine learning or learning about algorithms and AI?
",43,3,0,0,0,0,0,0,0,0,1,0
44,MAK,Grad Student,Whitney,"I have complicated feelings. So what does heavy break have to say the purpose of education is? I'm not going to do that. I've seen arguments. There's a lot of focus on algorithmic look where people are able to use algorithms and stuff and understand what they mean, et cetera. And the counterargument is well, should we teach that? What's the purpose in this? Who's pushing for that? And I've seen arguments that companies like Google or whatever want there to be more programmers because if there's more programmers in the market, they can pay their own programmers less. It's easier to fire someone if it's easier to hire their replacement. So if everyone knows how to do it's very easy to take advantage of those people. They're easy to find people who are willing to do sketchy things or enough people to have in a company, they can break apart the sketchy thing into a bunch of non-sketchy pieces. So there's ways to use that for harm, just the fact that the market has more people trained in it who understand it. When it comes to understanding and positive side of it, not just the super fucked up sad side, positive side of it there's the people understanding what data means. Something that I try and focus on in my research and data analysis teaching those kids is helping them think through data can only represent this much. Or data has these limitations. Or data's narrow in this sense, blah, blah, blah, blah, blah. It's of the teachers that I interviewed, this kind of falls under the algorithms ought to be valid side of things. There's the when we teach AI ethics, we're getting at professional ethics. There's Kazuya Street, teaching students to reason about present cases from past cases. There's being critical of institutions and understanding they have social histories of things, blah, blah, blah. But one of the views that came up in my interviews was algorithms ought to be valid. They ought to map to reality in the daily work on should map to reality in some sense. And so understanding how that mapping works, I think is important. There's this older paper called Invisible Grammarian talking about the red squiggle underlines of Microsoft Word. And the computer has an ethos to it. Anything my computer tells me, I inherently trust because it has the ethos of science to back it up. So when my computer constantly tells me I'm doing grammar wrong, what work does that put on the grammar teacher or the English teacher? And so my favorite thing about that paper is that it gives advice of your first activities should be taking your students through the settings. Undermining the ethos of the computer's default settings have and let them know that these are just choices because the grammar that Microsoft Word at the time of the paper used for telling you that you were wrong was 1890s Turgent businessman grammar, a particular kind of properness. And we know that's wrong. That's not how you ought to express yourself in every situation. And in most situations not. Also language fucking changes. And so I lost track of this question. So helping students understand kind of peeling back the black box a bit, helping them understand how these algorithms work and so on so they can make their decisions themselves so when they interact with machines, they don't give that much trust in the machine. They're able to blame the machine more in themselves less. Something that I see when I work with students and they run into problems, they blame themselves. They're like, ""No, it's computer's fucking problem. Show me the screenshot. It's computer's problem. Here you go. You didn't do anything wrong kid."" And it kind of gives them more agency to kind of be in control of how they use technologies, how they might buy and consume them, how they might reason politically about them, and so on. But when we're talking about AI systems, these big machine learning systems, one person I interviewed said this really great quote about how he's not going to go and buy a big machine learning system off the shelf. The consumers of those systems are large institutions. It's not him. It's not the everyday people. They aren't the target audience of machine learning systems. They are the target data of machine learning systems and knowing that kind of helps you make some decisions in life around where you want to put your trust.",44,3,0,1,0,1,1,1,1,1,1,1
45,MAK,Researcher,Researcher 2,"That's great, that's a good perspective. So what do you think about youth learning about the ethical issues of AI?",45,3,0,0,0,0,1,1,0,0,1,0
46,MAK,Grad Student,Whitney,"I know that there's a K12 curriculum that someone's made for AI ethics. And so I just try to defer to that because I don't want to collect K12 kids. It looks legit. They break it down in a way that's not just bias. So that passes my muster of a lot of people, a lot of well meaning allies who are sometimes the most dangerous people, go jump to bias and go no further, which is why I tried to bring up all of these examples that weren't bias. So there's this K12 AI ethics curriculum somewhere. I think it's AI K12 or something. It does a good job of helping students see things like it's a computer. It has sensors. What's the biology of the machine in a sense. It has these parts to it, something that students might not have ever thought about. One of my first activities I did when I taught CIT105, which was Intro to Computers for people who had never touched a computer in their lives, which was a good percentage of my students, the first thing I did is I would have a video of cats, just like a kitten livestream playing on the projector as they walked in, nice calming activity. And then once we got started, I said, ""Okay, tell me every piece of technology between these kittens and us."" And it's just illuminating seeing there's this, there's this part, and having them just name all the parts, just giving them permission to sit there and name the parts, I think, is important. Just kind of peel back that curtain and take things less. They start with letting students know there're sensors. It makes decisions in these ways. Data's collected in this way. It's reasoned about in this way. Problems come up in this way, and blah, blah, blah. They spell it out very well and they have a nice breakdown of curriculum. I'm like this looks fine to me and I have to trust them because I don't know a fuck at all about K12.",46,3,0,0,0,1,1,1,0,0,1,1
47,MAK,Researcher,Researcher 2,"Yes, venturing indicates well is a different story. So what age do you think students or young people should start learning about AI and machine learning?",47,3,0,0,0,0,0,0,0,0,1,0
48,MAK,Grad Student,Whitney,"AI ain't the thing. Episode one of Halt and Catch Fire, which I haven't able to keep watching because there's too much drama for my tired, stressed out graduate self to keep watching, first episode of Halt and Catch Fire one of the main characters goes, ""Computers aren't the thing, the thing that get us to the thing."" I think the more important aim to get isn't AI or machine learning in itself, but that longer tradition of humans having a history of the technology that raises questions. Here's the one we have right now that raises questions. And in 10 years it will be a different thing or go by a different name. NFTs, the idea for that is at least as old as the 1980s. All this news about that, the idea of cryptocurrencies, this is an old thing of using computers and global networks to undermine how money itself works just for the fun of undermining how money itself works. Ellen Ullman's getting close to the machine. I was reading it again recently. I'm like, ""God, this sounds like all these fucking NFT bros now. It just sounds exactly like them, but it's talking about the same idea from the 1980s going by a different name. These things are always going to come up. They're always going to be around. There's always going to be question raising technology. So what do we do about it? How do we think about it? And I don't have good meat answers for that other than it's not just AI. So AI is the thing, but it's not the thing. It's not the thing. It's the thing that gets us to the thing if we open up. But it's good fun present activities. It's good to have students work with stuff they're familiar with, least as an entry point. They understand livestream of cats and they don't think about all the pieces in between it. So I use it as an entry point. Having kids draw Alexa takes something they're familiar with in a sense, but opens it up. So I'm fine starting with it. But it can't be the end all, be all, whatever the thing is that we're getting at. ",48,3,1,0,0,0,0,0,0,0,1,0
49,MAK,Researcher,Researcher 2,"No, that's great. I understand that because we do have a past history. And if you look at that, it is repeating itself in manners when you think about the questioning and the trusting of the technology.",49,3,0,0,0,0,0,0,1,1,0,0
50,MAK,Grad Student,Whitney,"Also, VHS systems, I think kids... all technology is fun.",50,3,0,0,0,0,0,0,0,0,0,0
51,MAK,Researcher,Researcher 2,It is fun.,51,3,0,0,0,0,0,0,0,0,0,0
52,MAK,Grad Student,Whitney,"Humans are drawn towards ruins, like ruined cities. I have this book on ruins and I'm reading it. It's fascinating to me about why we're attracted to all broken things. I'm like, ""That's cool.""",52,3,0,0,0,0,0,0,0,0,0,0
53,MAK,Researcher,Researcher 2,It is cool.,53,3,0,0,0,0,0,0,0,0,0,0
54,MAK,Grad Student,Whitney,"I see the same thing for old discarded technologies, why museums and bones are fun and it's fun to go to those things. I'm like yeah, let' bring some of that in while we're talking about AI too because it's fun.",54,3,0,0,0,0,0,0,0,0,0,0
55,MAK,Researcher,Researcher 2,"It is, it's interesting to see where we've come from and how far we've come and just looking at the past. That's great. I think that we've covered most of the questions on our protocol. Is there anything else that you would like to add or have any questions for me?",55,3,0,0,0,0,0,0,0,0,0,0
56,MAK,Grad Student,Whitney,No.,56,3,0,0,0,0,0,0,0,0,0,0
57,MAK,Researcher,Researcher 2,That's okay.,57,3,0,0,0,0,0,0,0,0,0,0
58,MAK,Grad Student,Whitney,"I can't think of anything. I'll leave it at that. I think I've just rambled on the exact same points over and over because it's what I have that I've been thinking about. My very vague dissertation idea, which I need to make not vague soon because I have to propose soon, is how ought we teach AI ethics. But I'm focusing at the adult learning level.",58,3,0,0,0,0,0,1,0,0,0,0
59,MAK,Researcher,Researcher 2,"Yes, not K12 learning.",59,3,0,0,0,0,0,0,0,0,0,0
60,MAK,Grad Student,Whitney,"Not K12, specifically avoiding K12 because that gets into too much of ed departments and my department is in information science. So I focus more at the adult learning level just for my own wellbeing that I can assume that everyone in my class is a moral actor. When you're dealing with kids and you're doing philosophy, it gets weird because are they moral actors or moral patients? Moral patients, anything that's treated morally higher than an everyday object, like this old doorknob I have, which it's a whole story here. But I think this is cool on my desk, but it's still a fucking door knob. But a Bible might be held higher than this or a US flag. We don't want to step on it. Or we hold these things to some revere. So those are moral patients because we protect them more than every other kind of object. And kids are sometimes treated as moral patients in philosophy and not really moral agents. And it kind of gets weird. I'm like I'm just going to avoid that because one, the philosophy on it is kind of... I don't want to deal with it. Also, I'm not that much of a philosopher. I'm a qualitative researcher who knows a lot of other stuff. So I avoid talking to kids because I talk with the adults on purpose so I can just... yes, they are moral agents, let's move on. ",60,3,0,0,0,0,0,0,0,0,0,0
61,MAK,Researcher,Researcher 2,"Yeah, I mean, that's fine. It's important to have everybody be critical consumers of digital information, not just children. Adults need to be critical consumers as well and understand the ethics behind it. So I think you've talked a lot about what you think is important about teaching ethics throughout our interview. So I don't know if I need to ask you anymore, unless there's anything else that you want to really hone into that you don't think you've expressed enough.",61,3,0,0,0,0,0,1,0,0,0,0
62,MAK,Grad Student,Whitney,"I've worked with a lot of adults who know almost nothing about technology. And I know that we're talking about AI. One of the first things you want to do in a class is help the students know what the fuck you're talking about to the extent that you need to know for the class that you have. And I've worked with a lot of adults who just don't use... they're new to all of this. And trying to get them to let's say how like someone who makes AI understanding should not be the goal because one, it's not going to happen and two, it's not going to help them unless their goal is to go on and write those things and that's their dream. But they don't need to know all of it. And it's easy when we're planning these courses or whatnot for adult populations to forget that people don't know as much as us or the students that we're used to working with. So that's why I like having the very wide mix of student populations I've worked because it reminds me that everyone is different in coming in. They know more than me. They're 60 years old. They've lived a whole fucking life. They've lived three times my life, or twice now, fuck I'm almost 30, not 20 anymore. They do know more than me. And I only know this bit. And so it's humbling to try and draw on what they already know that isn't around technology. And it's really eye opening and stuff. So just it's an easy thing to forget that I try to remind myself of because it's a beautiful thing and I like it. I like finding beauty in things, so that's all I got. ",62,3,0,0,0,1,0,0,0,0,0,0
63,MAK,Researcher,Researcher 2,"It is a beautiful thing. No, that's wonderful. I appreciate that. Well, thank you so much for volunteering to interview us. We got a lot of good information, so I really appreciate it. I think you are the only person that has the more data ethics side of it. So we definitely appreciate your viewpoint about everything. And if you have any questions, you can feel free to reach out. You have my email. So at any point...",63,3,0,0,0,0,1,0,0,0,0,0
64,MAK,Grad Student,Whitney,I do have questions after the recording though.,64,3,0,0,0,0,0,0,0,0,0,0
65,MAK,Researcher,Researcher 2,"Okay, let me stop it.",65,3,0,0,0,0,0,0,0,0,0,0
1,MS,Researcher,Researcher 2,"Recording. All right. Today is... Sorry, I froze. Friday, February 4, 2022, and we are here with Mitch and we are going to be interviewing today about AI. Mitch, could you tell me a little bit about your professional background and work history?
",1,4,0,0,0,0,0,0,0,0,0,0
2,MS,Faculty,Chad,"Sure. I'm currently a professor of practice in the school of computing at University. I'm part of the instructional faculty, but I am not a career educator. Came to University just two years ago actually, having left a career in industry, a long, long career in industry. In industry, I started my career with early stage, venture backed startup companies, and I focused on helping to grow them into sustainable businesses, and then my last gig in industry before coming to University was serving as the chief technology officer at Morningstar, which is the financial services company based in Chicago. Morningstar is definitely not a startup company. It's been around for well over 35 years. It's got a market cap of probably 13, 14 billion dollars, annual revenue of one and a half billion dollars, so a pretty big size company, but I got to Morningstar by way of an acquisition. They acquire a small venture back startup company that I was with.",2,4,0,0,0,0,0,0,0,0,1,0
3,MS,Researcher,Researcher 2,"Wow. That's interesting. I've actually heard of Morningstar. I grew up in the suburbs of Chicago, so I'm familiar with-",3,4,0,0,0,0,0,0,0,0,0,0
4,MS,Faculty,Chad,"Oh, sure. Yeah.",4,4,0,0,0,0,0,0,0,0,0,0
5,MS,Researcher,Researcher 2,... who they are. Do you have any experience through... I know you said you had multiple jobs in industry and now you're in the computer science department working with AI or machine learning.,5,4,0,0,0,0,0,0,0,0,0,0
6,MS,Faculty,Chad,"Yeah. It's still, I think, very early for AI, but at small companies, if done properly, small companies can leverage AI to be bigger, and for a big company, you can definitely leverage AI to keep growing and to be more competitive. So, certainly at places like Morningstar, where there is so much data to be processed, we applied AI in a wide variety of fashions. We really focus on providing independent investment data and research. Mostly, that analysis is done by human experts, but there are times where there's so many possible investments to cover that you have to consider something like AI to look at all the information about a particular investment that may not be that well known or very popular, but for completeness, a company like Morningstar wants to provide some insights. Oftentimes, we will experiment with AI to consume all that available information and generate some information that a human analyst could also generate, but maybe doesn't have the time to. There's lots of applications for AI all over the place.",6,4,1,0,0,1,0,0,0,0,1,0
7,MS,Researcher,Researcher 2,"Yeah. That's a great application and it's good to hear from your personal experience. Now that you have ventured into academia, do you work with AI at all?",7,4,0,0,0,0,0,0,0,0,0,0
8,MS,Faculty,Chad,"Yeah, I'm part of the teaching faculty, so most of my focus is on teaching, but another responsibility I have is I serve as the executive director for University's AI Research Institute for Science and Engineering, which is a new institute that came online in the summer of 2020, so right in the middle of COVID, and is only now sort of getting going. It was founded by Dr. Feng Luo, who is a professor in the school of computing. I'm helping him realize his vision for AI RISE, is what we call it, and it really is a combination of providing educational opportunities across University to train faculty and researchers and students. It's to bring in the community, the upstate and the entire state, to help educate everyone really, on AI, and what AI is because it's such an overloaded, overused term and everybody maybe thinks they know what it is, but I think everybody has probably a different idea of what it is. AI always comes up in whatever subject I'm teaching. One of the classes I'm teaching this semester is on computing, ethics, and society. So obviously, talk a lot about AI and the moral issues associated with the use of AI and the bias that is proven to be in a lot of systems that employ AI today, and it has certainly lots of positive impacts, but also a lot of negative impacts. We talked a lot about that in that class. It always comes up because it's everywhere, honestly.",8,4,0,0,0,0,1,1,0,0,1,0
9,MS,Researcher,Researcher 2,"It is everywhere, yeah. I know it's important. It's important to talk about the ethics as well. That actually leads me into my next question. You can provide an example if it's easier to do this, but what ways has AI or machine learning helped us humans, and who in particular have they helped? And then we're going to do the reverse question after.",9,4,0,0,0,0,1,0,0,0,0,0
10,MS,Faculty,Chad,"Yeah. I think maybe some of the obvious ones that people can relate to are benefits associated with recommendations. We rely on, and we always have, even before AI, rely on recommendations to help us make buying decisions that are best for us. You see it mostly in streaming media, for example. It's like, you watch this movie or you watch this genre, you might be interested in this series, and it is helpful, definitely is helpful, and then when we buy stuff, same kind of thing. People are looking at this, they ended up buying this. You were looking at this, maybe you'd be interested in this. It's subtle. It's kind of built in and it helps us make these important or maybe not so important decisions where we spend our money and things like that, and that affects so many people, and our reliance on recommendation systems has been around forever, and I think AI has really tapped into it. It's very freaky, and the other thing is, a lot of companies use AI just to speed up what they can do and increase their capacity. Screening resumes, looking for the right candidates to hire. There's so many opportunities out there. So much of the workforce is in motion right now and companies that are hiring to keep up, they employ different AI solutions that they probably bought from somebody else, who decided, hey, it's probably good business for me to do this. Those are just a couple examples.",10,4,1,0,0,0,0,0,0,0,0,0
11,MS,Researcher,Researcher 2,"Thank you. We appreciate those examples. I think most people have been encountering the AI that makes decisions or suggest things for them. Amazon, Netflix, they all have that. Now the reverse of that question, how has AI or machine learning harmed us and who have they harmed?",11,4,1,0,0,0,1,0,0,0,0,0
12,MS,Faculty,Chad,"In the spirit of getting things done and automating things, oftentimes, you see that in these industries that involve money. A classic example is evaluating loan applications or credit applications, things like that. There's a lot of systems out there that will analyze those applications and make decisions. That's why you have this instant decision making. Apply for this credit card, be approved right away, whatever. Those systems, I understand the spirit behind those systems, but sometimes their decisions are questionable because they take into consideration where you live, where you work, those kinds of things. Perhaps, I don't know that anybody will ever admit this, but they'll probably do some analysis on your name, and there are so many services that these systems can tap into to find out things like where else you've lived or where else you've worked, and it makes decisions that often negatively impact the people that would benefit the most, and that's unfortunate. There's that bias that really reinforces, I think, some of the divides that we see in society already. Instead of making things better for people who are disadvantaged, oftentimes AI, maybe not intentionally will actually make those divisions even more clear, and it just doesn't help the people who need that mobility.",12,4,1,1,0,0,1,0,0,0,0,1
13,MS,Researcher,Researcher 2,"Unfortunately, it can kind of amplify some of the systemic issues that are already happening.",13,4,1,1,0,0,1,0,0,0,0,0
14,MS,Faculty,Chad,"I think one of the topics that keeps coming up is this issue of facial recognition, and a lot of research in that area where the accuracy of facial recognition is certainly in doubt, especially for people of color. There's a lot of research and certainly a lot of improvements being made in those areas, but still, wrongfully identifying somebody because of a failure in a AI system for facial and image recognition is devastating for the people. When you're not one of those people who are flagged, you're like, well, what's the deal? That doesn't affect me, but if you're that person, it's life changing in a bad way. It could be.",14,4,1,1,0,0,1,1,0,0,0,0
15,MS,Researcher,Researcher 2,"Definitely, and you have to think about the history of our country, too, and who's been impacted. All of those. Those are really big issues that we need to think about.",15,4,0,0,0,0,0,0,1,0,0,0
16,MS,Faculty,Chad,"One other thing, just a quick thing. On the positive side, the nice thing about AI, if done correctly, those systems can identify things that humans cannot. Certain patterns. I just think about mostly in the area of medicine. They identify things that even a doctor, a skilled doctor will not recognize, because the pattern is not something that you can consume as a human, but certainly identifiable by an AI system.",16,4,1,0,0,0,0,0,0,0,1,0
17,MS,Researcher,Researcher 2,It'll be interesting to see what type of advances the AI will add to our medical system.,17,4,1,0,0,0,0,0,0,0,0,0
18,MS,Faculty,Chad,Yeah. Yeah.,18,4,0,0,0,0,0,0,0,0,0,0
19,MS,Researcher,Researcher 2,"If somebody were to come up to you and I know you kind of touched on this earlier, but there's a lot of different definitions, so I'm wondering what is your definition of AI?",19,4,0,0,0,0,0,0,0,0,0,0
20,MS,Faculty,Chad,"Well, I do a lot of presentations that cover these basics to get people on the same page. It's really the ability of something to mimic the capabilities of the human mind by learning from data and experiencing things. This general definition, the ability again, to have a system mimic the capabilities that we have, but what we have, in reality, is something quite different. In general, I think about that. And then within that, there're subsets, like machine learning and deep learning. I think when people think of AI, they think of robots killing all the humans.",20,4,1,1,0,0,1,0,0,0,1,1
21,MS,Researcher,Researcher 2,Yeah.,21,4,0,0,0,0,0,0,0,0,0,0
22,MS,Faculty,Chad,Or robots taking all the jobs.,22,4,0,0,0,0,0,0,0,0,0,0
23,MS,Researcher,Researcher 2,Yeah.,23,4,0,0,0,0,0,0,0,0,0,0
24,MS,Faculty,Chad,"It's just this mystery, but I think if you set the stage with some basics and then, you talk about... Because people throw around AI and they throw around machine learning and they throw around deep learning and it just turns into this big jumble, and then people just substitute all the terms for whatever they feel they're talking about, but that's kind of what I think of it.",24,4,0,0,0,0,0,0,0,0,0,0
25,MS,Researcher,Researcher 2,"How would you define machine learning then, because I know you just mentioned that?",25,4,0,0,0,0,0,0,0,0,0,0
26,MS,Faculty,Chad,"Machine learning is an AI that essentially learns by itself and it improves by ingesting more data to perform a task with better efficiency and accuracy. That's kind of what I think of it. That's why when people start talking about training data, their eyes glass over, but it is about that. You're just educating this AI, helping it to learn, like what a cat looks like. So that, when you say, ""Is this a cat?"", it knows what a cat looks like, and that's what we see in image recognition and stuff like that. That's why you can look for cats on the internet. It's just that, more and more data, but the downside of it is, you're assuming that what you're feeding it is accurate and complete.",26,4,1,0,0,0,0,0,0,0,0,1
27,MS,Researcher,Researcher 2,Technically.,27,4,0,0,0,0,0,0,0,0,0,0
28,MS,Faculty,Chad,You're going to get some weird results if the data is bad.,28,4,0,0,0,0,0,0,0,0,0,1
29,MS,Researcher,Researcher 2,"Yeah. It'll definitely change the whole algorithm. Switching gears a little bit, we're going to start talking about youth. What are your thoughts about youth learning about AI or machine learning?",29,4,0,0,0,0,0,0,0,0,1,0
30,MS,Faculty,Chad,"Yeah. I think at a high level, my generation, it was always, for your education, you really need to understand reading and writing and arithmetic, math. I think to add to that, now you have to understand computational thinking. You have to understand just some basics of how computers work, things like that, just basic stuff, because you just have to. You probably grew up in a world that already had the internet, that already had things like GPS, that already had smartphone, or something close to it. I didn't. My kids, they think I [inaudible 00:19:33] prehistoric times or something. It's like cave man, how did you get anything done? But now, everybody that's being born is born into a world where computing is everywhere. It's not just reading and writing, and arithmetic. It's reading, writing, arithmetic, and computational thinking, understanding how stuff works. In the spirit of that, you have to understand, I think at least conceptually, what AI is, and what it is not presently. We're in no danger of robots taking over the world anytime soon.",30,4,0,0,0,0,0,0,0,0,1,0
31,MS,Researcher,Researcher 2,Nope.,31,4,0,0,0,0,0,0,0,0,0,0
32,MS,Faculty,Chad,"I tell people all the time, ""Robots are not going to take over the world. They're not going to kill all the humans,"" because what we have now really is, AI is mostly about pattern recognition. Honestly, just doing it faster, but for somebody who is just a young person learning, I think they just have to understand what kind of impact AI has on society and what it will have on their lives, especially when they are in a world with autonomous driving, things like that. They have to understand that everything is not magic.",32,4,1,1,0,1,1,0,0,0,1,0
33,MS,Researcher,Researcher 2,"That is essential, yes. You kind of touched on this, but what do you think is important for youth to know about AI or machine learning?",33,4,0,0,0,0,0,0,0,0,1,0
34,MS,Faculty,Chad,"I think to not be fearful of it, but to understand at its core what it is and how it works, so that there's no fear, for one thing. And then, when they're learning that, that they can also, I think, open up their imaginations to what it could be used for, for the benefit of global society because I think what's been happening with technology is, it used to be inaccessible to people who had great ideas, and now with things like cloud computing and tons of open source software, some very specialized around AI, if you have a good idea, you can try some things out. If you get everybody's brain in the game, we have a lot of serious problems that we need to address, and I think young people need to understand that no one's going to solve those problems, and you need to think about... I should say, other people are not always going to solve the problem. You have the ability to solve some of these problems or to contribute to the knowledge. We have to start addressing these difficult global challenges, and we have to stop, I think, focusing so much on things like TikTok. Just think about all the technology that went into building TikTok. It's like, I'm sure there are valid and great use cases for TikTok, but I would say by and large, from my small sample, this is kind of ridiculous. It's entertaining, and you get that dopamine hit. I understand that, but I just think, of these technologists that develop things like TikTok or Facebook, I'm like, we probably could have ended food distribution problems or just poverty, environmental concerns, but instead, we have TikTok. It's kind of depressing a little bit. I'm hoping that you get to the youth and have them understand this. It can only be a good thing, I think.",34,4,1,1,0,1,0,1,0,0,1,0
35,MS,Researcher,Researcher 2,"Yeah. I hope so, too. I hope they'll change the world for us.",35,4,0,0,0,0,0,0,0,0,0,0
36,MS,Faculty,Chad,"With any technology though, it's just, there's the good and the bad and the dark underbelly. It just tells us a little bit about human nature, I think.",36,4,0,1,0,1,0,0,0,0,0,0
37,MS,Researcher,Researcher 2,"It does. It definitely does. I know you don't have much time left, so this will be my last question.",37,4,0,0,0,0,0,0,0,0,0,0
38,MS,Faculty,Chad,Okay.,38,4,0,0,0,0,0,0,0,0,0,0
39,MS,Researcher,Researcher 2,How can we engage youth in learning about AI and machine learning and ethics? Have you ever used any activities? Do you know of any resources out there of [inaudible 00:24:53] or any ideas of how we can?,39,4,0,0,0,1,1,0,0,0,1,0
40,MS,Faculty,Chad,"Yeah, there's a really thought provoking... Hang on, just let me see. It's a great thought provoking website. What is it called? Oh yeah. moralmachine.net. If you go to moralmachine.net and then click the judge link, what this is, is this research that's done by MIT and a handful of other universities, and it asks you some interesting questions because everybody's talking about self-driving cars, and how they're going to happen. They're already happening. It's going to happen, and the reason behind it is, humans are not good at driving. People always think they're good at driving, but they're not. So, if we get the self-driving stuff done correctly, even if it's not entirely self-driving, even if you're sitting in the driver's seat and have to take over, there are these interesting moral decisions to be made by the technology in the event of something unexpected. This website poses all these interesting questions about, if you were programming this self-driving car, what would you do in the situation? Your brakes fail. If you continue on your path, you're going to destroy three children in the pedestrian path. If you swerve, you're going to kill everybody in your car because you're going to crash. It's an interesting reveal of how we think and they, MIT and these other universities collect this data. I think for young people, gaming, just taking advantage of gaming technology to educate in a way that's maybe not right in your face, I think is a good way to learn. So much of learning is caught rather than taught. You just never know.",40,4,1,0,0,1,1,0,0,0,1,0
41,MS,Researcher,Researcher 2,"Yeah. I've never heard that before, but I like that saying. It's interesting.",41,4,0,0,0,0,0,0,0,0,0,0
42,MS,Faculty,Chad,"If you sit around in a room and you hear a bunch of people just talking, you learn a lot. They're not teaching you, you're just learning a lot. You're just kind of catching it. I think by employing things like gaming and some of these thought workshops, like what would you do in this case? It's interesting. That's why I really like teaching the class I'm teaching this semester, which is computing, ethics, and global society. Because some things that seem simple, are not. They're tough decisions. They may benefit some people. They're going to hurt some people. Is it the right thing to do? Even though you can do it, should you do it? It's-",42,4,1,0,0,0,1,1,0,0,1,0
43,MS,Researcher,Researcher 2,It's an important class. It's an important class. I'm glad to have that at University.,43,4,0,0,0,0,0,0,0,0,0,0
44,MS,Faculty,Chad,"Yeah. It's fun. But anyway, there you go.",44,4,0,0,0,0,0,0,0,0,0,0
45,MS,Researcher,Researcher 2,Awesome. Thank you so much. I really appreciate you taking the time. I'm going to go ahead and stop the recording.,45,4,0,0,0,0,0,0,0,0,0,0
1,NM,Researcher,Researcher 1,"Okay. So this is Thomas interviewing. Today is Friday, January 28th, 2022. Welcome, Nathan. So let's just start out, can you tell us more about your professional background and your work history?",1,5,0,0,0,0,0,0,0,0,0,0
2,NM,Faculty,Thomas,"Yeah. So pretty much been an academic in training for a very long time. My dad was a dean at University State, so I grew up in academia. I knew about academia. I never wanted to be in academia, this is the funny part of the story. I remember telling both of my parents, why would I ever, ever want to do what my dad does? It sounds like the most boring thing in the world. And then I have ended up mimicking his career in many ways. So my professional career is very interdisciplinary. I have a degree in psychology, I have a degree in information science, and then a postdoc basically on computer science. And then I'm a professor of computer science, essentially. So I expand the spectrum from social and hard computational perspectives, and I think that's really important when you talk about AI. It can't just be one or the other. It can't just be a bunch of psychologists ruminating about what they think is important or sociologists thinking what they think is important about AI. You need real computer scientists in the room as well to understand the feasibility of how these things are going to happen. So both of these entities need to be talking to each other. I kind of planned my career that way, that I knew from a very early age that I was interested in the intersection of just people and technology. So I started off learning, I built my foundation with people, with the psychology, understanding that. And throughout my career, I've kept that foundation. It's what grounds me as a researcher and from my worldview of things. I've kept that humanistic foundation, but I built on top of that through additional degrees, more of a technology flare from information sciences and computer science. And now you kind of get whatever the heck I am nowadays. It's like a morphous blob of social and computer science. But I think it's important. And that's how I train my students to think about things is, if we're going to make sure that AI is beneficial for people and inclusive to many people, you better be taking into account the human side of things. But you also need equally know, from my perspective, as people that build AI, you need to know how to do that as well. So it's a big ask, but I think it's what the next generation of people studying, and implementing and developing AI need. They need both of these perspectives. Collaboration amongst both of those is great.But if we can start training people for this early on, to your point in some of your studies that you look at, if we can start instilling this mindset in kids from an early age of AI is not just computer science, it's human science as well, it's both of these things together, instilling that from an early age and having actual interdisciplinary training and degrees for that is going to be really important. So I went all over the place. I'll do this throughout the interview, I'll ramble-",2,5,1,0,0,1,1,1,0,0,1,0
3,NM,Researcher,Researcher 1,"No, it's great. And actually [crosstalk 00:03:39] ... We picked you because of that. That's actually a strength here. So you actually, you did answer some of the questions that I was going to follow up with, so that's great. So you gave us an understanding of broadly kind of your career trajectory, what you're interested in. This intersection of humans and technology specifically with AI. I think you explained that well. Let's take a finer grain look. So on a day to day or weekly basis, what do you do with AI and machine learning?
",3,5,0,0,0,0,0,0,0,0,0,0
4,NM,Faculty,Thomas,"Yeah. So what we study in my research group, almost everything we study nowadays is on this concept known as human AI teaming or human autonomy teaming. So it's the idea of humans teaming with AIs or autonomous teammates for the completion of a shared goal or a shared task. So everything we study nowadays is related to this concept, and there's a lot of different perspectives and paradigms and ways to look at that concept. And we really try to run the gamut on this. So the thing I talk about all the time when we talk about human AI teaming is that there's a bidirectional quality to it. You have to check off the boxes for the human. You have to check off the boxes for the AI. So the human needs to know how to interact with the AI. It needs to have an expectation of what the AI is. But also the AI needs to know what the heck humans are. It needs to know what teaming is, what matters. And this is where we have to get better. We have to develop autonomous teammates that actually know how to interact with humans, because it can't just be a one sided paradigm. And that's what it is right now. We stick people into a human AI team and we say, go work with this AI. But the AI has no clue how to work with you as a human. So what happens is that the human has to take on this brunt of dealing with basically a bad teammate. So what we're trying to do is number one, understand perceptions that humans have of AI as teammates, and reverse engineer those perceptions so we can build more effective, good AI teammates. So like I was talking about before, you can clearly see how there's the psychology point of view with the perceptions of humans and AI as teammates, but then on the other side, it's the computer science side of things. How do we actually build AI's that understand communication, coordination, awareness, things like team cognition, really critical aspects of teaming that have to be built into human AI teams?",4,5,1,1,0,0,0,0,0,0,0,0
5,NM,Researcher,Researcher 1,"Can you give us an example of a real world situation where that research could be applied, where AI and humans are working together?",5,5,1,0,0,0,0,0,0,0,0,0
6,NM,Faculty,Thomas,"Yeah. The most apparent situation is it usually happens in three areas. So first you see it happen a lot in emergency crisis management. The most recent example was when, if you guys remember when that big condo building fell down in Miami, so they always respond nowadays with two things for emergency crisis management, obviously humans, but they respond with dogs, which has always been the case, but now they respond with robots that have intelligent capabilities that are working towards teaming. So that's one instance where human AI teaming's happening a lot is emergency crisis management situations. The other is a myriad of Department of Defense military operations, where you have aerial drones, water drones that have intelligent capabilities that have to actually team with human operators for a shared common goal. That's why the DOD is obsessed with the human AI teaming perspective, is because they know that AI brings a lot to the table and teaming is critical to almost any military operation. So they're trying to figure out how can they exploit the advantages of AI within their paradigm of teaming? And then the third that's starting to catch on and you see it more and more is the healthcare domain. You're seeing some tele-roboted things that are happening. A lot of clinical decision support that is starting to have intelligence capabilities. We haven't really got to the teaming quality as much as the previous two examples, but it is coming. There's a wave coming where human AI teaming and the concepts related to that are going to start molding and bleeding into the medical sector.",6,5,1,1,0,0,0,0,0,0,0,0
7,NM,Researcher,Researcher 1,"Cool. I'm interested in that. Can you give a specific example of that, just one?",7,5,0,0,0,0,0,0,0,0,0,0
8,NM,Faculty,Thomas,"Yeah. So there's code blue resuscitations in hospitals. I think you guys are probably familiar with that, when somebody goes into cardiac arrest. Whenever that happens, an alarm goes off in the hospital and everybody that is assigned to that code blue that day is supposed to, in theory, stop what they're doing and run to that room and help triage a patient in real time. And it's one of the best instances that I've ever studied of human-human teamwork. It's an absolute chaotic environment where you have extreme time pressures. People don't have, they have information disparities, inaccuracies, they don't know what's going on really so they're trying to understand at an individual level, what do I do? What do my team members do? Leadership is needed. One of the biggest problems that you see within those is what I was just saying, is information disparities and information needs not being able to access that very quickly. So in the communities I've been talking to regarding this, there's the development of utilizing robots and intelligent agents to aid in that collaborative decision making process, where the intelligent agent is providing, it's looking at all the data on the human, because as a human, we give a lot of biophysical data and can't possibly look at all of that in real time. It takes us a long time to go through all that. So an AI agent that has been trained on an algorithm to look at peaks and valleys of all of that, and then flag it can be trained to provide real time relevant information to that team when they need it. They don't have time to dig through the data, where the AI can dig through all that real time data and alert you of multiple things that are going wrong so you can better understand the medical operational environment. That's an example of where we're heading towards.",8,5,1,0,0,0,0,0,0,0,0,1
9,NM,Researcher,Researcher 1,"Yeah, that's fascinating. And I think that's a really good example of the power of AI and how it can be so helpful, especially, like you're taking the person's strengths, you're taking the AI strengths and bringing them together to make this really functional system even more functional. So what are some examples then kind of on the opposite end of the spectrum of how potentially AI or machine learning can harm us? And who in particular do you think it harms?",9,5,1,0,0,0,1,0,0,0,0,0
10,NM,Faculty,Thomas,"Yeah. You look at AI used to make decisions for hiring specifically. This is an issue we've seen this and then there's a lot. The problem with AI is not necessarily how the algorithm is aligned or built, humans, I believe are not malicious in nature, so for the most part they're not trying to build malicious AI algorithms. I'm of the belief that the problem starts with the data. The data that is often pulled is unrepresented. It's not inclusive. It's not diverse. So your starting point in your foundation is fundamentally flawed and biased. So we need to be very much more aware of the type of data that we're feeding into these algorithms, because if you have a bias in your data sample, it's only going to be more concentrated when it goes for an algorithm, because an algorithm basically at its core is just looking for concentrations and patterns of data. So if you have the slightest concentration or bias in your data, it's going to be amplified throughout the algorithm, and then the impacts of the algorithm with humans are going to be felt. So you see this in HR and recruiting all the time. When you have resumes that are given for, let's take the example of a professor. Unfortunately in many cases, most professors are white males and that's who's applying to be professors. So if you were training a theoretical AI algorithm to assess what a good candidate is for a professor and you feed them all a bunch of white male CVs, well, they're going to say that, oh, it seems like based on our data that the white male is the best candidate, because that's what the majority of the CVs are. So it's an inherent ... This is what's tricky, and I hope you guys are able to capture this in the whatever research you publish. AI's very tricky, because it's mimicking societal problems. It's not just the AI, that's the problem. It's in many ways, representative of real problems in society. And this is where I get really frustrated when I study, because I have grants on ethics and bias in AI. And I get really frustrated, because at some level I don't know how much we can fix these problems because they're deeply ingrained at a cultural and society level, because AI, and algorithms and data samples are in many ways mimicking the real world in some cases. It just becomes more amplified through the algorithm itself. I'm probably getting ahead of, but we have to build safeguards in to make sure that we're checking on the data that we're looking at, the algorithms that we're constantly having human eyes on the outputs. You have to make sure that human factors are directly tied to AI outcomes. You can't just let the AI run loose. It needs oversight.",10,5,1,1,0,1,1,1,0,0,1,1
11,NM,Researcher,Researcher 1,"Yeah, absolutely. One of the things, we have run with kids in the past, getting them involved in these kinds of discussions. So understanding that algorithms and these technologies can perpetuate some of these systemic inequities. So we posed the question to them, well, what should Google do? What should these companies do? Should they mess with the data and create kind of fake data that doesn't actually reproduce these inequities? But what's the consequence of that then? So kids have really interesting ideas when it comes to these-",11,5,1,1,0,1,1,1,0,0,1,0
12,NM,Faculty,Thomas,What's the main takeaway from them?,12,5,0,0,0,0,0,0,0,0,0,0
13,NM,Researcher,Researcher 1,"It depends on the context. So if it's a Google image search engine, many kids say, yeah, I'm not represented here, but that's how the world is. The consequence isn't huge. I search for computer science professor and I don't see myself as a African American woman. Okay, that hurts. But I don't think Google should mess with that. Then when it comes to hiring algorithms, yeah, they see that as problematic. So the context really matters and the effect of the consequence as they see it matters to them.",13,5,1,0,0,1,1,1,1,0,1,0
14,NM,Faculty,Thomas,"I think they're right. I mean [crosstalk 00:16:09]-
",14,5,0,0,0,0,0,0,0,0,0,0
15,NM,Researcher,Researcher 1,But it's cool that like middle schoolers can talk about that.,15,5,0,0,0,0,0,0,0,0,0,0
16,NM,Faculty,Thomas,"... Yeah. I think that's what's cool about your research is that we discount kids, and kids know an awful lot. And they are really good at distilling it down to the black and whites almost of what makes sense. Whereas humans, we try to muddy the waters constantly, and we have so many things in our mind, we can't see it as clear as kids can sometimes. So that's what's ...",16,5,0,0,0,0,0,0,0,0,0,0
17,NM,Researcher,Researcher 1,"Yeah. The tricky part is getting them to understand it, relate to it and care about it. If it's not part of their everyday experience, it can be hard. So there are limits to that for sure. So I guess one thing to back up that I didn't ask you, so leveraging some of your expertise. If I asked you to define AI or someone on the street asked you to define AI, how would you define it?",17,5,0,0,0,0,0,0,0,0,0,0
18,NM,Faculty,Thomas,"It's taking a lot of data, aggregating that data and trying to simplify that data to make sense of that data in a way that you can predict patterns. That's my 30,000 feet in the sky. It's about a bunch of data, distilling that data down to allocate patterns.",18,5,0,0,0,0,0,0,0,0,1,0
19,NM,Researcher,Researcher 1,"Yeah. Yeah. And that's what we're looking for, because we're looking for kind of a broad definition that we can get it kind of a consensus on from everyone we're interviewing, and then provide it to kids in some way. So same question, but for machine learning. How would you define machine learning?",19,5,0,0,0,0,0,0,0,0,0,0
20,NM,Faculty,Thomas,"Machine learning is taking a bunch of data and feeding in new data continually to that initial large data source, and then adapting and learning based on the foundation of the data that you have, and adapting to the new data that is brought into the foundation. So it's an adaptive learning situation. So it's AI that really learns based on the foundation and the introduction of new data into that.",20,5,0,0,0,0,0,0,0,0,0,1
21,NM,Researcher,Researcher 1,"Okay, great. Thank you. And then, so we talked about some of the harmful effects of some AI applications. Are there any other sort of potential problems you see that we haven't touched on, or ethical issues, or other social issues?",21,5,0,0,0,0,1,0,0,0,0,0
22,NM,Faculty,Thomas,"I mean, jeez, we could be here all day.",22,5,0,0,0,0,0,0,0,0,0,0
23,NM,Researcher,Researcher 1,"Or I guess, if we want to narrow it down, which one of those issues that you know so much about do you think youth would be interested in, or should they know about? Either one.",23,5,0,0,0,0,0,0,0,0,0,0
24,NM,Faculty,Thomas,"Gender and race. I think that those are the two things that people with inequities historically are affected by the harms of AI. And I think if you're looking at youth, no matter what their skin color or their background is, they need to know that from a very early age. They need to know the impact that technology can have on them and other people, and how the impact on other people can have an impact on them. I think that's what we miss, is that like, I'm a white male. Well, if there's a negative impact on somebody, is it going to affect me? Maybe, maybe not. But we need to start teaching that more. It's multidimensional in terms of bad outcomes. We only focus on bad outcomes for that one specific person. We need to focus on it for everybody, because it's impacting everybody. So yeah, I'd go back just to gender and race as the two things that really need to be hit home. Because if you look at biases, and fairness and equality issues related to AI, those are the two markers that are getting hit the hardest. And race being number one actually before gender.",24,5,0,0,0,0,1,1,0,0,0,0
25,NM,Researcher,Researcher 1,"Yeah, definitely. So going back a little bit, you mentioned that people who are designing these technologies, the vast majority are not doing it wanting to intentionally harm certain populations, it's just embedded in the data and they use that data. So can you maybe describe from what you know, who are these people then? How would you describe them? The population of people who are in charge or who are the ones designing these technologies, who are they?",25,5,0,0,0,1,1,0,0,0,0,0
26,NM,Faculty,Thomas,"Yeah. Typically AI engineers and software engineers within large tech companies. Most of the AI that you're interacting with is coming from basically three or four companies. It's coming from Google. It's coming from Microsoft. It's coming from Meta, Facebook. And then I'm missing ... Apple. Those are the four companies where I would venture to bet 90% of the AI that humans are interacting with are actually coming from. There's obviously AI companies all over the world, but they're very small. And so I'm not saying we don't focus on those companies, but jeez, let's start with the big problem first, the one that's impacting as many people as it is. So the focus needs to be on the big companies, and it needs to be focused on the AI engineers and the software engineers in there. One of the things I want to get in here in the interview is the idea ... And I'm sorry if this is a question that you're going to answer, but I want to make sure I don't forget to say this. If you're dealing with the idea of ethics and bias in AI, and how do you solve that problem? One of the things we've found in my own research, because we have a research project that's focused on bias mitigation in AI decision making systems, and one of the things we've done a bunch of qualitative work talking about how do you mitigate bias? And people have pretty good ideas on how to mitigate bias in AI. The real problem that stems from our research that we see is a lack of responsibility and accountability on who wants to do that. So we talked to industry companies like the companies I was just mentioning, we talked to people in those companies and they're fully aware of bias and AI. They don't like it. They hate it. They want to make a difference. But it actually comes to an organizational company level problem of whose job is it to actually fix these problems and make sure these problems are not there to begin with? Is it the actual engineer? Is it the product manager? Is it upper level administration? No one from our experience in our interviews, no one knows the answer to that question, and no one wants that accountability on their shoulders of a goal. If you're a product manager at Google, your job goal is to make sure that the AI that your team's generating has no biases. That's a heavy burden. You don't really want that. So what happens is that the idea of AI bias and mitigation is super important within these companies, but it goes unchecked in terms of actual accountability of somebody doing this, because no one wants to have that heavy burden on their shoulders. No, one's willing to take on that job of being the AI ethics czar within companies. And that's, I mean, it's a fair thing. Who wants to do that? Who knows what is right or wrong in many ways for things? So that's a big problem that has to be dealt with, and I don't know how you deal with it.",26,5,0,0,0,1,1,1,1,0,0,0
27,NM,Researcher,Researcher 1,"Yeah. Yeah. It's messy. There's no one right answer. It's a huge ethical dilemma. And there's no answer to human ethical dilemmas. So yeah, nobody wants to take that on at such a large scale when you're deploying these algorithms and they affect millions of people. That's tough. Yeah. Yeah. That is very interesting. Well, we're making our youth do it, obviously in a low risk situation.",27,5,0,0,0,1,1,0,0,0,0,0
28,NM,Faculty,Thomas,Right.,28,5,0,0,0,0,0,0,0,0,0,0
29,NM,Researcher,Researcher 1,"We'll see what they come up with. So you talked about sort of what you thought maybe would be important for youth to learn and address when it comes to the social and ethical issues. What about content? So can you imagine elementary, middle, high school, maybe more middle school kids, what sort of machine learning content do you think they could engage with or should they engage with?",29,5,0,0,0,0,1,0,0,0,0,0
30,NM,Faculty,Thomas,"Ah, gosh, that's a really good question. And I don't have a good answer for it.",30,5,0,0,0,0,0,0,0,0,0,0
31,NM,Researcher,Researcher 1,That's fine.,31,5,0,0,0,0,0,0,0,0,0,0
32,NM,Faculty,Thomas,"I think the reason I don't have a good answer for it is because it's a really complex question. It's a good question, because machine learning, I've studied a lot of things in my career, and machine learning is probably the most complicated thing I've studied in terms of understanding it. I don't even understand it. It's a black box. Machine learning, there's a black box. You understand at the high level what your algorithm is that you build at the beginning, and you understand what the data that was used to build that algorithm are and the new data that comes in. But no one really understands unfortunately how the algorithm is tweaking itself and changing itself. And from a teaching standpoint, that's really, really hard to describe. It's like this idea of you're going to build something, and it's going to [amorphically? 00:25:51] change on its own and you have no control over it. I think if you were to develop content at that age, it's not necessarily understanding machine learning per se, but more of the conceptual level of what I was just talking about of here's data, you build a tool to make sense of that data, and then data is built into that and it changes over time. Very concept oriented curriculum is what is needed at that age, because you quite frankly can't get too deep on a lot of the machine learning concepts, because they're very much based on computer science theoretical concepts. So you can't actually even teach some of the machine learning concepts until you understand the computer science concepts. So maybe that's the answer, is we need to do a heck of a lot better job in stem of just teaching computer science and AI concepts in general, and then work down the path of machine learning. I don't think we can jump just in the machine learning, because you have to develop that concept awareness before you get into that.",32,5,0,0,0,1,0,0,0,0,1,0
33,NM,Researcher,Researcher 1,"Yeah. Yeah. Sometimes in my work, so we're trying to teach kids, now I'm doing machine learning, but before it was all kinds of complicated things, too, like engineering design and building products. And there's definitely a black box attitude towards it. So what do we black box and what do we expose kids to? And how do we get those key epistemic ideas? And that's part of what this interview is too, what is key to you and how can we reproduce those for kids in a way that's ... A word I use is truthy? Because we do want to get them exposed, but we also want to make sure that they're learning something that's not fundamentally wrong. So yeah, we focus a lot on more of the supervised machine learning. And it's focusing on the training data, they put it in something, a black box, and see what comes out and they have to test it. They have to investigate that training data to see where the bias lies and how they can change it. Test it again with a different set. So it's kind of making sure the difference between training and test set data, so something like very simple, but important. And also just understanding the difference between machine learning and just programming a robot to do something. What does it mean to interact and learn from your environment?",33,5,0,0,0,0,0,1,1,0,1,1
34,NM,Faculty,Thomas,"Yeah. I mean, one of the ways I was talking about just teaching concepts, it's interesting if you distill machine learning down to just concepts. It's similar to a psychology paradigm, which is something called input process output with a feedback loop back to the input. That's what machine learning is. The input is the data, the process is the algorithm and the output is whatever the insider information is. And that feedback loop is going back to the output, feeding into the initial data again. It just keeps going on, and on and on in the cycle. So I think kids are smart enough to understand that. And that's the level that we need to be talking about in terms of machine learning. But in order to even understand that, to your point goal, you have to understand programming and data. When you say data, what in the world do you mean data? So they have to break it up into these digestible parts and pieces.",34,5,0,0,0,0,0,0,0,0,1,1
35,NM,Researcher,Researcher 1,"Yeah. Yeah, absolutely. That's funny you mentioned that connection to psychology. I'm teaching a learning theory course, and I have these three HCI students that have been taking my courses. They're lovely. And we were talking about behaviorism stimulus response. And he's like, ""this is like machine learning."" And I was like, ""yes, it is in a lot of ways."" And just having them in the class draw those connections is so fun.",35,5,0,0,0,0,0,0,0,0,0,0
36,NM,Faculty,Thomas,"Yeah. I mean, machine learning's history is based on cognitive theory. If you go back to, so it started off as things called expert systems. If you know this stuff, just ignore what-",36,5,0,0,0,0,0,0,0,0,0,0
37,NM,Researcher,Researcher 1,"No, say it, because we need to record it. Go for it.",37,5,0,0,0,0,0,0,0,0,0,0
38,NM,Faculty,Thomas,"So it started off with this idea of expert systems, which was an idea of just mimicking people's actual cognition of how do humans cognitively understand things? Well, there's data in your environment, that's the input. Your process is in your mind. You take that data and you process it. And the outcome or the output is the behavior that you have from the thought in your mind. So that was the still down into this idea of an expert system or cognitive modeling. So act our cognitive modeling is one of the first ways that we started getting into this foray of machine learning broadly speaking. But it started off as the crystallization and summarization of how at a high level, we as humans understand and make decisions from a cognitive standpoint. And then how can you from a computer science standpoint, use that same process to create similar outcomes that we have as humans. So in many ways, and it's kind of scary, machine learning neural net, a neural net is similar to how we cognitively process information in our own brains. We were talking about the black box. Well, guess what? This is a huge black box. So it's very interesting how there's parallels into the human brain and machine learning. And then you get into really interesting, cool stuff, like human brain computer interfaces, which is outside the scope of this interview. But connecting the actual human brain with the neural networks and all that good stuff, that's really scary stuff.
",38,5,0,0,0,1,0,0,0,0,0,1
39,NM,Researcher,Researcher 1,"Yeah, it is. Yeah, it is. Yeah, I was reading some stuff about a group of scientists looking to young children and to help them, because almost saying some machine learning systems or intelligent systems, I think just young children. So looking to see how young children develop into more intelligent beings, and then using that information to do the same thing with our AI.",39,5,0,0,0,1,0,0,0,0,0,0
40,NM,Faculty,Thomas,"Yeah. I mean, this is the thing that Elon Musk is focused on with Neuralink. And basically you can quote me on this, anything Elon Musk gets interested in is very dangerous for human beings.",40,5,0,0,0,0,0,0,0,0,0,0
41,NM,Researcher,Researcher 1,"That goes back to my question about who's in power, who's creating these things and what are they interested in? So you went straight to corporations, which yeah, is in the literature about corporate interests, and these people in power and how that influences the rest of us.",41,5,0,0,0,0,0,0,1,0,0,0
42,NM,Faculty,Thomas,"I mean, I'm a cynic in this regard. I think everything in this country and this world is motivated by money and financial interest, and corporate entities maintain that at the highest level. And depending on the governments, they either promote that or try to curb that back. But at the end of the day, it's all about money. So I think when you talk about AI and dealing with the problems that are dealt with, with AI, you have to understand that people are making money off of AI. Even if it's terrible AI in terms of being this most biased, terrible agent in the world, someone's going to make money off of it potentially. And I'm a cynic in that regard. People will put money above much of their own ethics in some cases.",42,5,1,0,0,0,1,0,1,0,0,0
43,NM,Researcher,Researcher 1,"Yeah. I'm with you, man. Okay. I think that's all the questions. Is there anything else you want to add that we haven't touched on?",43,5,0,0,0,0,0,0,0,0,0,0
44,NM,Faculty,Thomas,"No. I think what you're doing is important. I think that AI, machine learning, reinforcement learning, neural networks aren't going anywhere. They're going to become a bigger entity and play a bigger role in society as time goes by. So the people that are really going to matter in terms of making sure that this works for other people, our youth, their kids, they're the ones that are going to actually have the big impact on being able to change this and understand it at a better level then people that are our age it. It starts with the education of the things that we're talking about, understanding how this can go wrong, understanding the errors so you're educated on that and you can avoid that. In many ways, I think what people like me and a lot of people that are similar to me, we just try to put bandaids on this because we're too far along on the road. And youth have the ability to not just put bandaids on things, they can actually fix things, I think.",44,5,0,1,0,1,1,1,1,0,1,1
45,NM,Researcher,Researcher 1,"Yeah. Yeah. I think so too. And they're so creative, the kids that ... All kids really, but the kids we're working with are just phenomenal. And once they get into it, they design such amazing things to help people. They're really interested in designing robots to help and robots for social good. So they're really understanding this stuff. And even if the goal is not for them to go be computer scientists or to go build these, but to have that fundamental understanding so they can be critical consumers, so they stop and say, wait, this is wrong. I need to say something. That's what we're hoping, obviously. I mean, we're not going to follow them, but we're hoping that what we do has a little bit of that impact anyway.",45,5,1,0,0,1,0,1,1,0,1,0
46,NM,Faculty,Thomas,"Yeah. No, that's super cool.",46,5,0,0,0,0,0,0,0,0,0,0
47,NM,Researcher,Researcher 1,"Well, thank you so much. This was very helpful. And thanks for reaching out to your students too. It's always good to see you and talk with you.",47,5,0,0,0,0,0,0,0,0,0,0
48,NM,Faculty,Thomas,"Yep. It's always good seeing you. It's nice seeing you again, Katherine. I hope you guys have a good weekend.",48,5,0,0,0,0,0,0,0,0,0,0
49,NM,Researcher,Researcher 1,Thank you. You too.,49,5,0,0,0,0,0,0,0,0,0,0
50,NM,Faculty,Thomas,Bye,50,5,0,0,0,0,0,0,0,0,0,0
51,NM,Researcher,Researcher 1,"Bye. All right, I'm going to stop the recording.",51,5,0,0,0,0,0,0,0,0,0,0
1,RZ,Researcher,Researcher 2,"All right. So today is Monday, January 31st, 2022, and we are interviewing Shi about AI and machine learning. So it's nice to meet you, Rui, thank you so much for volunteering to be a part of our interview and our city. So could you tell me a little bit about your professional background and work history?",1,6,0,0,0,0,0,0,0,0,0,0
2,RZ,Grad Student,Shi,"So I'm currently a fourth year PhD student in human centered computing, where we basically just study how humans interact with different technologies. And in our lab, our research focus is mainly human AI teams, human AI teaming. So we basically study how humans interact with AI teammates in a given environment like gaming, where AI is pretty common to see. And before that I did my bachelor and master in engineering. So basically it's kind of like the algorithm behind the thing. That's basically my background.",2,6,1,0,0,1,0,0,0,0,1,0
3,RZ,Researcher,Researcher 2,Would you mind telling me a little bit more about AI teaming?,3,6,1,0,0,0,0,0,0,0,0,0
4,RZ,Grad Student,Shi,"So basically the human AI teaming concept is that human and AI teammates coordinate and collaborate to finish a set of goals basically as [inaudible 00:01:32] goes. And what we have done previously is given environment norm in games and give them a series of team tasks that they need to either share information with AI or share with them and also receive information that shared by the AI teammates and finish the task. Or we have also done research where the AI has their own responsibility, but this you need to coordinate their tasks like connect with each other. So that they collaborate and finish the team go. So that's basically how we define human AI teams.",4,6,1,0,0,0,0,0,0,0,0,0
5,RZ,Researcher,Researcher 2,Thank you for that. That's really interesting.,5,6,0,0,0,0,0,0,0,0,0,0
6,RZ,Grad Student,Shi,No problem.,6,6,0,0,0,0,0,0,0,0,0,0
7,RZ,Researcher,Researcher 2,"I know you provided an example with games because that's probably what you work on, but do you know of any other examples with AI teaming that's outside of the gaming world?",7,6,1,0,0,0,0,0,0,0,0,0
8,RZ,Grad Student,Shi,"So a lot of times human... we would call it human AI collaboration when we don't really view AI as teammates. So we have a lot of actual human AI collaboration, examples, especially in data science that we use different models. Those actually are also machine learning algorithms, with those we basically consider is a tool. So it's not really human AI teaming but more like human AI collaboration. So currently not a lot. And that's actually why we choose game because you know, games, we have a lot of bots, but also I'm not sure whether you have heard of Open AI. It's basically a company, they created very intelligent AI teammates, but basically what they did was a team of AI and compete with humans instead of human and AI in a team. So I would say outside of games, not a lot, most of them AIs are just used as a tool to provide some prediction results or be used to help humans, but not really collaborate at the same level as a teammate.",8,6,1,1,0,1,0,0,0,0,1,1
9,RZ,Researcher,Researcher 2,"Yeah, that makes sense. That makes sense. Interesting. So I noticed you just mentioned maybe using AI to help humans. Do you know of ways that AI have helped humans and like what groups of humans have they been able to help?",9,6,1,0,0,0,0,0,0,0,0,0
10,RZ,Grad Student,Shi,"So there are several examples I think I can talk about the first one is Tesla, is a kind of AI driving. You can consider as a teamwork because their goal is to get to the destination safely or so, or you can consider it as AI, just easy to use as a tool to drive. So that could be an example of humans using AI to help them. And another one theory we use every day, Google home, that type of thing is also. We ask them okay, turn on the light or share what's the weather today. So that's another example of humans using AI to get the information and save their time. And I think also healthcare, I think I read papers before, but I don't really know examples in my life, but I think I have read that healthcare use machine learning, especially when diagnosing some images of humans. What is it called that kind of scanning pictures and can help them to diagnose whether it's benign or a bad cancer or so, and in addition to that that's most of the examples. And also I mentioned before data scientists that would use different models to help them predict things.",10,6,1,0,0,0,0,0,0,0,0,0
11,RZ,Researcher,Researcher 2,"Yeah, definitely. Those are great examples of ways that AI have helped us. So kind of on the reverse, what are ways that maybe AI has harmed us and who in particular have they harmed?",11,6,1,0,0,0,1,0,0,0,0,0
12,RZ,Grad Student,Shi,"So actually still Tesla, because we have heard about so many accidents because human, I think those people who totally trusted the AI to drive the car and caused, unfortunately, those accidents and even human death. And that's a really, I would say, the first, I say, jump into my mind when you said harm humans and I would say that's the special case. And a lot of others I would say is only when they provide inaccurate prediction results. That might harm a little bit, but that harm is not really human death or physical health, that severe, is more just maybe lower the human [inaudible 00:06:29] who used it a little bit. And actually in a research project I did last semester, we has a follow up interview after they interacted with AI teammates in the game. And we were asking them how they feel about AI taking actions without their command. And a lot of them, I feel, didn't like it. And it was like, now I even don't want AI to drive my car. It could cause really severe result like death. And also they didn't like surgery with healthcare related stuff that has AI involved because they don't trust AI to do that kind of things that I think may need a lot of thinking, like need to be flexible and change based on the situation. So I think those are potential harms and also harms we have seen in Tesla.",12,6,1,1,0,0,1,0,0,0,0,0
13,RZ,Researcher,Researcher 2,"Yeah. Those are great. So you've kind of touched on this a little bit, but could you tell me about your personal experience working with machine learning or artificial intelligence?",13,6,0,0,0,0,0,0,0,0,0,0
14,RZ,Grad Student,Shi,So you mean work or in my personal life?,14,6,0,0,0,0,0,0,0,0,0,0
15,RZ,Researcher,Researcher 2,Either one. You could highlight either or. ,15,6,0,0,0,0,0,0,0,0,0,0
16,RZ,Grad Student,Shi,"So in work, we mainly test actually how humans react to AI with different attributes, kind of like human, maybe talk a lot or maybe do a lot or different features. And sometimes actually we would use a wizard [inaudible 00:08:08] just because AI teammate means they need to coordinate at a higher level instead of just like, okay, I get the data and analyze it. I give you a prediction result. So it's more than that. And that's why a lot of times we would use wizard of OZ to try to make sure it's kind of controlled, all the variables, the confounding variables are controlled, especially in experiments. And so in addition to that, in terms of [inaudible 00:08:41] we have use. Normally it's the machine learning algorithm that's used to kind of give them an instruction in terms of how they react in different situations. And in terms of AI in personal life, I actually don't really trust AI that much. Siri on my phone is always off. I don't really use it and I don't have a Google home. I just don't feel very comfortable that it listens to my voice all the time. Although I'm not saying anything that cannot be heard, it's kind of a privacy issue, I guess. For instance, if my family member really wants to have one, I would be fine with it. Although I personally would not choose to have one, if that makes sense?",16,6,1,0,1,0,0,0,0,0,1,1
17,RZ,Researcher,Researcher 2,"Yeah, no, it does. No, you brought up a good point. Privacy is important, right? I mean, you don't always know who's behind these AI systems.",17,6,0,0,1,1,0,0,0,0,0,0
18,RZ,Grad Student,Shi,"It's just that Google home, it's when I feel there's a machine listening the whole time, I just feel like, no.",18,6,0,0,1,0,0,0,0,0,0,0
19,RZ,Researcher,Researcher 2,"I understand that. So going back a little bit to the work that you do with AI, what kind of problems have you encountered working with AI in the kind of settings that you do? So you typically work, I think, in games with teams. So what problems have you encountered?",19,6,0,0,0,0,0,0,0,0,0,0
20,RZ,Grad Student,Shi,Is there any specific problem you are interested in because problems are pretty broad?,20,6,0,0,0,0,0,0,0,0,0,0
21,RZ,Researcher,Researcher 2,"Well, maybe if you see a problem that could result in like a social or ethical issue or something that could be advantageous or harmful to the human population, maybe that will help refine it a little bit.",21,6,0,0,0,0,1,0,0,0,0,0
22,RZ,Grad Student,Shi,"Actually we just did a project last year regarding the ethical issues of AI. So we wanted to see how humans react to AI's ethical or unethical actions, decisions. And in terms of problems, that actually experiment, we used the Wizard of Oz. It was not real AI, but we structured into a very specific way so that it would say specific words and make specific decision that were predefined to control the experiment. And I would say one big thing of AI is, since it does not have the thinking ability, although we are trying to make it to learn and to think so a lot of times it cannot react flexibly. So that's actually, I think, the main constraint, no matter in communication, like text based communication or in making a decision. And I think in my research, we feel like a lot of times when the participants interact or collaborate with AI for a while, for instance, like half of the game, then they will feel like, okay, the AI has been doing that, finishes responsibility and the trust will be built, but their trust is kind of limited on AI doing that specific task. And in terms of concerns, it's just actually for us to just really hard to build, especially we focus more on understanding their interaction, human perception and experience. And in that case, that's actually a bit difficult for us to build a very intelligent AI to use in our experiment because that's more like computer science, they're what they do. So that's actually kind of a difficulty for us to find the platform that can meet the research needs with the AI that we need when we study different things.",22,6,0,1,0,0,1,0,0,1,0,0
23,RZ,Researcher,Researcher 2,"No, that's great. So if somebody were just to come up to you and ask you, how do you define AI? What would you tell them? How would you define it?",23,6,0,0,0,0,0,0,0,0,0,0
24,RZ,Grad Student,Shi,"I would say it's a computer or an agent that can take information and learn from it and make prediction or decision based on their ease. I don't know, learning process.",24,6,1,0,0,0,0,0,0,0,0,1
25,RZ,Researcher,Researcher 2,"So, kind of very similar, same question. How would you define machine learning?",25,6,0,0,0,0,0,0,0,0,0,0
26,RZ,Grad Student,Shi,"I would say my machine learning to me, my understanding is it's kind of the algorithm behind the scene. I consider artificial intelligence as kind of like with, how to say, a subject being there. It could be virtual, it could be a robot being there, but machine learning is more like the algorithm behind it. Kind of like its mind or core. That kind of feeling. It's kind of like if I use human as an example, it's just like artificial intelligence is a human and machine learning is kind of his brain to think, to help it to learn and make predictions.",26,6,1,0,0,0,0,0,0,0,1,0
27,RZ,Researcher,Researcher 2,"Awesome. Thank you, kind of got those. So how would you describe the people who are designing and distributing AI or machine learning applications and tools?",27,6,0,0,0,1,0,0,0,0,0,0
28,RZ,Grad Student,Shi,How would I describe them?,28,6,0,0,0,0,0,0,0,0,0,0
29,RZ,Researcher,Researcher 2,"The people that are creating, basically these AI materials and tools. You could think of it like demographically.",29,6,0,0,0,1,0,0,0,0,0,0
30,RZ,Grad Student,Shi,"Oh, demographically. I think I did actually, the first thought was people who are pretty good at programming and math probably, and who are interested in creating really advanced technology that's very smart. I can think about humans and demographic. I don't actually really have a thought of a specific group who design those. I would say just people who are good at programming and math or either one of those.",30,6,0,0,0,1,0,0,0,0,1,0
31,RZ,Researcher,Researcher 2,"Great. That's a good answer too. Let me, so what are your thoughts about youth learning AI or machine learning? So young people-",31,6,0,0,0,0,0,0,0,0,0,0
32,RZ,Grad Student,Shi,"Actually, I was surprised. I remember when I learned programming, I think I started learning programming after I went to college. The first year freshman, I feel like currently kids, they learn. They actually have the channels to interact with different technologies really early. They probably have a Google home or Siri on their mom or dad's phone or like their iPad or so. So I feel they're exposed to those advanced technologies, including machine learning or artificial intelligence a lot. And I feel like, I'm not sure, I know high school kids definitely learn programming. I'm not totally sure about middle school kids, but I would say even if it's not in school, they still have a lot of chance to interact with technologies. Not necessarily to learn how it works, but more just to get to know it. And I currently don't see, at least I haven't really thought about the harm of they learning machine learning at a really young age. There might be [inaudible 00:17:12] issues. I'm not sure, but I think they might trust more than we do. I don't really trust the Google, not trust, it's more like, I just don't feel very comfortable having Google home listening to my voice, but they probably got the young generation because they interacted with technologies much earlier than we did. So that might have built the trust in machine learning or artificial intelligence.",32,6,1,0,0,0,1,0,0,1,1,0
33,RZ,Researcher,Researcher 2,"What age, do you think we should start teaching them about AI and machine learning",33,6,0,0,0,0,0,0,0,0,0,0
34,RZ,Grad Student,Shi,That's a good question-what age,34,6,0,0,0,0,0,0,0,0,0,0
35,RZ,Researcher,Researcher 2,Or just introducing these concepts.,35,6,0,0,0,0,0,0,0,0,0,0
36,RZ,Grad Student,Shi,"I think high school would be good age. I think for me, I personally don't like elementary school because I think they're too young to kind of to think about the unethical side or so of artificial intelligence and a lot of times I feel like they haven't developed the ability to make decisions regarding how they use data either. So I'm not sure about middle school. I would say, I think high school will be fine. And also that will be the time they can develop to see whether they have interest in learning those. Rather as a future major or career or so.",36,6,0,0,0,0,1,0,0,0,1,0
37,RZ,Researcher,Researcher 2,I heard you mention that maybe elementary school would be too early to introduce the ethical issues. Do you think there's a way that we could introduce ethical and social issues at a younger age that would be appropriate?,37,6,0,0,0,0,1,0,0,0,0,0
38,RZ,Grad Student,Shi,"So the thing is, I would say if we could teach them the unethical side of no matter applying AI or just the potential unethical decision AI could make, because it's not perfect. But the problem is the ethical side of AI, I feel like it's still not well studied now. And that makes it more difficult for us to teach the kids an ethical side, because we even don't fully understand it or have a full picture of all the unethical aspects of AI. So I feel like currently probably still not very easy to do that, to teach them all the unethical sides.",38,6,0,0,0,0,1,1,0,0,0,0
39,RZ,Researcher,Researcher 2,"Thank you for those responses. Can you think of any tools, activities, or resources that could be used to help young people to start thinking about AI and machine learning and kind of the algorithms behind them?",39,6,0,0,0,0,0,0,0,0,1,0
40,RZ,Grad Student,Shi,"Um I would say, one way is to maybe if they have experienced interacting within the AI that does not make accurate or correct prediction results were like does not.  It's hard to say to achieve that ethic like act ethically because for us it's also important to protect them, you know is different from you telling that an adult saying okay see in this game that a teammate or like agent can make a decision that kills all the civilians in the game, we can't do that to Q, so that that is like more difficult, like how much information you could share with the keys, yeah.",40,6,0,1,0,0,1,0,0,0,0,0
41,RZ,Researcher,Researcher 2,"Yeah, I mean, I understand that so going off of what you said, what do you think it would be important for you to know about AI and machine learning like what are some key things that you think they should take or learn about not necessarily going into the ethical issues if you don't want to.",41,6,0,0,0,0,1,0,0,0,1,0
42,RZ,Grad Student,Shi,"I would say one way is to maybe if they have experienced interacting with an AI that does not make accurate or correct prediction result... It's hard to say to a kid that act unethically, because for kids it's also important to protect them. It's different from you telling an adult saying, okay, see, in this game that AI teammate, or agent could make a decision that kills all the civilians in the game. We can't do that to kids. So that is more difficult, like how much information you could share with the kids.",42,6,1,0,0,0,1,1,0,0,1,0
43,RZ,Researcher,Researcher 2,"I mean, I understand that. So going off of what you said, what do you think it would be important for youth to know about AI and machine learning? What are some key things that you think they should take or learn about not necessarily going into the ethical issues, if you don't want to think about that?",43,6,0,0,0,0,1,1,0,0,1,0
44,RZ,Grad Student,Shi,"I think one thing I'd like them to know is machine learning or artificial intelligence is not perfect. And although the goal may be to keep your, for instance, data private, but they may leak information too. They have the risk of doing that. It's different from a human who can kind of control that. Although we also have that risk, but artificial intelligence, it could be hacked too. So that could be something kids need to know. That if someone hacked through the system, they can go get all of her information and they can also make bad decisions, and accurate result or so. Inaccurate. So that type of thing I think will be good.",44,6,1,1,1,0,1,1,0,0,1,0
45,RZ,Researcher,Researcher 2,"Yeah. That makes a lot of sense. Going back to what you said a little bit earlier, you said that maybe presenting like a inaccurate data set or something that will produce an inaccurate prediction. Have you ever done that yourself? Have you ever tried to present that in your research or your teaching? I'm just curious if you've ever actually implemented that.",45,6,0,0,0,0,1,1,0,0,0,1
46,RZ,Grad Student,Shi,You mean to show the unethical or the not perfect side?,46,6,0,0,0,0,1,0,0,0,0,0
47,RZ,Researcher,Researcher 2,Yes.,47,6,0,0,0,0,0,0,0,0,0,0
48,RZ,Grad Student,Shi,"So what we have done before the [inaudible 00:22:25] study, I mentioned earlier in the interview, we presented one group actually was the unethical decision. So in that one we tried to present the potential harmful result could cause by AI's unethical decision. So that's the only one I would say I have encountered in my research.",48,6,1,0,0,0,1,0,0,0,0,0
49,RZ,Researcher,Researcher 2,"Would you mind describing that a little bit more, that project and kind of what happened and the people's perceptions of the unethical AI?",49,6,0,0,0,0,1,0,0,0,0,0
50,RZ,Grad Student,Shi,"So basically what we did was, there were two groups, one was the ethical decision or what we call ethical decision. And one was the one we called unethical decision and the ethical one, there would go, the AI's responsibility was to clear that area that has both enemies and civilians and the AI's responsibility was to clear the area so that their team could finish destroying some devices from the enemy side in the top. And the ethical AI, what they did was to try to use a way that does not harm civilians, but also attract the enemies to another direction or so. And the unethical one basically would just blow up the town so that civilians would die too. So that's pretty unethical in the common sense. So that's the two decisions we presented and interesting enough actually, probably because it's a game, although it was kind of like a simulation game which is close to real life. But a lot of participants, although they did say that they didn't trust the AI that much, but they still trusted the AI to fulfill its responsibility, which is to clear that town. So they still believe that the AI could do that, but they also know that his action was unethical. So it's like in general, the trust maybe decreased, but a part of the trust remained regarding its responsibility.",50,6,1,0,0,0,1,0,0,1,0,0
51,RZ,Researcher,Researcher 2,That's interesting. Thank you for sharing. I think that's all the questions I have for you. Do you have anything else you would like to add that we didn't touch on?,51,6,0,0,0,0,0,0,0,0,0,0
52,RZ,Grad Student,Shi,"Um, I don't have any questions now",52,6,0,0,0,0,0,0,0,0,0,0
53,RZ,Researcher,Researcher 2,Okay um well I'm gonna go ahead and stop the recording.  ,53,6,0,0,0,0,0,0,0,0,0,0
1,SA,Researcher,Researcher 2,"Alright, so today is February 7, 2022 and we are here with on address, and I thank you so much for agreeing to be interviewed. So, would you be able to tell me a little bit about your professional background and work history?",1,7,0,0,0,0,0,0,0,0,0,0
2,SA,Industry ,Matthew,"Yeah, absolutely. I'm a researcher at Microsoft Research in Redmond. I've been here for about five years. And before that I was a PhD student at University of Wisconsin studying computer science, probably, but I was working kind of on human robot interaction and doing a lot that was kind of based on understanding social gaze behavior of people and how to design social gaze mechanisms for robots. And so at Microsoft Research, I'm a research scientist and I'm kind of in a group that focuses on broad problems in AI. My focus is more on still on interaction. So I work in an area that my group calls situated interaction or situated intelligence, where we're very interested in understanding how to design AI systems that can interact with people in kind of everyday settings. So it encompasses human robot interaction. I've done stuff with human virtual agent interaction, stuff in mixed reality. But the idea is how do you combine multiple AI technologies and actually build real systems that can interact with people? So there's an element of studying interaction and studying people and studying social science and then studying the AI and how to actually build systems that can interact with people effectively.",2,7,1,0,0,1,0,0,0,0,1,0
3,SA,Researcher,Researcher 2,"Wow. That's really interesting. I guess I should have realized this, but I never really realized that Microsoft has its own research team. I didn't really think about that. So fascinating.",3,7,0,0,0,0,0,0,0,0,0,0
4,SA,Industry ,Matthew,"Yeah, yeah, they do. Yeah. So Microsoft Research, it's a big organization actually. And so I'm in the sort of flagship kind of headquarters of Microsoft Research, which is on the main Microsoft campus in Redmond. But there are also Microsoft Research labs in New York and Boston and Montreal, in China and India and in England.",4,7,0,0,0,0,0,0,0,0,0,0
5,SA,Researcher,Researcher 2,Makes sense. I just never thought of it.,5,7,0,0,0,0,0,0,0,0,0,0
6,SA,Industry ,Matthew,"Yeah. Yeah. It's cool. And what's interesting is it's almost like a broad computer science department that just happens to be at Microsoft. So there's a lot of us doing AI stuff, but it's kind of the whole spectrum of computer science research.",6,7,0,0,0,1,0,0,0,0,1,0
7,SA,Researcher,Researcher 2,Would you be able to tell me a little bit more about the work you did as a PhD student in Wisconsin?,7,7,0,0,0,0,0,0,0,0,0,0
8,SA,Industry ,Matthew,"Sure. Yeah. So, like I said, it was still on interaction, but it was much more focused on one particular cue, which was understanding social gaze behavior. So I was looking, and I actually was doing human robot interaction, but I was also doing stuff with virtual agents. And so there was a lot of reading social science and psychology literature on understanding what is known about how people use their gaze when they interact with each other, and when do they make eye contact? When do they look away? When do they use gaze to reference things that they're talking about? And what's the timing of that? And so there's lots of kind of patterns that are known from the literature of just human observational studies, but then they're not kind of often not really precise enough to sort of implement in an artificial system. If you need to design a robot or an agent that can follow those patterns, you need to know sort of frame by frame almost when should it look at the person, when should it look at an object if there's some kind of collaboration going on? When should it look away? So my methodology was kind of take what I can learn from literature, but then also occasionally bring people into the lab in pairs or in groups to do a task or to have a conversation with each other and kind of record their gaze behaviors and their head motions and their speech. And then doing a lot of, at that time, a lot of manual annotation to get more hard numbers and statistical distributions of, for example, when do they avert their gaze from each other, and then there'd be a process of, okay, can I turn that into kind of some kind of computational model that I can implement on a robot or an agent? And then there's a study where I bring people into the lab and at that time, it was basically just diadic, just one-on-one conversations. So it'd be one person talking with the robot. And maybe sometimes there is a task they had to do like a sorting task, or maybe sometimes it was more rapport building and just conversational. And I would measure if the robot that uses the distributions of gaze behavior that I learned from humans versus the robot that maybe just has static gaze or gazes randomly, which one results in better outcomes? Whether it's just how much did you like the robot, or task performance? How much did you learn if it was an educational scenario, or how quickly did you complete the task? So there was usually an array of different measures. But yeah, that was kind of generally the methodology that I followed. And so I've kind of studied three or four different mechanisms of gaze and did different studies like that.",8,7,1,0,0,1,0,0,0,0,1,0
9,SA,Researcher,Researcher 2,"That's interesting how that seems very applicable for AI, right. It could be implemented in a lot of different types of AI systems. Do you know any examples of AI systems that have been implemented? Or work areas like your work would be implemented? Wouldn't it be most AIs that have to work with humans or faces in a way?",9,7,1,0,0,0,0,0,0,0,0,0
10,SA,Industry ,Matthew,"Yeah, I mean, there isn't a lot though. I mean, obviously there's work that people are doing on human robot interaction, for example. If you want a robot to interact with people and it needs to detect where people are and it needs to have a conversation with them, it's very applicable to that. But I think a lot of work is more on... I mean, a lot of AI work isn't really interactive anyway. I mean, it's more about machine learning and developing better vision systems that can classify images or speech recognition systems that can classify speech, but not necessarily interactively. It's on a batch data set or all of these deep learning models for text generation, which is a little bit applied to text chat bots. So a lot of the interaction with AI is chat bots, I would say, which is written text, and there's no need to understand or no ability even to think about cues beyond what's coming in the text stream. The argument I make at Microsoft to why I think an input research is important is that those kinds of applications are coming and they're important and not enough people are working on them. And they've become really important in virtual reality, augmented reality, which everyone's very excited about these days. And of course in human robot interaction. If you want robots doing things with and alongside humans that they need to kind of not just gaze, but all sort of social cues, they need to be able to understand and participate in them. So I think there's a lot of applications that way, but it's not really what the field is focusing on as a whole, I would say.",10,7,1,1,0,0,0,0,0,0,1,1
11,SA,Researcher,Researcher 2,That's interesting. So then would you tell me a little bit about your experience that you've done working with either AI or machine learning?,11,7,0,0,0,0,0,0,0,0,1,0
12,SA,Industry ,Matthew,"Yeah. I consider myself a researcher that works on... I mean, AI, a lot of people have different definitions for it. I work broadly in AI and I would say I'm a user of machine learning because the kind of AI work is not necessarily developing new kinds of machine learning techniques or developing the next big, deep learning breakthrough, which a lot of research is, especially at Microsoft Research. But I'm kind of interested in having a goal of an interactive system that can do something and then thinking about what are the abilities it needs. Okay. It needs to speak, it needs to talk to people. It needs to understand speech. So there are machine learning models that can do that. It needs vision. It needs to be able to see people and it needs to be able to see objects. So, okay. What are the best computer vision models out there that I can use? So I'm constantly kind of on the lookout for what's the state of the art for a lot of different kinds of machine learning models. And then my research is on how do I bring them together and kind of integrate them into a larger system, an end to end system, an interactive intelligence system. Because a lot of machine learning is kind of, you focus on one sort of wedge or one sort of competency like speech or vision or whatever. And so I'm interested in... And that's great, but how do you actually bring those together into end to end systems, which is its own science I would say.",12,7,1,0,0,1,0,0,0,0,1,0
13,SA,Researcher,Researcher 2,"Yeah, that's a lot. That's a lot of work to do to create that. Especially when you said there's not that many people doing it. So that's fascinating. You kind of mentioned this. You said that everybody has different definitions. So I'm curious, what is your definition of AI?",13,7,0,0,0,0,0,0,0,0,0,0
14,SA,Industry ,Matthew,My definition of AI?,14,7,0,0,0,0,0,0,0,0,0,0
15,SA,Researcher,Researcher 2,Yes.,15,7,0,0,0,0,0,0,0,0,0,0
16,SA,Industry ,Matthew,"I mean, I would say it's broadly sort of the study of how to get computers and technologies to do things that humans would regard as intelligent. And I don't know. I say it like that, because I think it's sometimes a shifting boundary. Sometimes AI will accomplish something in AI and then people are like, wow, maybe that wasn't actually that intelligent after all. But I would say murkily, it's getting computers to do things that human humans would see as intelligent.",16,7,1,0,0,0,0,0,0,0,1,1
17,SA,Researcher,Researcher 2,"So, same kind of question, but how would you define machine learning. ",17,7,0,0,0,0,0,0,0,0,0,0
18,SA,Industry ,Matthew,"Well, machine learning is one technique within AI to develop sort of intelligent applications or competencies that are driven by data sets and statistics really.",18,7,0,0,0,0,0,0,0,0,0,1
19,SA,Researcher,Researcher 2,"So how advances either AI or machine learning harm us, harm human beings? ",19,7,0,0,0,0,1,0,0,0,0,0
20,SA,Industry ,Matthew,Do they harm us?,20,7,0,0,0,0,0,0,0,0,0,0
21,SA,Researcher,Researcher 2,Yes. How do they harm us and who in particular do they harm?,21,7,0,0,0,0,1,0,0,0,0,0
22,SA,Industry ,Matthew,"I don't know. I mean they have that potential to harm anyone based on how they're used. I mean there are potential ethical harms and potential harms of discrimination. I think there are potential harms, especially in machine learning of not getting enough informed consent from the data that you're using. Not having a good approach for actually collecting the data that you build off of and then not having a good understanding of where the data even came from that you build off of, especially when you're doing things like scraping all of Reddit to build a chat bot and not ever taking the time to read oh, what's in this data set? Maybe people say not nice things once in a while. Scraping all of Twitter. It's even worse. So I think there are unintended harms that come from sort of sloppiness of using data that you're not sure of it's prominence. And then I think there are harms of sort of over promising what AI can do and over trusting it and deploying it in situations that have real effects, potentially positive or negative effects on people's lives and sort of over trusting the decisions that AI makes without again having an understanding of how it's coming to those decisions. And that's where you get into topics like transparency and interpretability of AI models. And when you deploy these sort of black box models, that it's really okay how it's coming to these decisions. There's a lot of potential harm there.",22,7,0,1,1,1,1,0,0,1,0,1
23,SA,Researcher,Researcher 2,Do you have any examples of a way that AI or machine learning has harmed people and who have they harmed? ,23,7,0,0,0,0,1,0,0,0,0,0
24,SA,Industry ,Matthew,"There are the classic examples of models being used in credit, in banking situations on determining who can get credit or not. In judicial scenarios of determining who's likely to re offend in a criminal case. And studies have shown how often these decision making systems are heavily biased, right? Because they're built off of bias data. They're basically taking data that has been used in these sorts of decisions over the years and then just kind of reproducing and amplifying those patterns and the original patterns were usually biased in some way, in terms of race and gender often. And so often that those get, like I said, reproduced and amplified. So there are these key sort of decision making scenarios that I think they've had harms.",24,7,1,0,0,0,1,0,1,0,0,1
25,SA,Researcher,Researcher 2,"So, on a brighter side, how do advances on AI and machine learning help us and who, in particular, do they help?",25,7,0,0,0,0,0,0,0,0,0,0
26,SA,Industry ,Matthew,"Geez. Hopefully they help everyone. I don't know. I mean, I just see it as, it's like any technology, I mean it has the potential to increase human productivity. It has the potential to increase human collaboration, creativity. I don't know. It's hard to answer because I think there's so many different kinds of technology that you could lump under AI and it's almost like who's helped by computers?",26,7,1,0,0,0,0,0,0,0,0,0
27,SA,Researcher,Researcher 2,Yeah.,27,7,0,0,0,0,0,0,0,0,0,0
28,SA,Industry ,Matthew,Potentially everyone. I think there's a lot of promise and therapy and education and lots of places.,28,7,1,0,0,0,0,0,0,0,0,0
29,SA,Researcher,Researcher 2,"Awesome.  I'm kind of switching gears a little bit, what are your thoughts about youth learning about AI and machine learning?",29,7,0,0,0,0,0,0,0,0,1,0
30,SA,Industry ,Matthew,I think that's great. I think I think they absolutely should.,30,7,0,0,0,0,0,0,0,0,0,0
31,SA,Researcher,Researcher 2,Is there a particular age that you think we should start being introduced to these concepts?,31,7,0,0,0,0,0,0,0,0,0,0
32,SA,Industry ,Matthew,"I think you can introduce it pretty young depending on how you do it. I taught a fourth and fifth grade after school class on computer science and programming and we were just kind of learning about how to do programming and scratch and they were making little games, but it was more about kind of how do you... It's about computational thinking, right? It's how do you break a problem down and think of a solution step by step and those are pretty young kids. And I think the idea of extending that to how can you think about machines or computers that are intelligent and what does it mean to kind of have a system learned from examples rather than telling it instructions step by step? I think you can start to kind of explain those concepts at a pretty young age, at a high level. You don't need to get into the weeds of a deep learning algorithm or anything even at the high school level. I don't think it's important to kind of get into the details of how any particular ML algorithm is built. But I think it's important to think about just what does it even mean to have a machine learning model and what does it mean to learn from data and learning about the importance of knowing where the data comes from and blah, blah, blah. So I think it could be pretty early.",32,7,0,0,0,1,0,0,0,0,1,1
33,SA,Researcher,Researcher 2,"Good. I mean that's fascinating. That's great. So you touched on the fact that you had some experience teaching young people about computer science. If you were going to teach, just think about what you could do if you were going to teach some young people about machine learning or AI, what type of activities or resources would you maybe use in order to do that?",33,7,0,0,0,0,0,0,0,0,1,0
34,SA,Industry ,Matthew,"I mean, I've seen some online little tools that looked fun where you learn about the concept by having... But it's very interactive and hands-on. And you'll start with, how do you develop a system that learns the difference between cats and dogs? Well here, let's find some pictures of cats and let's find some pictures of dogs and let's click on them and label these as cats and let's click on these and label them as dogs. And then here's this, for now with this seemingly kind of magic algorithm that I'll start to learn the difference between cats and dogs. And then you can start to go into it from there. Okay, why do you need labels? What are labels? Why do you need to kind of separate, train your model and this, and then test it on some data that's over here that's been held out. What does it mean? How do you know how well it's doing? What does it mean to evaluate? So I would just start with some simple problems like that and then try to build into just the concepts around the whole pipeline. Not the particular algorithm or back propagation or anything like that.",34,7,1,0,0,1,0,0,0,0,1,1
35,SA,Researcher,Researcher 2,Yeah. Just teach the basics. That makes a lot of sense. So what are your thoughts about youth learning or youth being introduced to some of the ethical or social issues around AI and machine learning?,35,7,0,0,0,0,1,1,0,0,1,0
36,SA,Industry ,Matthew,"Oh, I think it's super important. And I think that should be right with lesson number one. I mean, especially with machine learning, because again machine learning is algorithms that are trained on data and the data has to come from somewhere. And so there's the ethical questions around where does the data come from? And there are ethical questions of when someone's going to use this algorithm, this model. And so where are they going to use it? Who's going to use it? What are they going to use it for? So I think those are really important just to talk about early, I would say.",36,7,0,0,0,1,1,1,1,0,1,1
37,SA,Researcher,Researcher 2,"So, can you think of any way that we can help you connect these topics to their everyday lives and make it meaningful to them?",37,7,0,0,0,0,0,0,0,0,0,0
38,SA,Industry ,Matthew,I don't know. I'd have to think. I'm not sure.,38,7,0,0,0,0,0,0,0,0,0,0
39,SA,Researcher,Researcher 2,"Yeah. That's a hard one. Especially if you don't interact with youth regularly, it might be difficult.",39,7,0,0,0,0,0,0,0,0,0,0
40,SA,Industry ,Matthew,"Yeah, I don't. It's been a while. I don't know...do something with tick tock?",40,7,1,0,0,0,0,0,0,0,0,0
41,SA,Researcher,Researcher 2,"Yeah. We have thought of that, integrating Snapchat filters or something like that. Something that they would be interested in.",41,7,1,0,0,0,0,0,0,0,0,0
42,SA,Industry ,Matthew,Are you talking about just learning AI and ML in general or the ethical issues?,42,7,0,0,0,0,1,1,0,0,1,0
43,SA,Researcher,Researcher 2,"Either or. So we're going to try to integrate them. So if we can integrate them, I think that would be best. But...",43,7,0,0,0,0,0,0,0,0,0,0
44,SA,Industry ,Matthew,"Yeah. I feel like there's so much you could talk about that's just here are all things that you use every day that are using some kind of AI or ML, like Snapchat filters, right? There are machine learning model. How is that possible? Taking the time to think about what enabled that? How is this working? And then with the ethical issues, I don't know. There's a news story every week that you could connect to. So I feel like connecting to things that are happening and big stories that are in the news I think would probably be what's most engaging, I would guess.",44,7,1,0,0,0,1,0,0,0,1,0
45,SA,Researcher,Researcher 2,Thank you. So how did you start to be interested in AI machine learning? Did it start when you were young or at what point did you start being interested in all of this?,45,7,0,0,0,0,0,0,0,0,0,0
46,SA,Industry ,Matthew,"I mean, I got into computer science generally. I was interested in computer games, video games. I was kind of interested in the AI that goes into all the games and the enemies that you fight against or whatever. But I started out more interested in graphics and animation and my undergrad was more, I took more classes that are about computer graphics and animation with a little bit of AI, just kind of out of interest. But then in grad school, it was really just in talking with some of the potential professors that were there that I could work with. So my main advisor [inaudible 00:23:30] he kind of really started to introduce me to some of the ideas of, HCI and just thinking about interaction and thinking about how to... Because I was still interested in animation and animated characters, but thinking about how could you actually design animated characters that interact with people? And so I just got super interested in thinking about how does interaction work and then more and more interested in how does humans' social interaction work in the first place? It's so complex. So my passion has become understanding as much as I can about human social interaction and how to computationalize it enough that you can start to develop intelligence systems that participate in that.",46,7,1,0,0,1,0,0,0,0,1,0
47,SA,Researcher,Researcher 2,"Yeah. That's fascinating. That's what we're hoping to do is get some students, well not every student is going to be somebody who researches AI, but at least they'll be critical consumers. Right?",47,7,0,0,0,0,0,0,0,0,0,0
48,SA,Industry ,Matthew,Right. Yeah. That's the most important thing.,48,7,0,0,0,0,0,0,0,0,0,0
49,SA,Researcher,Researcher 2,"Exactly. So as somebody who works with AI and other people who work with AI, how would you describe the people who are designing and distributing AI or machine learning applications and tools?",49,7,0,0,0,1,0,0,0,0,0,0
50,SA,Industry ,Matthew,How would I describe them? Who is doing it?,50,7,0,0,0,0,0,0,0,0,0,0
51,SA,Researcher,Researcher 2,Mm-hmm (affirmative).,51,7,0,0,0,0,0,0,0,0,0,0
52,SA,Industry ,Matthew,"I don't know. Engineers. They're engineers. I'm more on the research side of things. So there's a lot of research happening obviously at universities. But I think that in terms of who's actually developing applications and tools that requires more engineering resources and more computational power that often universities unfortunately don't have. So it's a lot of institutions like Google and Microsoft and Facebook and Apple and Amazon. And so it's a lot of the big tech companies are the ones that are producing the applications and the technologies. Another thing that I work a lot on is on open source tools. And I would like to democratize that a little bit more. I wish it was. But I think right now, a lot of the main AI systems and ML tools are definitely kind of sequestered in the top five tech companies basically.",52,7,0,0,0,1,0,0,0,0,0,0
53,SA,Researcher,Researcher 2,"Yeah, yeah. That's how it's going to be now, but who knows what it'll be in the future, right?",53,7,0,0,0,0,0,0,0,0,0,0
54,SA,Industry ,Matthew,Yeah,54,7,0,0,0,0,0,0,0,0,0,0
55,SA,Researcher,Researcher 2,"So my last question for you, because you work at Microsoft and do research for Microsoft, do you know of any applications or tools that Microsoft has to help people learn about machine learning or AI and any maybe tools that are directly related to children learning about machine learning or AI?",55,7,0,0,0,0,0,0,0,0,0,0
56,SA,Industry ,Matthew,"I have to think. And I can maybe send you some links, but I know there's research going on, for example, because Microsoft owns Minecraft. There's research going on. I think they've released it as... But there's really research going on like how do you do reinforcement learning in Minecraft? How do you use Minecraft to create intelligent agents? And I think they've released tools and things that people can explore that on their own with Minecraft. So that's one thing. There's another project that comes to mind. I think it's called Make Code. I don't know. Is that a thing? Let me look really quick. I thought that has some element of... Oh this also has something to do with Minecraft, I guess. Microsoft free online learn to code platform. Yeah. So let me send you this link.",56,7,1,0,0,1,0,0,0,0,1,0
57,SA,Researcher,Researcher 2,Awesome. Thank you.  Appreciate it.,57,7,0,0,0,0,0,0,0,0,0,0
58,SA,Industry ,Matthew,"So this is another kind of project that I remember seeing out of Microsoft Research. And it's about coding in general, I think and computer science, but I think it gets into some things that have some AI. So yeah, I think that those are the places I'd start.",58,7,0,0,0,0,0,0,0,0,1,0
59,SA,Researcher,Researcher 2,"Oh yeah great Thank you um is there anything else, that you would like to add that we haven't touched on yet",59,7,0,0,0,0,0,0,0,0,0,0
60,SA,Industry ,Matthew,"Um, no not really. I mean, I'm curious to hear more about like what the overall goals of this project that you guys are working on.",60,7,0,0,0,0,0,0,0,0,0,0
61,SA,Researcher,Researcher 2,"Um, let me stop the recording and then I'll go ahead and get into that.  ",61,7,0,0,0,0,0,0,0,0,0,0
1,BS,Researcher,Researcher 2,"Hi. Today is Friday, February 4th, 2022. And we are with Jerry. Thank you Beau again, for volunteering. Would you tell me a little bit about your professional background and work history?",1,8,0,0,0,0,0,0,0,0,0,0
2,BS,Grad Student,Jerry,"Sure. Basically, I have not been officially in the working world yet. I did my undergrad in psychology in University and graduated December of 2018. Then my current grad program, which is in human-centered computing, did not start until the fall. So, I was a substitute teacher at a middle school for that whole semester. And then over the summer, I just kind of take a break, went to Europe, all that good stuff. Then I started in the fall and I've been a research assistant ever since, working on human-AI teaming projects. Specifically, my research is on team cognition in human-AI teams.  I don't know, we can get more into the weeds with that, but the only other professional work experience I have is working at a light during internship my junior year of undergrad. And they did benefits management stuff. To be honest with you, I know this is a bad AI. Basically, their entire company could go away because they... I don't know, my job, it was just so much data management and it's crazy because they hire people with four-year degrees to do these jobs that you could basically do a Python script for.",2,8,1,0,0,1,0,0,0,0,1,0
3,BS,Researcher,Researcher 2,Not pay these people's salaries.,3,8,0,0,0,0,0,0,0,0,0,0
4,BS,Grad Student,Jerry,Literally,4,8,0,0,0,0,0,0,0,0,0,0
5,BS,Researcher,Researcher 2,That's interesting. How did you actually... I know you said you had a psychology degree from University and then you kind of moved into the human-centered computing program. What made you interested in that? How did you become interested in working with AI and machine learning?,5,8,0,0,0,0,0,0,0,0,1,0
6,BS,Grad Student,Jerry,"I pretty much always wanted to be more in the realm of technology and computer science, but also just really working with people. I was a little intimidated by computer science as a field at first. So, I went with psych. And then, I always knew I wanted to go to grad school. And so, I was originally thinking a good marriage between the two would be human factor psychology, because that is also very involved with technology and design and development. But I didn't even know about the human-centered computing program until my current advisor, I found some papers by him that were about human-AI teaming and team cognition in those teams. And so, I reached out to him and the lab that I was working at the time, I did a collaboration with Nathan and he basically just reached out at me and was like, ""Hey, I'd like to have you in the lab. What do you think?"" And I'm thinking to myself, ""Oh, this is an opportunity to get to learn computer science and be a little bit more involved in that and still retain the usefulness of my undergrad."" So, I jumped right at that opportunity.",6,8,1,0,0,0,0,0,0,0,1,0
7,BS,Researcher,Researcher 2,"Wow. Yeah. That sounds like great opportunity for you to just be presented with it. I mean, that's fantastic. It also shows your value, right? That he thought that you-",7,8,0,0,0,0,0,0,0,0,0,0
8,BS,Grad Student,Jerry,"I always was surprised by how personal grad school really is, between the advisor and the student. And when you're applying too. Basically, if a professor wants you and wants you to be accepted in the program, it's basically all you need. It's really weird. It kind of threw me for a loop when I was learning about that.",8,8,0,0,0,0,0,0,0,0,0,0
9,BS,Researcher,Researcher 2,"It's definitely different than undergrad. I got my undergrad at University too, in genetics. So, I understand. I'm doing a similar thing as you. Would you tell me a little bit more about your AI teaming and cognition, your research, what you're studying?",9,8,1,0,0,0,0,0,0,0,1,0
10,BS,Grad Student,Jerry,"Sure. All the research I've done up to this point has been looking at basically what does team cognition currently look in human-AI teams? I did a study on the role of spatial awareness or the availability of spatial information. And then I did another study that was essentially just looking at, it was pretty exploratory in the fact that I just studied or I just collected measures of shared mental models, along with trust and a bunch of qualitative data. So, for the objective measure, I say objective, but it's hard to actually measure a construct like that objectively. We didn't get anything on the objective measures, but the qualitative data that we got was really interesting. The perceived team cognition too is lower when you're working with AI, which I thought was pretty interesting. And then, there was lower trust as well. And it gets worse when you work with two AIS and you're the only human. When you become a minority member of the team, versus when it's two humans and one AI. So, that's where my research has been. And basically what I want to move into is how to develop, or figuring out what qualities an AI can have that is going to best support shared understanding between humans in a human-AI team. And then going that extra step and creating basically a shared mental model of the AI teammate and its operation. And that sounds a lot like AI explainability and transparency, but I think you take it a step further in making sure that both human teammates have a shared understanding of that. You know, I can go deep into the weeds in terms of the theory behind it, because you got task mental models and team mental models, and I'm kind proposing that there should be a AI teammate mental model that the humans can share, but basically developing AI that are going to support the more traditional aspects of shared understanding for humans. And then also developing them in a way that makes it easy for the humans to develop a mental model of the AI teammate, because you know, working with AI is very different. They are very smart and very stupid at the same time.",10,8,1,1,0,1,0,0,0,1,0,0
11,BS,Researcher,Researcher 2,"That's very true. Very true. That's interesting. Yeah. Thank you for sharing that. Just a personal question. When you were talking about the trust within the human team member and the AI team members, they were aware that they were working with AI, correct? Or were they... Okay. Just curious. I wonder, do you think the humans would be able to figure out they're working with AI if they didn't know that the person, the teammate was an AI teammate? This is just a personal question. Just curious.",11,8,0,0,0,0,0,0,0,1,0,0
12,BS,Grad Student,Jerry,"It kind of depends. If communication's involved, they can figure it out pretty easily. I know what you're trying to propose and that is an experiment that I think would be really cool. And I actually do know somebody that's doing something with that, but I think most people will be able to figure out that they're working with an AI teammate if they're even just textually communicating. Because you know, everybody knows natural language processing is so bad, but I actually did run a study where I used participant confederates. I had them act as the Wizard of Oz. I had them play with two other individuals. They didn't communicate. That's what kept the deception alive. But they were in a team of three and they were working with two other participants and I told everybody they were working with two other AI. And just because I had told them that they were working with AI, it changed a lot of things and they actually performed much worse. Whereas, had the same exact setup, but I just told them, ""Hey, you're all working together. You're all human.""",12,8,0,1,0,0,0,0,0,1,0,0
13,BS,Researcher,Researcher 2,"Oh, that's fascinating. That's interesting.",13,8,0,0,0,0,0,0,0,0,0,0
14,BS,Grad Student,Jerry,Just the perception of working with an AI really changed what they did.,14,8,0,0,0,1,0,0,0,0,0,0
15,BS,Researcher,Researcher 2,"That's really interesting. I'm new to the AI world, so I appreciate all this information. It's just fascinating to me.",15,8,0,0,0,0,0,0,0,0,0,0
16,BS,Grad Student,Jerry,I think it's so cool. ,16,8,0,0,0,0,0,0,0,0,0,0
17,BS,Researcher,Researcher 2,"It is. I mean, my background's in genetics, so very different, but very interesting. If somebody came up to you and asked you to define AI, how would you define it?",17,8,0,0,0,0,0,0,0,0,0,0
18,BS,Grad Student,Jerry,"I have to do this pretty somewhat frequently with... Anytime my parents are always like, ""Hey, Beau, tell me what you do,"" and stuff. And I'm like, ""Oh, AI."" ""Oh, what do you mean?"" Basically, AI, I always just kind of want to call it any kind of computer program or algorithm or anything that can basically teach itself and improve over time. Just any program that teaches itself to do something or achieve a goal or become more efficient.",18,8,0,0,0,0,0,0,0,0,1,1
19,BS,Researcher,Researcher 2,"Yeah. So, then, how would you define machine learning, because I know, sometimes some people use them interchangeably-some people don't. So, what is your definition of machine learning?",19,8,0,0,0,0,0,0,0,0,0,0
20,BS,Grad Student,Jerry,"For machine learning, it's just a subset of AI and the fact that it kind of pulls from a bunch of different fields, like statistics and operations management and stuff. Basically machine learning, there's a lot of... You could take big data, the term big data and just throw machine learning at it. Machine learning is something that's going to pull value from that data by itself.",20,8,0,0,0,0,0,0,0,0,0,1
21,BS,Researcher,Researcher 2,"Okay, great. Thank you. What are some current issues or trends that you see in AI and machine learning? Do you see any issues or concerns?",21,8,0,0,0,0,0,0,0,0,0,0
22,BS,Grad Student,Jerry,"There's a huge issue of ethics and bias that goes right along with that. It's really hard, obviously, to ensure that anything that humans implement, even if they're our own policies, it's hard enough to make sure that those aren't biased and disparaging any one group disproportionately. That is a major problem because we would like to offload a lot of decision-making to AI, to free us up for other tasks. So, being able to actively target, no, find target and mitigate biases in AI is a huge major problem. And I also think ethics is a huge issue. I think it is somewhat separate from bias because with ethics you got, I don't know. I don't know why I always go to zero to 100, but with ethics, I think of life and death decisions and that's something that Tesla and any car company that's trying to do autonomous driving is going to end up having to deal with, at some point. Everybody's kind of been avoiding it, especially with self-driving vehicles, but there was a NATO report last year. I actually just used it in a paper. I cited the report where an AI program on a combat drone, literally... They didn't outright say it killed somebody, but they were like, ""It was trying to.""",22,8,1,1,0,1,1,1,0,0,0,0
23,BS,Researcher,Researcher 2,Oh.,23,8,0,0,0,0,0,0,0,0,0,0
24,BS,Grad Student,Jerry,"And it was not connected to a human, so there was no human to intervene in its decision-making. It was disconnected from its operators at the time.",24,8,0,1,0,1,0,0,0,0,0,0
25,BS,Researcher,Researcher 2,Yeah that's definitely an ethical issue that we need to encounter. ,25,8,0,0,0,0,1,0,0,0,0,0
26,BS,Grad Student,Jerry,"I think that's a huge, huge issue. ",26,8,0,0,0,0,0,0,0,0,0,0
27,BS,Researcher,Researcher 2,"Do you have an example? You provided an example of the ethical issue. Do you have an example of the other issue, a more social issue?",27,8,0,0,0,0,1,0,0,0,0,0
28,BS,Grad Student,Jerry,"Yeah. With bias, the there's a famous Facebook, one where they're serving ads for higher paying jobs to more men than women. There's other ones where they're predictive policing. The algorithm AI will tell officers to target more communities of color and not the communities of... it's the inverse of minority and majority. And then there's another one. Oh. That they have AI algorithms that try and identify candidates for parole. And it'll say that African American individuals are 40% more likely to repeat offend, even though the human will look at the data and be like, ""That's not my experience. That's not the case. That's not true."" Things like that.",28,8,1,0,0,0,1,0,0,0,1,0
29,BS,Researcher,Researcher 2,"I actually, have never heard of the last one before so that was interesting",29,8,0,0,0,0,0,0,0,0,0,0
30,BS,Grad Student,Jerry,"I think it's in a paper that... You're friends with Caitlin, right?",30,8,0,0,0,0,0,0,0,0,0,0
31,BS,Researcher,Researcher 2,"Yeah.  Yeah, I am.",31,8,0,0,0,0,0,0,0,0,0,0
32,BS,Grad Student,Jerry,Yeah. I think it's in a paper of theirs that they just submitted so they could [inaudible 00:14:14] you with the actual citation.,32,8,0,0,0,0,0,0,0,0,0,0
33,BS,Researcher,Researcher 2,Yeah. I'll ask her about that. What type of people are designing and distributing these AI and machine learning applications and tools?,33,8,0,0,0,1,0,0,0,0,0,0
34,BS,Grad Student,Jerry,"For the most part, people that don't have a lot of experience in these issues that are really important. To be honest with you, I don't think there's enough representation from the different fields and perspectives and groups of people that need to be there making those decisions and/or developing these things. You know, AI started out as such a niche aspect of computer science and it's just ballooned into something that basically every single field needs to have their hands on. So, it's a challenge too though, because it's hard for computer science individuals to communicate and convey how these things work to individuals in other fields and to just the general public. The general public has a lot of misconceptions about what AI can and can't do. What was the original question?",34,8,1,1,0,1,0,0,0,0,0,0
35,BS,Researcher,Researcher 2,What sort of like people are designing or distributing these?,35,8,0,0,0,1,0,0,0,0,0,0
36,BS,Grad Student,Jerry,"Okay, I answered that",36,8,0,0,0,0,0,0,0,0,0,0
37,BS,Researcher,Researcher 2,"Yeah, you did. I think you did. Oh, cute cat.",37,8,0,0,0,0,0,0,0,0,0,0
38,BS,Grad Student,Jerry,"Thank you. His name's Weezy, after... We got him, I think when No Ceilings dropped, so it is after Lil Wayne.",38,8,0,0,0,0,0,0,0,0,0,0
39,BS,Researcher,Researcher 2,That's awesome. I love that. What are your thoughts about youth learning about AI or machine learning?,39,8,0,0,0,0,0,0,0,0,1,0
40,BS,Grad Student,Jerry,"I think it's wildly important. I don't think that programming should be something you go to college for. I think this is something that everybody should learn. It literally should just be like typing class. And I think AI should be... I don't know. Because some people, I don't know, I don't want to make people go that deep into something that they might not be that interested in. You know, I think everybody should learn programming because I think it'll become somewhat of a basic skill too. But actually, you know what, we got AI that are starting to program now and you got the discussion that manual programming is going to become obsolete because AI can program everything. So, that just kind of speaks to the complexity of what AI represents. I think it should be included more in the curriculum. I'll meet in the middle. I think it should be included more in the curriculum. I might not put it as an entire class. However, I do think that children should be given many more opportunities to learn about these technical things than they currently are. I think we should give them more to challenge them with. I think kids can do a lot more than we think they can.",40,8,1,0,0,0,0,0,0,0,1,0
41,BS,Researcher,Researcher 2,"I agree, I agree, so what age, do you think it would be appropriate to start introducing these concepts to young people",41,8,0,0,0,0,0,0,0,0,0,0
42,BS,Grad Student,Jerry,"You know there's different ways to like introduce these things like you can introduce you know the concepts of AI to elementary school or elementary aged children, and then you know, just as they grow in the middle school and high school.  Those concepts can be expanded upon and elaborated, and you can get into those details.  And the specifics like when I substitute teacher who there I can't remember her name, I think it was very she has shared like technology class and she was a you know it's like physical programming, where you have the little robot that you guys along the line you know so like you know, an elementary school, you can-Yeah, you can talk to him about what.  You know what these.  Like how basically how these devices function, you know, probably not get super in depth with it, but like you know, once you get a middle school, you can start talking to them about  more advanced aspects, like the you know physical programming that my name is Barry was trying to show them, and you know, in the in the high school, you can really kind of get down to the nitty gritty.  So I think I think it should be taught at all ages, but obviously it should just follow the curve of development",42,8,0,0,0,0,0,0,0,0,1,0
43,BS,Researcher,Researcher 2,I agree. I agree. What age do you think it would be appropriate to start introducing these concepts to young people?,43,8,0,0,0,0,0,0,0,0,0,0
44,BS,Grad Student,Jerry,"You know, there's a lot of different ways to introduce these things. You can introduce the concepts of AI to elementary school or elementary age children. And then, just as they grow into middle school and high school, those concepts can be expanded upon and elaborated and you can get into those details and the specifics. When I was a substitute teacher over there, I can't remember her name. I think it was Ms. Barry. She had the technology class and she was... It's like physical programming where you have the little robot that goes along the line. In elementary school you can… Yeah, you can talk to them about basically how these devices function, probably not get super in-depth with it. But once you get to middle school, you can start talking to them about more advanced aspects like the physical programming that Ms. Barry was trying to show them. And once you get into high school, you can really kind of get down to the nitty-gritty. So, I think it should be taught at all ages, but obviously it should just follow the curve of development.",44,8,0,0,0,1,0,0,0,0,1,0
45,BS,Researcher,Researcher 2,Yeah. That makes a lot of sense. What do you think is the most important things that you should know about with AI and machine learning?,45,8,0,0,0,0,0,0,0,0,1,0
46,BS,Grad Student,Jerry,"Trying to think. The first thing that jumps to my mind is that any of these algorithms is responding to you and your digital choices, I guess. The importance of their data, and I know the erosion of privacy or the apathy towards the erosion of our privacy is continuing. I'm trying to think. I'm not sure how to teach people about things that are going to... or how to teach the youth about issues of ethics and bias because being involved in that conversation, I don't know. It requires, like we were talking about... I don't know, it's just hard to teach kids, I feel like. Those are hard topics to broach. And so, I'm thinking that might be something restricted to like high school, but I don't know. The sooner you start teaching things to kids the better, because they have continual reinforcement throughout all of their years. I don't know. What do you think? How do we teach kids concepts like that?",46,8,0,0,1,1,1,1,0,0,1,1
47,BS,Researcher,Researcher 2,"Well, that's one of the reason we're interviewing all of you, is because we're trying to create a tool to help teach young children or young people about machine learning and AI and hopefully integrate some social and ethical issues into that. That's our goal, is that we're trying to figure out how to do that. Do you have any ideas of games or resources that you've seen that engage youth in these kinds of conversations or just conversations about AI or machine learning?",47,8,0,0,0,1,0,1,0,0,1,0
48,BS,Grad Student,Jerry,"Hmm. I think kids would probably always like to use... I remember when I was a kid, a chat bot was something that was super cool to me. And that is something, I'm sure when I was a kid probably not even close to being actually, it was probably just a self-programmed expert system or... oh gosh, I don't even remember what to call it. It's a certain type of algorithm. But OpenAI has a program called GTP-3 that you can play around with. It's really cool. It's the most advanced national language processing algorithm in the world. And that is something that I'm sure kids would have a lot of fun exploring, honestly, because you can look at the different models that they have and they.-you can go as depth into detail as you want. I think that would be really cool. I think teaching kids how to... I think reinforcement learning programming is also another good avenue. I did a educational component thing for this fellowship that I was on, and I basically made this video to teach middle schoolers how to make a reinforcement learning AI or it's really just a reinforcement learning model, and the programming language was Python, but the library that it was implemented on was Tensorforce. And it's really not that hard. It's so much easier than you'd think. I basically coded everything up and just added it to where they would enter one or two things and be able to see how it changes. I think that, obviously somebody can do it better than I can. They probably still would've had a very hard time figuring out how to do it. But I think especially as these libraries continue to develop and become even easier, you can do, especially with machine learning models, you can do some of those in two lines of code. So, I think that would be a really good way. It might be something for only middle school and high school, but you might be able to bring it down to the elementary level and just hold their hand or just show them on the screen, getting those kids to actually see the process of how these models get made and how they can be implemented for useful features. Or there you go. There's a way to show them bias. You can do two models based on two different sets of training data and you can show them, ""Hey, do you see how this one outputs basically bias and incorrect answers, whereas this one with the more representative training set does make better decisions that more humans would make?"" And then, it also shows them that AI aren't perfect impartial beings. They are subject to the same flaws that we are, especially if we're giving them training data that we make. But yeah, I think that's probably the best way to get down into the nitty-gritty.",48,8,1,0,0,1,1,1,0,0,1,1
49,BS,Researcher,Researcher 2,Yeah. That's a really good suggestion. Can you think of any ways that we can help youth connect these topics to their everyday lives and make it meaningful to them?,49,8,0,0,0,0,0,0,0,0,0,0
50,BS,Grad Student,Jerry,"I mean, just pull anything out. I mean, a phone. This Google Home I have here, AI is everywhere. There is not a thing... I'm sure there's an AI processing algorithm in my camera right now that is doing something with my face. Any browser, your email. I mean, it's everywhere. Getting them to connect that training data and all this data that AI uses to continually teach itself and learn is coming from you and it's coming from everywhere. That might be a little scary for them to think about. But I think it's important to know.",50,8,1,0,0,1,0,0,0,0,1,1
51,BS,Researcher,Researcher 2,"Oh, I think that's important to know too. I think that's all of the questions I have for you. Is there anything else you would like to add that we haven't touched on, that you think is important or valuable?",51,8,0,0,0,0,0,0,0,0,0,0
52,BS,Grad Student,Jerry,"My mom is a teacher, and so is my sister. And I'm also curious to know what their take is on how to-",52,8,0,0,0,0,0,0,0,0,0,0
53,BS,Researcher,Researcher 2,What grades do they teach?,53,8,0,0,0,0,0,0,0,0,0,0
54,BS,Grad Student,Jerry,"My mom was certified for all grades, but she's in the district office now and she runs the English as a Second Language and World Languages.",54,8,0,0,0,0,0,0,0,0,0,0
55,BS,Researcher,Researcher 2,Oh.,55,8,0,0,0,0,0,0,0,0,0,0
56,BS,Grad Student,Jerry,[crosstalk 00:27:01] district. I'm going to text her.,56,8,0,0,0,0,0,0,0,0,0,0
57,BS,Researcher,Researcher 2,I'm curious. What district does she work for?,57,8,0,0,0,0,0,0,0,0,0,0
58,BS,Grad Student,Jerry,"District 5, Lexington-Richland.",58,8,0,0,0,0,0,0,0,0,0,0
59,BS,Researcher,Researcher 2,"Oh, okay. Yeah, my mom's a... she was a teacher. She's now a speech pathologist. So, I've been in the teaching world as well with those.",59,8,0,0,0,0,0,0,0,0,0,0
60,BS,Grad Student,Jerry,What was that... All right. Can you say the question again?,60,8,0,0,0,0,0,0,0,0,0,0
61,BS,Researcher,Researcher 2,"The last thing I asked was if there was anything else you wanted to add, but before that I asked if there was any ways that we can help youth connect the topics of AI and machine learning and make it mean-",61,8,0,0,0,0,0,0,0,0,1,0
62,BS,Grad Student,Jerry,What about the one before that?,62,8,0,0,0,0,0,0,0,0,0,0
63,BS,Researcher,Researcher 2,"The one before that was, are there any particular tools or resources that you are aware of that we can use to help youth engage in conversations about machine learning, AI and ethics?",63,8,0,0,0,0,1,1,0,0,1,0
64,BS,Grad Student,Jerry,"Ooh, wait, I'm sorry. The one before that one. The one I got stumped on.",64,8,0,0,0,0,0,0,0,0,0,0
65,BS,Researcher,Researcher 2,"The one you got stumped on. Oh. It was, what do you think is important for youth to know about AI and machine learning? Is that the right one?",65,8,0,0,0,0,0,0,0,0,1,0
66,BS,Grad Student,Jerry,I think it was the one after that. Hold on. I know you sent me the script. It might be here.,66,8,0,0,0,0,0,0,0,0,0,0
67,BS,Researcher,Researcher 2,"[crosstalk 00:28:14] in there. We also have, what age do you think is appropriate for them to introduce these concepts?",67,8,0,0,0,0,0,0,0,0,0,0
68,BS,Grad Student,Jerry,"When she responds, I will send it to Caitlin and she'll send it to you.",68,8,0,0,0,0,0,0,0,0,0,0
69,BS,Researcher,Researcher 2,Yeah. She'll send it to me. Yeah. We're in contact. She was a nice middle man for this meeting.,69,8,0,0,0,0,0,0,0,0,0,0
70,BS,Grad Student,Jerry,"Oh, yeah. But yeah, no, I think that does it.",70,8,0,0,0,0,0,0,0,0,0,0
71,BS,Researcher,Researcher 2,Okay. I'm going to go ahead and stop the recording.,71,8,0,0,0,0,0,0,0,0,0,0
1,CF,Researcher,Researcher 2,"So we have Chris with us today, and it is Wednesday February 16 2022. Thank you, Chris. So, Chris could you tell me a little bit about your professional background and work history.  ",1,9,0,0,0,0,0,0,0,0,0,0
2,CF,Grad Student,Brad,"Yeah, so I got a computer science degree, and then during my computer science degree, I worked at a few different jobs using it. So I worked, like, IT management in ceilings working IT, I then had two stints doing software development work, one for a manufacturing company and then another for a larger tech company. And then around the time of graduating, I decided to go into grad school instead. And now that I'm in grad school, most of what I do is research with AI systems and humans using AI systems.",2,9,1,0,0,1,0,0,0,0,1,0
3,CF,Researcher,Researcher 2,Would you mind telling me a little bit about like what got you interested in computer science and AI. ,3,9,0,0,0,0,0,0,0,0,0,0
4,CF,Grad Student,Brad,"Yeah, so I think there's two small separations there, which is like my initial interest in computer science is when I was a lot younger. I actually went to a fair amount of coding camps as a kid. I just always was around tech and then my mom knew I liked it a lot. So we would go do local camps that would look at programming and things like that, were just in the area and targeting younger kids. Then when I got out of high school, the guy who gave me my first job as an IT professional decided to teach a coding course at my high school. So I took that a few times just so that way I could keep redoing it and I found it really fun. And also it was just like really interesting, because it was vastly different than all the other material we were covering in high school. And then obviously I went into getting the CS degree in four years of that. So I just stuck with it. And then when I got into grad school, I had to pick a domain and I wanted to work on tech that was more like 10, 15, 20 years out as opposed to looking at tech that already existed. So then I was like, AI is a future tech. That's really interesting. It's not very formed yet. There's a little structure to it. So I thought it'd be fun to look at.",4,9,1,0,0,1,0,0,0,0,1,0
5,CF,Researcher,Researcher 2,Okay. Yeah. That's interesting. Would you mind telling me a little bit about some of your research that you have been involved in as a graduate student?,5,9,0,0,0,0,0,0,0,0,0,0
6,CF,Grad Student,Brad,"Yeah, so work that I've done has been outlining how there are different camps I've worked in. Number one is outlining how humans and AI interact with each other, specifically my dissertation work is on how humans and AI systems can impact and influence each other in a task. So how a human could be susceptible to letting a robot or an AI system tell it what to do and take commands from it or vice versa. So looking at what comprises that, how humans should lead AI or how an AI should lead a human, things like that. So that trade off and then I've also done work looking at how ethics in AI systems can be implemented, created and how it interacts with humans. So, it's fairly big part is the ethical implications of AI systems and how those ethical implications ultimately impact the utility of AI. And then the last, there are other smaller things that I've had to do. But then the last main one I worked on is AI. There's a grant that I work on fairly often that is a grant that looks at using machine intelligence and recommender systems to provide recommendations to teachers for professional development. So it's a lot of providing recommendations for their professional development and I work on the side of that where I work on building this system and outline in that aspect.",6,9,1,0,0,1,1,0,0,0,1,0
7,CF,Researcher,Researcher 2,"Yeah, I'm actually familiar with that one, because it's the Name of Program program. We have some people in the learning sciences that are working on that. So I'm familiar with this one. Would you mind giving me a little bit more detail about your project that involves AI ethics? What were some of the results that came out of that?",7,9,1,0,0,0,1,0,0,0,0,0
8,CF,Grad Student,Brad,"So there are two main ones that I can talk about that have differences. The first one is, there's a big one that was looking at it from a theoretical angle, but more of a formation angle of looking at how the complexity of an AI system having a moral agenda would interact with human moral agendas. So obviously if you code an AI system to be ethical, it would have an ethical ideology and when it does work that ideology would exist and be present in its work. So if you'd asked to do something against an ethical ideology, that ethical ideology would present itself in the workplace and that's how humans work too. So what the paper was about was about how our human ideology is going to interact with AI ideologies. And then how it does form a collective team ideology, because that's how it works right now with humans and we're entire teams can have an ethical identity, but does that ethical identity change if you implement an AI system that has its own ethical identity. And then for instance, where should that ethical identity of an AI come from? Should it come from the team it's assigned to? Or should it come from the industry it works in or should it come from general standards of AI appropriateness? Where does that identity come from was also a big question of that. And that's more of a theoretical piece that's higher level because it looks at all those different factors simultaneously. So it was that one. And then the other one we looked at was a piece on how humans react to the ethical severity of a decision with ethical implications. So a decision that might harm someone or a decision might lie to people. And I was looking at, are humans going to be okay with the system that uses social deception or a system that allows physical harm to happen, even if it's not directly causing it. And that one was interesting because that was a full empirical study where we found that a social consequence, lying in deception is a real bad like no go for a lot of people when it comes to the machine system, but something like a physical consequence within the context we were talking about was completely fine. So it was having that consequence and having the AI judge that consequence was okay, but having it have a consequence that almost hurt the relationship between them and the human was worse. So those… the two we looked at the imperial side and then that theoretical side",8,9,0,0,0,1,1,0,1,1,0,0
9,CF,Researcher,Researcher 2,"That's actually really fascinating. Thank you for sharing that. So I know you work with AI and machine learning. So what activities related to AI and machine learning, you do in a typical week? So I know you talked about some of those projects, but what things are you doing on the day-to-day level?",9,9,0,0,0,0,0,0,0,0,0,0
10,CF,Grad Student,Brad,"Yeah. So on the day-to-day, once again, if I talk about it from a project to project standpoint, there are some easy ways to look at it, which are the TLP project, that's coding and expert system, which means I'm looking at how experts look at things and I'm creating rules for a system to make judgements based on those rules. So, on a day-to-day, what I do is, I check those rules. I look at them, but most of what I do is just make sure it's still working. Make sure nothing's gone wrong, make sure I look at the results. I'm like, ""okay, these results came out, they don't look bad."" A lot of it, a lot of time goes into those, a lot, at a concentrated period and then a lot of it's just watching it happen. So that's the one. And then for my dissertation work, I actually use machine intelligent systems that were designed by other groups. So I got them from a group that the platform I chose to use, they had created these bots for that platform. And so what I actually do is just, I found these bots made by that platform that are open source and I slightly tweaked them. So similar to before it's less of a like I need to change and develop so many things every day and more like, ""okay, I just need to keep this up and running, make sure everything's fine. Make sure nothing's changing."" So just a lot of oversight.",10,9,0,0,0,1,0,0,0,0,1,1
11,CF,Researcher,Researcher 2,"Yeah. That's interesting. So I know you said it's a lot of oversight, but what do you like most about working with machine learning and AI technologies?",11,9,0,0,0,0,0,0,0,0,0,0
12,CF,Grad Student,Brad,"Um, I do like getting kind of in the nitty gritty nuts and bolts of things where it's like it, you can be AI kind of lets you be at like 10 miles ahead and like also at ground level where a lot of times when you're building like a system to work with a systems, it is about like Okay, what is happening, like in the process right now, like if we talk about process 'A', 'B', 'C', 'D', like, fixing 'A', fixing 'B', fixing 'D'- but then you can stop doing that and, like take a step back and look at the whole process at the same time, and you can't really do that with other software developmen,t like-Most of the software development you do you you're in charge of working on a single component.  So you don't get to see like the whole like sausage making process, you just get to be a little piece of it, but with AI systems, I find that, like you get to be a part of a lot more of that because all those parts are more intertwined-interesting.",12,9,0,0,0,1,0,0,0,0,1,0
13,CF,Researcher,Researcher 2,"Interesting. Yeah. I wouldn't have thought of that, like looking at the more macro view of everything with the AI technology versus other things in computer science. So we've been talking a lot about AI and machine learning. So I'm curious, what is your definition of AI?",13,9,0,0,0,0,0,0,0,0,0,0
14,CF,Grad Student,Brad,"Yeah, so I think for me and I go back and forth on this, but I usually take it as layers. So machine learning is this big bubble. And then within that bubble is where I see AI and so if I define machine learning, it's the ability for machines to create insights and make a decision based on data it's presented. And what I see AI as is simply that it does a feedback loop. So based on those decisions, it then creates new data. And that's where I see the difference come in. It's like AI is still machine learning because it's still making those insights and making those critical points. But then at the very end of it, it makes this feedback loop where it keeps doing it over and over again. So that's what scopes AI down.",14,9,0,0,0,0,0,0,0,0,0,1
15,CF,Researcher,Researcher 2,"That's awesome. I'm glad you brought machine learning into that because that was my next question. So thank you for covering that. So what are some current trends or issues that you have as somebody who works with AI and machine learning, have you noticed any current trends or issues that are happening with either of these?",15,9,0,0,0,0,0,0,0,0,0,0
16,CF,Grad Student,Brad,"Yeah, a weird one. I was looking at job applications recently. I was just on LinkedIn, saw a few and this is a very interesting one. There's a weird and this is where my dissertation's about acceptance and over-reliance and things like that. And there's a weird over-reliance for some of these things that creates someone missing the point almost. So I was looking at data science positions and they were, ""oh yeah, so data science work, you need to be able to do machine learning stuff for data science and predictive analysis."" And so for that, they're something called random force generation, which is a machine learning technique where you just put a bunch of data in and then say what you want to predict. And then it predicts the stuff with a bunch of complicated math and that's all fine and dandy and it works out great. But you can also do that with basic statistical analysis. So it's almost one of the concerns I run into is, people use it when they don't need to like, don't use a tool that isn't needed or don't use a tool that's too much for the issue almost, which is an issue I've seen. And something I run into as a larger issue is over designing and over implementing some of that tech.",16,9,1,1,0,1,0,0,0,0,0,1
17,CF,Researcher,Researcher 2,"It's just so novel and new, so it's like, ""I want to use it,"" but is it really the best thing for your situation?",17,9,0,0,0,0,0,0,0,0,0,0
18,CF,Grad Student,Brad,"Yeah. And that also makes it to where it creates a mythos around it, that makes it really intimidating for some people like, ""is this new fancy amazing,"". Like that job application, I was like, ""yeah, it's not hard to use, machine learning though."" My brother learned it in a week and does it for his job, and he goes to his job and he tells his job, ""oh, I implement machine learning for this."" And they're just amazed by it. He learned that in two days. So it creates this weird thing where it is simultaneous, over-engineering the problem, but also intimidating new people from getting involved in it because it is considered magic.",18,9,1,1,0,0,0,0,0,0,0,0
19,CF,Researcher,Researcher 2,"No, I actually feel that because I recently joined Golnaz's lab and she does work on AI and machine learning and I had never done that before, so I was intimidated to go and start working on it, but I understand completely. So, how do you see advances in AI or machine learning as a way to help human populations?",19,9,1,0,0,1,1,0,0,0,1,0
20,CF,Grad Student,Brad,"Yeah, I think there's a couple things with that in terms of, if I'm thinking about helping humans, I think it's more about something that's really cool about how humans work is that a lot of times they find easy small problems and they figure out how to fix it. And then it turns out that problem is a really big problem because it affects a lot of people. And so AI systems create this interesting idea where in my opinion, AI systems have a very low barrier of entry or at least including machine learning, you can use machine learning stuff if you can take two weekend classes and I think get pretty up to speed with it if you have the right education and teaching resources behind it. And the key to that is that, you can start solving really small problems in your life really quickly with really simple systems. And eventually what that does is it enables people on a micro level to make their life a bit easier, but also understand technology from this smaller perspective. And then I have a second way as well, but in my head there's a small piece there where it's the toolbox for people to get involved in computing stuff, I think actually lowers with that. So it helps people make things easier. Because I would say back in the day, coding on C and Fortran and stuff was awful and computers were millions of dollars and now it's, ""oh you can do very easy things with very little."" So that's that The second one I have is, more of on the large scale meta-perspective is I think one of the reasons I also got into AI and find it really interesting is I like to see it from a perspective like aiding humans in reducing workload and replacing a human systems within a group and not having humans pick up that work. So more of the idea of freeing up humans to do things that matter to them, but also freeing up humans to work on stuff that they find important. I think that's the 10 years from now potential is, I think in terms of workload and work future it has the most potential to impact and improve people.",20,9,1,0,0,0,1,0,0,0,0,0
21,CF,Researcher,Researcher 2,"Yeah. I mean, we've actually already seen that with some of like there's AI robots that Ford uses in their factories and stuff. So we've already seen that happening and I'm sure it's going to grow from here. So same kind of question, but in reverse. So how do advances in AI or machine learning harm us and are there any particular populations that it harms? Oh, oh no. Okay. All right. I'm going to go ahead and ask the question again just in case. So how do advances in AI or machine learning harm us, harm humans and who in particular is it harming?",21,9,1,0,0,0,1,0,0,0,0,0
22,CF,Grad Student,Brad,"Yeah, so I think piggybacking off of my last answer, I think the most optimistic thing is work future and enabling a work future. But that is also simultaneously the worst aspect of it if done incorrectly. So generally speaking, I like the idea of relieving human workload, but I think the larger concern is in actual phasing out of them from a work perspective. So in other words, an over-reliance on a machine system for the sake of using a machine system as opposed to a human I think is a main issue. And I think ultimately it affects lower level, blue collar workers more and it affects a larger population that has received less expertise, education, throughout their lifestyle, throughout their entire life. So for instance, a PhD individual would probably not have a larger issue with that, given that the specialized area of knowledge that they received, but someone who has a more general work area where the knowledge application is not as deep, but it's a task based knowledge. I think that's the person that has the greatest ability to impact. And I think ultimately it comes down to who we let use that system because there's easy ways to mitigate that, creating systems where for instance, there's the idea of creating head to access for robots, whereas the utilization of a robotic employee doesn't allow you to just skirt the idea of paying for that employee. It still should be something that CRE, it is something you use in generating revenues, therefore it's something that needs to also be accounted for. So I think that's the main issue, the work future I want is also a good and a bad thing, depending on who's in charge of it.",22,9,1,0,0,0,1,0,0,0,0,0
23,CF,Researcher,Researcher 2,"Yeah. I mean, I can see that, but that is a very big concern about the phasing out of people and the introduction of AI and machine learning into these environments. So besides what you just mentioned, do you feel any ethical issues with the use of AI or machine learning?",23,9,0,0,0,0,1,0,0,0,0,0
24,CF,Grad Student,Brad,"I think ultimately AI systems themselves are tools. So, an ethical dilemma existing in AI is simply the reflection of that ethical dilemma existing in a person. What I think AI makes it easier is AI is a tool that makes a lot of things easier and I think that also means AI could be a tool that makes being unethical a lot easier. There's a lot of things you can do with AI systems, with them being black boxes and completely hidden. And also then just being a machine system, if I think of a really modern example, Google is extremely adamant that they will never share the AI algorithm side that determines whether or not a video on YouTube should be monetized or demonetized and the reason they say they don't want to do that is because of bad actors. They're like, ""oh, if we tell you that, then they're a bad actor come in and do something,"" but the issue with this, of them coming in and so saying like, ""oh, we won't do this,"" is there's no oversight now to know if that's discriminatory or not, we can't even tell. And then we say like, ""well shouldn't you provide something?"" No, we can't even provide the oversight because that's too much information, and you be like, ""you just have to trust us."" And I think the challenge right now is that with AI systems, people are way too willing to give them that trust. If a company comes out and says, ""oh, we can't divulge the AI secrets,"" because they'll be, ""oh they're just trade secrets, you can't,"" it's like a normal trade secret, but it's a trade secret that heavily impacts a lot of other people. And it doesn't have that oversight right now. So, I think that's where the complication of ethics comes in is that it makes it easier especially with the current state of it to do something unethical because there's that lack of oversight coming from both a computational side and a social side where people are just like, ""oh, it's an AI system. We can just trust it,"" when in reality, it allows the bad motivations of individuals to almost be hidden because they're exercising those bad motivations through a system.",24,9,1,0,0,1,1,0,1,1,0,0
25,CF,Researcher,Researcher 2,"Yeah, absolutely interesting. I never really thought about these companies releasing that information. Personally I've never looked into it, but now I'm going to be more curious about that. So we're going to shift gears a little bit. We're going to start talking more about youth and AI. So what are your thoughts about young people learning about AI and machine learning?",25,9,0,0,1,0,0,0,0,0,0,0
26,CF,Grad Student,Brad,"I think it's important, but I think it's important from two perspectives. The thing I think it's more important is the computing at a very young age and then older youth I think is perfectly fine to start with machine learning from the perspective of it's very easy to learn if you are put on the right path. So I found machine learning easier to learn because I started doing coding at a much younger age. And so I think ultimately given how our society's going, things like data and things like computing are going to become another form of literacy. And so that idea of having youth learn is another form of just technological literacy, especially in terms of data computing and things like that. And then given that now as a person who have a digital footprint, helping humans under helping, especially youth understand just how powerful their personal identifying data is to a machine system is pretty important. And I think the best way to understand that is, this is what a machine could do with it. So there's it's good because you could get a lot of societal education to people because of its integration, but you could also get youth involved in stem and youth involved in AI development, which is going to be a big part of the workforce. So it's a two front benefit from it.",26,9,1,0,1,1,0,0,0,0,1,1
27,CF,Researcher,Researcher 2,"Yeah, um, so, what age, do you think would be appropriate to start introducing the AI and machine learning concepts?",27,9,0,0,0,0,0,0,0,0,0,0
28,CF,Grad Student,Brad,"Yeah. I think my full path… My mother's an educational therapist who works at a high school/middle school. So I've talked about this a fair bit. I always think if I start with general coding, it starts in second to third grade and I think you can start introducing levels of machine intelligence as early as fifth grade, because machine intelligence doesn't have to be demonstrated from a coding perspective. It can be demonstrated from just what are these things? What do they do? What do they look like? And the benefit is it's an interesting part about it. There's so many really good abstractions of coding principles. I said earlier, I said, ""oh a big coding thing for machine intelligence is something called a random forest. And a random forest is called that because it's a bunch of binary decision trees grouped together and so they call it a forest."" Computing and AI and all those things are already filled with a very large amount of abstract representations of what they are. And so translating that and it's because a lot of us aren't very smart and so it makes it easier to teach us, but there are also things that make it easier to lower the barrier of entry for a lot of these concepts, like talking about a decision tree from the perspective of an actual tree makes it easier for people to understand. So I think you can at least get that high level interest in there at fifth grade, or maybe even slightly earlier with fourth grade, just from a concept perspective under the assumption that there's already some computing knowledge before that. And then, I think from a coding perspective, getting in there at late middle school is always my ideal because then it's, ""oh this is something that you can pursue further in high school, but also you are smart enough right now to understand that."" And that's because I also think that as someone who did a lot of coding, a big issue with learning to code complex things is, for me it was a lot tied to my math maturity. So I found that as I gained greater math maturity, I also gained a lot better ability just to understand coding quickly. And so in terms of hitting the hardcore coding concepts of it, I wouldn't want to do it before that math maturity, is at least somewhere. I felt like I started to get that in late middle school. So I think that's the time to do that.",28,9,0,0,0,0,0,0,0,0,1,0
29,CF,Researcher,Researcher 2,Yeah. That makes sense. I am still learning how to code. So I'll get there one day.,29,9,0,0,0,0,0,0,0,0,1,0
30,CF,Grad Student,Brad,Eventually there's a light bulb moments. It's all about lightbulb moments,30,9,0,0,0,0,0,0,0,0,0,0
31,CF,Researcher,Researcher 2,"And then you feel better about yourself and you want to keep going. Yeah. So what are your thoughts about you learning about the AI? I'm sorry, the social and ethical issues about AI and machine learning?",31,9,0,0,0,0,1,0,0,0,0,0
32,CF,Grad Student,Brad,"Oh yeah. I think that's more important, but it's mostly because I think it's more important because you as an individual interact with society through those platforms and through that data and through that AI, even if you don't realize you are, so me watching a video on YouTube, if I watch a video that has ethical issues, if I watch a video that it just is a very mean spirited video that can harm someone else by watching it I'm promoting it. And then while it might be, ""well, I didn't tell anyone about it."" It's still me actually watching it needs an algorithm system that then promotes it to especially people in my geographic region or people with somewhat profiles to me. So it's this idea that, I think it's important because it also important and ultimately I think it's the fault of the company that is the case, but I don't trust them to fix that. So I think it's more important to educate the individual on how that's going to work. And then I think that's just, once again your data literacy, understanding your digital footprint and also understanding your worth, humans are worth more as data to people than they are as humans. So I think understanding just how much your data is worth contextualize, you should just be giving it out for free, it is something fairly important and also the other adage of nothing is free in life where it's, ""yeah, all these things are free."" TikTok is free, but you're getting a lot of data and you're getting advertised to a lot.",32,9,1,1,0,1,1,0,1,1,1,1
33,CF,Researcher,Researcher 2,"Yeah, those are really good points. We kind of hit on this, but are there any particular really important topics that you think you should learn about machine learning or AI?",33,9,0,0,0,0,0,0,0,0,0,0
34,CF,Grad Student,Brad,"Yeah. So, I said what happens to your data is the most important thing to me. And also what do you produce as a person in terms of data? So what do you produce and then what happens to it? That's the biggest thing for me, because I think that also goes hand in hand with that literacy angle. But I also think the most important thing is how easy it is. Because I think reducing a mythos around a technology, there's a quote about ""tech big magic hammer,"" but reducing the mythos around it, I think is also an extremely important aspect of it because computing has been plagued with people who brag about how hard it is and try to make it seem extra hard. And it isn't. Especially if you don't go into it with respective of it being extra hard. If you go into it with an encouragement angle and with an interest in learning something, it's a lot easier. So I think the second most important thing is you need to learn just how easy it is to get started. There are so many things out there just to get started and they're really easy to get started. They're really easy to get just a little bit interested in it and then that's enough to know if you're going to like it or not. So I think that's the two things. It's from the computing side, what happens to your data? And then from that side, what are the resources you can do to get started and how easy is it to get started?",34,9,0,0,0,1,0,0,0,0,1,0
35,CF,Researcher,Researcher 2,"Yeah. It's like once you start the snowball rolling, it's just going to keep building. So how could we engage youth in learning about machine learning and AI and the ethics involved? Do you have any ideas of ways to introduce that to youth?",35,9,0,0,0,0,1,1,0,0,0,0
36,CF,Grad Student,Brad,"Yeah, let me think. I mean, for me, I was always a fan of informational videos as a child, but that was because that meant I didn't have to do schoolwork that day. I mean, I think it's also personal investigation, having a young person do an activity log where, if I think about the things I think they should learn about, if I think about data, maybe have a child do an activity log where throughout an entire day they have to write down all the data they produce. If they ever do something that they think produces data, they need to write it down and then also have an experienced person do it as well and be like, ""this is how much data I actually produce in a day, knowing me,"" and then you can compare it and contrast it. I also think, it's the idea of calorie counting where the best way to lose weight is just to start counting because the awareness of it is what actually reduces your calorie intake. It's not actually counting is the secret. It's just, ""yeah, you're now aware of what you're eating."" And so I think that's the key, will be a fun activity, ""oh, let's do a log."" Everyone go home and for the next week write down all the things you've done that you think produced data and then you could even have it basically, every time you use technology write down what technology you use and then write down what data you think it produced. And you could start off easy, giving them examples of data. So in YouTube you could be, this is the data that I got. Then you could, let them investigate themselves, ""oh, what data am I getting?"" Things like that. And then the benefit is due to special European laws, there are ways to find out what data companies do have on you. Then you could actually show them and here's the actual data they have on you. I'm sure if you have a student come in and say, ""oh, I watched a YouTube video."" So they logged what YouTube video I liked. In reality it's like, ""well, no, they logged your location, YouTube video you liked, the last four websites you visited and whether or not you skipped the ad when you watched that video."" So yeah, there's plenty of other things they looked at in your video. They didn't just look at, did you watch the video? Did you like it? So I think like that would be a very fun one. And then obviously from the computing, from that standpoint and from the other side, I love scratch anything, associated with it. So any fun little coding things, there's one that's you program a turtle to walk and draw art. Any of those things, I vibe with, but yeah, I think the more fun activity for me from a literacy perspective is that logging perspective.",36,9,0,0,0,1,0,0,0,0,1,0
37,CF,Researcher,Researcher 2,"Yeah. I mean, you just taught me something. I didn't know they could figure out what other websites I had previously visited.",37,9,0,0,0,0,0,0,0,0,0,0
38,CF,Grad Student,Brad,"All of them share the information together. Google also owns half the internet. So if you go to eight different Google sites, they just tie it all together and, ""oh, we know where you went.""",38,9,0,0,1,0,0,0,0,0,0,0
39,CF,Researcher,Researcher 2,"Well, I didn't realize that so now Now I know to.  Oh, you know you already picked or mentioned a couple like scratch, but you don't have any other particular tools activities or resources that you are aware of that we can use to help youth engaged in these conversations are learning about.",39,9,0,0,0,0,0,0,0,0,0,0
40,CF,Grad Student,Brad,"I'm trying to remember. I sent it to my mom a while ago. If I ever find it, I will send you again. There was a really good group I found a while ago, that did coding education for individuals, but they split it up by grade and it was research group I think I have Kentucky or something, but they do second grade should learn this and this. And second grade is when they start them on scratch",40,9,0,0,0,0,0,0,0,0,1,0
41,CF,Researcher,Researcher 2,Wow!,41,9,0,0,0,0,0,0,0,0,0,0
42,CF,Grad Student,Brad,"But then after that is when they get higher and higher. If I'm trying to think about things that I mean, block coding is obviously the first thing that always comes to mind given its prevalence. But I could also think that something from a higher level that would be interesting is introducing them to something like GitHub, but not from the perspective of getting them to use it. But from the perspective getting them to look at things they might find interesting. GitHub is also a social media platform. It is tech repositories, there's so many things and looking at open source websites, source forage, websites that have cool projects, even something like Indestructible, where it's just looking at something that has a project associated with it. I love Kiwi Kits as well. Kiwi Kits are really cool.  Those are really fun things for me. I grew up on Lego Mindstorms. So I also like heavily push the concept. Because Lego Mindstorms are really cool because they start out with block coding and then after block coding, they have a full Java implementation. So you can do the full path and then if it has Java, that means it can have AI. So you can do the whole gambit, going from start to finish. So I think that could be, for me that is where it's at. Yeah, like scratch is my biggest one for early stuff. And then all Lego Mindstorms. Those are my jam.",42,9,1,0,0,1,0,0,0,0,1,0
43,CF,Researcher,Researcher 2,I think I have heard of that one.,43,9,0,0,0,0,0,0,0,0,0,0
44,CF,Grad Student,Brad,"Those are even still around. Yeah. Those are really fun. And that's-by high school coding class we did Java programming for Mindstorms and it was really interesting, but there's so much more you could do with it after that. So if you had kids start with it and grow up with it, the potential they have there is pretty cool I think.",44,9,0,0,0,1,0,0,0,0,1,0
45,CF,Researcher,Researcher 2,"Yeah I mean that is you just gave us a lot of good information Thank you so, can you think of any ways to help us connect these topics like thinking about data machine learning AI to their everyday lives and make it meaningful for them.",45,9,0,0,0,0,0,0,0,0,1,0
46,CF,Grad Student,Brad,"Oh yeah. Like I said, I think for me, actually I talked about with a log talking about, I think reverse engineering, looking at, instead of being like, ""oh, how does data impact your daily life?"" Be more like, ""oh, how does your daily life impact your data?"" Taking it event by event is great. And then looking at the basic tasks you could do as an individual or pieces of entertainment they like. Relating it back to some they derive pleasure from a just consumer standpoint. For instance, I'm sure a lot of children watch Netflix or other things like that, Netflix and you could even take this as an interesting one. You open up Netflix and it's, ""here are recommendations for you."" Talking to them about, ""well, what does that recommendation come from?"" And then having them throw out those ideas of, oh, they could see a show they watched and they're like, ""oh, I watched the show already."" I think that's why [inaudible 00:36:12] and answer is yes you did. That's why they recommended it to you. Because Netflix did a bunch of research and found the number one thing that determined whether or not someone wanted to watch a show or not is whether or not they already finished it because people just like to do the same thing over and over again. That was an interesting one too. I met with Home Depot one time and they're like, ""yeah, our algorithm is designed to show you the same items over and over again because eventually you'll like it, you'll lower your standards and like it eventually."" So tiny things like that. But yeah, I think with something like Netflix, it will be interesting or media richness, talking about this is a piece of media you work with, this is a platform to interact with every day and extracting data from it. Because I think that's the key is, looking at the data they already have. So that way it means something to them. And then like that way, next time I go on Netflix, that's how I was as a kid. I know I might have been a weird kid, but if I learned that in school, the next thing I would've done is gone home and talked to my mom about all the cool things Netflix has with data and then watch and I would pull up our Netflix, this is what it's doing right now. So I think that's for me, what I would find interesting or applicable to those younger audiences.",46,9,1,0,0,1,0,0,1,0,1,1
47,CF,Researcher,Researcher 2,"Yeah. I mean, once again, you just taught me more stuff that I didn't know. So last question, have you used any of these teaching techniques that you just discussed with me in your own work, teaching or research? And if so, how did it turn out?",47,9,0,0,0,0,0,0,0,0,0,0
48,CF,Grad Student,Brad,"Yeah, so from two perspectives, in terms of full formalized teaching, I've taught the second one is about stuff I do with my mother, but I've taught coding courses at the collegiate level, like lab courses at collegiate style. And so there is less of a gap there in terms of age. I was pretty much two years older than everyone I was teaching. And so yeah, you do get interesting. You do have to work down in terms of their understanding, but also you can still stay at a very high level, but even when I was doing that, the best instructors I've ever had are the ones that pulled up their code and did it with you. So, that's just how I did it. Like I said, I think what changes is the modality you do it through. So for college kids, you don't pull up a YouTube and talk about how their data is produced there. You just pull up data and you work with them through a data set. So, I think the teaching principle, the pedagogy principle, [inaudible 00:38:56] whatever the word is, principle still stays the same, which that demonstration aspect, the difference is how abstract that demonstration gets at the collegiate level. We don't need that. But then my mother works with students who have gotten interested in stem and I'm like, ""yeah, I can talk to them about this."" And it's more about like once again, the education side for that younger side is, I don't want to just sit up there and tell them about those things. I want them to go find what they find interesting. So I give them the website of, ""here's is all, here's scratch."" Just play around with it for 10 minutes. I was like, ""I don't want to touch it."" I'm not going to talk to you about it. You just go play with it for 10 minutes because that's like how I not only learned it, but I got interested in it. Because I think it's less interesting for a student to be told what to do. And it's way more interesting if they were, ""here's a fun thing. Here's 10 minutes."" Instead of doing homework in class, go do this for 10 minutes. And that was always my favorite part of doing computer stuff when I was younger.",48,9,0,0,0,1,0,0,0,0,1,0
49,CF,Researcher,Researcher 2,"Kids love free time and if you can give them some boundaries within that free time, even better. So that was my last question for you. Is there anything else that you would like to add that we haven't discussed or you think is important?",49,9,0,0,0,0,0,0,0,0,0,0
50,CF,Grad Student,Brad,"No, I don't think so.",50,9,0,0,0,0,0,0,0,0,0,0
51,CF,Researcher,Researcher 2,Okay I'm gonna go ahead and stop the recording then.,51,9,0,0,0,0,0,0,0,0,0,0